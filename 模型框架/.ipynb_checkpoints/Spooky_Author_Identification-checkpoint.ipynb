{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ARkId6wAT1aC"
   },
   "source": [
    "一个几乎可以解决所有NLP问题的kernal\n",
    "\n",
    "*   tfidf\n",
    "*count features\n",
    "*logistic regression\n",
    "*naive bayes\n",
    "*svm\n",
    "*xgboost\n",
    "*grid search\n",
    "*word vectors\n",
    "*LSTM\n",
    "*GRU\n",
    "*Ensembling\n",
    "\n",
    "所属kaggle比赛：\n",
    "\n",
    "spooky author 分类\n",
    "\n",
    "所用框架： tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vh-2HZbdZ_QU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm #可扩展的Python进度条\n",
    "from keras.models import Sequential\n",
    "from sklearn.svm import SVC\n",
    "from keras.layers.recurrent import LSTM,GRU\n",
    "from keras.layers.core import Dense,Activation,Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7GDYQC0Gb9ht"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sample = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aJhBon2McLul"
   },
   "source": [
    "先看一下data长什么样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "colab_type": "code",
    "id": "xiAbd4GEcKwJ",
    "outputId": "a7a27d95-ae77-4380-e218-ffa60f97a172"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "colab_type": "code",
    "id": "LRsO8g1wcV5f",
    "outputId": "0dbcd0b6-beb6-4323-fb4a-84ff06a6bdc4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>And when they had broken down the frail door t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>While I was thinking how I should possibly man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>I am not sure to what limit his knowledge may ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "0  id02310  Still, as I urged our leaving Ireland with suc...\n",
       "1  id24541  If a fire wanted fanning, it could readily be ...\n",
       "2  id00134  And when they had broken down the frail door t...\n",
       "3  id27757  While I was thinking how I should possibly man...\n",
       "4  id04081  I am not sure to what limit his knowledge may ..."
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "colab_type": "code",
    "id": "ElsxUklxeIkL",
    "outputId": "8f961976-6da0-405e-fd23-65c0747dcb1a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       EAP       HPL       MWS\n",
       "0  id02310  0.403494  0.287808  0.308698\n",
       "1  id24541  0.403494  0.287808  0.308698\n",
       "2  id00134  0.403494  0.287808  0.308698\n",
       "3  id27757  0.403494  0.287808  0.308698\n",
       "4  id04081  0.403494  0.287808  0.308698"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BmxKefhnelbs"
   },
   "source": [
    "Kaggle采用[multi-class log-loss](https://github.com/dnouri/nolearn/blob/master/nolearn/lasagne/util.py)作为预测指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A6ikDOu_ekkj"
   },
   "outputs": [],
   "source": [
    "def multiclass_logloss(actual, predicted, eps=1e-15):\n",
    "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
    "    :param actual: Array containing the actual target classes\n",
    "    :param predicted: Matrix with class predictions, one probability per class\n",
    "    \"\"\"\n",
    "    # Convert 'actual' to a binary array if it's not already:\n",
    "    if len(actual.shape) == 1:\n",
    "        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n",
    "        for i, val in enumerate(actual):\n",
    "            actual2[i, val] = 1\n",
    "        actual = actual2\n",
    "\n",
    "    clip = np.clip(predicted, eps, 1 - eps)\n",
    "    rows = actual.shape[0]\n",
    "    vsota = np.sum(actual * np.log(clip))\n",
    "    return -1.0 / rows * vsota"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tYYrYWDKfApm"
   },
   "source": [
    "我们用scikitlearn中的LabelEncoder 将类别文本转化为0,1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xz2WXsUce_tr"
   },
   "outputs": [],
   "source": [
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "y = lbl_enc.fit_transform(train.author.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "0nepZflBfZon",
    "outputId": "056302c7-f85e-4a2a-d153-007ab5f308b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XO_n0hRnflu-"
   },
   "source": [
    "在进行下一步特征处理之前，我建议将数据分为训练集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "edJCHuXffiGH"
   },
   "outputs": [],
   "source": [
    "x_train,x_valid,y_train,y_valid = train_test_split(train.text.values, y, \n",
    "                                                  stratify=y, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "hemdObRRgYr0",
    "outputId": "5ecce7d8-9c21-4e5c-c9d4-9c6f9bc05a82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17621,)\n",
      "(1958,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4kSLFnArgglF"
   },
   "source": [
    "#建立基本模型\n",
    "\n",
    "首先第一个是tf-idf +LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nLBmvueuguV1"
   },
   "source": [
    "**Always start with these features. They work (almost) everytime!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 924
    },
    "colab_type": "code",
    "id": "R5QUmTixgfpF",
    "outputId": "10e07540-a5b5-43cb-c2a7-92d8172e4d70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 11813)\t0.2469424385443994\n",
      "  (0, 10050)\t0.31534173991151543\n",
      "  (0, 7734)\t0.2621357570531394\n",
      "  (0, 6078)\t0.21913481148346806\n",
      "  (0, 5920)\t0.2699803359499066\n",
      "  (0, 5641)\t0.28210670387497144\n",
      "  (0, 3647)\t0.33928338965309934\n",
      "  (0, 3312)\t0.2913532806410929\n",
      "  (0, 2813)\t0.3345950093082599\n",
      "  (0, 2161)\t0.3474674493892856\n",
      "  (0, 1489)\t0.3710563608683541\n",
      "  (1, 14862)\t0.3467364483300827\n",
      "  (1, 11446)\t0.23785570257025115\n",
      "  (1, 9156)\t0.3385709613222204\n",
      "  (1, 8899)\t0.49640563902064305\n",
      "  (1, 8268)\t0.4364136618558541\n",
      "  (1, 4746)\t0.3259827441631435\n",
      "  (1, 72)\t0.4067284254948717\n",
      "  (2, 14071)\t0.3240192548729904\n",
      "  (2, 13042)\t0.25915485523649134\n",
      "  (2, 12014)\t0.26382082678856383\n",
      "  (2, 11546)\t0.16409370088652775\n",
      "  (2, 9656)\t0.25408177755421213\n",
      "  (2, 9422)\t0.26141001709560185\n",
      "  (2, 7995)\t0.28804138618156144\n",
      "  :\t:\n",
      "  (17617, 2312)\t0.3765818334354421\n",
      "  (17618, 14413)\t0.41062696740663335\n",
      "  (17618, 13333)\t0.41457868692900307\n",
      "  (17618, 12513)\t0.2857797208393344\n",
      "  (17618, 8238)\t0.3745429502598771\n",
      "  (17618, 3074)\t0.3846536786703435\n",
      "  (17618, 2424)\t0.4487994588757252\n",
      "  (17618, 1910)\t0.29694802364808376\n",
      "  (17619, 11238)\t0.3787523030764777\n",
      "  (17619, 11006)\t0.32179216116874004\n",
      "  (17619, 9940)\t0.38429983611460417\n",
      "  (17619, 8597)\t0.3091580708837293\n",
      "  (17619, 7705)\t0.24513737956628373\n",
      "  (17619, 7485)\t0.31960708142761346\n",
      "  (17619, 6810)\t0.4014342579279944\n",
      "  (17619, 6374)\t0.2630621333876525\n",
      "  (17619, 653)\t0.3422561179502724\n",
      "  (17620, 10492)\t0.33585686401865333\n",
      "  (17620, 9289)\t0.36844069294759363\n",
      "  (17620, 8640)\t0.3812238967372595\n",
      "  (17620, 8025)\t0.3909847177152553\n",
      "  (17620, 4367)\t0.3381504178370897\n",
      "  (17620, 3325)\t0.3215013220701526\n",
      "  (17620, 2936)\t0.3132063646224388\n",
      "  (17620, 1734)\t0.37073424676603\n"
     ]
    }
   ],
   "source": [
    "tfv = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "            stop_words = 'english')\n",
    "\n",
    "# Fitting TF-IDF to both training and test sets (semi-supervised learning)\n",
    "tfv.fit(list(x_train) + list(x_valid))\n",
    "x_train_tfv =  tfv.transform(x_train) \n",
    "x_valid_tfv = tfv.transform(x_valid)\n",
    "print(x_train_tfv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "gjqmAFt2jhZP",
    "outputId": "bfec8311-7aed-407b-d569-f260f78b8c3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17621, 15102)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_tfv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "Lc6FavhQhnBW",
    "outputId": "14256937-efb5-4848-e27f-eb00620ad68a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.626 \n"
     ]
    }
   ],
   "source": [
    "#用简单的LR模型试一下\n",
    "clf = LogisticRegression(C=1.0)\n",
    "clf.fit(x_train_tfv, y_train)\n",
    "predictions = clf.predict_proba(x_valid_tfv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jvo47tP9h5TA"
   },
   "source": [
    "**为了提高准确性，我们可以采用其他特征，比如统计词数，采用scikitlearn中的CountVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tf3gDGGKhuBM"
   },
   "outputs": [],
   "source": [
    "ctv = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), stop_words = 'english')\n",
    "\n",
    "# Fitting Count Vectorizer to both training and test sets (semi-supervised learning)\n",
    "ctv.fit(list(x_train) + list(x_valid))\n",
    "x_train_ctv =  ctv.transform(x_train) \n",
    "x_valid_ctv = ctv.transform(x_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qkJv6o91idsS"
   },
   "source": [
    "我们只提高了0.1.......\n",
    "现在我们继续再用贝叶斯来试一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_0B-OXOBidKI",
    "outputId": "2aa12896-7393-4122-9cfb-72ecf2c39d5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.578 \n"
     ]
    }
   ],
   "source": [
    "clf= MultinomialNB()\n",
    "clf.fit(x_train_tfv,y_train)\n",
    "predictions = clf.predict_proba(x_valid_tfv)\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ce5tdS1vj4wN"
   },
   "source": [
    "看得出来还是LR更准确一点，但如果NB用在词数统计上呢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "1Z6eZYbzj4Ku",
    "outputId": "4b3666d4-0faf-4216-eb23-c2e87efb2672"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.485 \n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(x_train_ctv, y_train)\n",
    "predictions = clf.predict_proba(x_valid_ctv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cjoyym7jkQAu"
   },
   "source": [
    "所以可以看到RF仍然表现很好\n",
    "\n",
    "另外一个ML 算法是SVM，但是SVM计算比较耗时，我们要减小特征数量\n",
    "\n",
    "**对SVD来说，120-200个特征数量是比较合适的**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3AqDBRqukd_5"
   },
   "outputs": [],
   "source": [
    "svd = decomposition.TruncatedSVD(n_components = 120)\n",
    "svd.fit(x_train_tfv)\n",
    "x_train_svd = svd.transform(x_train_tfv)\n",
    "x_valid_svd = svd.transform(x_valid_tfv)\n",
    "#归一化\n",
    "scl = preprocessing.StandardScaler()\n",
    "scl.fit(x_train_svd)\n",
    "x_train_svd_scl = scl.transform(x_train_svd)\n",
    "x_valid_svd_scl = scl.transform(x_valid_svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HzlWJyIcmdVJ"
   },
   "source": [
    "**接下来使用SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "DA_M_1rxmc6e",
    "outputId": "2f65c9f9-9d52-47a0-c5fd-190fd856a4ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.740 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple SVM\n",
    "clf = SVC(C=1.0, probability=True) # since we need probabilities\n",
    "clf.fit(x_train_svd_scl, y_train)\n",
    "predictions = clf.predict_proba(x_valid_svd_scl)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LJAACvJvmtTZ"
   },
   "source": [
    "**看样子SVM表现性能并不好**\n",
    "\n",
    "在进行下一步之前，我们尝试一下现在最主流的xgboost模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "f_Pp0lKYm7Bh",
    "outputId": "8b465abc-fdab-4549-f4c2-62489c91ef19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.782 \n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(max_depth = 7,n_estimators = 200,colsample_bytree = 0.8,\n",
    "                       subsample= 0.8,nthread = 10,learning_rate = 0.1)\n",
    "clf.fit(x_train_tfv,y_train)\n",
    "predictions = clf.predict_proba(x_valid_tfv)\n",
    "#predictions = clf.predict_proba(x_valid_tfv.tocsc())\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pxcY3nUmol1H"
   },
   "source": [
    "看起来xgboost性能也不够好，但这是错误的，因为我们还没有进行超参数优化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dBNrfKhFotlu"
   },
   "source": [
    "#Grid Search\n",
    "\n",
    "常用的超参数调试经验在个[参考链接中](http://blog.kaggle.com/2016/07/21/approaching-almost-any-machine-learning-problem-abhishek-thakur/)\n",
    "\n",
    "这里仅对LR中的参数进行调试\n",
    "\n",
    "在进行之前，需要先建立评价函数，采用scikit-learn中的make——scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NkTWVp_6osk1"
   },
   "outputs": [],
   "source": [
    "mll_scorer = metrics.make_scorer(multiclass_logloss,\n",
    "                                 greater_is_better=False, needs_proba=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1GJ_u3wKqjZj"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7NN0MUBpqish"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Spooky Author Identification.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
