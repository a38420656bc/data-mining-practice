{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "特征：\n",
    "   'label','popularity','carCommentVolum','newsReplyVolum'平移了12个月\n",
    "    train:\n",
    "        1,  2,  3,  4,  5,  6,  7,  8,  9,  10,  11,  12\n",
    "        13, 14, 15, 16, 17, 18, 19, 20, 21, 22,  23,  24 \n",
    "        \n",
    "    test: 21,22,23,24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import os \n",
    "# import gc\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path  = './ccf_car/'\n",
    "train_sales  = pd.read_csv('train_sales_data_train.csv')\n",
    "train_search = pd.read_csv('train_search_data_train.csv')\n",
    "train_user   = pd.read_csv('train_user_reply_data_train.csv')\n",
    "evaluation_public = pd.read_csv('evaluation_public_9.csv')\n",
    "# submit_example    = pd.read_csv('submit_example.csv')\n",
    "data = pd.concat([train_sales, evaluation_public], ignore_index=True)\n",
    "data = data.merge(train_search, 'left', on=['province', 'adcode', 'model', 'regYear', 'regMonth'])\n",
    "data = data.merge(train_user, 'left', on=['model', 'regYear', 'regMonth'])\n",
    "data['label'] = data['salesVolume']\n",
    "data['id'] = data['id'].fillna(0).astype(int)\n",
    "data['bodyType'] = data['model'].map(train_sales.drop_duplicates('model').set_index('model')['bodyType'])\n",
    "#索引-->value\n",
    "\n",
    "#LabelEncoder\n",
    "for i in ['bodyType', 'model']:\n",
    "    data[i] = data[i].map(dict(zip(data[i].unique(), range(data[i].nunique()))))\n",
    "    #key-->value\n",
    "data['mt'] = (data['regYear'] - 2016) * 12 + data['regMonth']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>adcode</th>\n",
       "      <th>bodyType</th>\n",
       "      <th>forecastVolum</th>\n",
       "      <th>id</th>\n",
       "      <th>model</th>\n",
       "      <th>province</th>\n",
       "      <th>regMonth</th>\n",
       "      <th>regYear</th>\n",
       "      <th>salesVolume</th>\n",
       "      <th>Unnamed: 0_y</th>\n",
       "      <th>popularity</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>carCommentVolum</th>\n",
       "      <th>newsReplyVolum</th>\n",
       "      <th>label</th>\n",
       "      <th>mt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>31675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>350000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5276</td>\n",
       "      <td>59</td>\n",
       "      <td>福建</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>210000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5277</td>\n",
       "      <td>59</td>\n",
       "      <td>辽宁</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5278</td>\n",
       "      <td>59</td>\n",
       "      <td>重庆</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>610000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5279</td>\n",
       "      <td>59</td>\n",
       "      <td>陕西</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31679</td>\n",
       "      <td>NaN</td>\n",
       "      <td>230000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5280</td>\n",
       "      <td>59</td>\n",
       "      <td>黑龙江</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0_x  adcode  bodyType  forecastVolum    id  model province  \\\n",
       "31675           NaN  350000         0            0.0  5276     59       福建   \n",
       "31676           NaN  210000         0            0.0  5277     59       辽宁   \n",
       "31677           NaN  500000         0            0.0  5278     59       重庆   \n",
       "31678           NaN  610000         0            0.0  5279     59       陕西   \n",
       "31679           NaN  230000         0            0.0  5280     59      黑龙江   \n",
       "\n",
       "       regMonth  regYear  salesVolume  Unnamed: 0_y  popularity  Unnamed: 0  \\\n",
       "31675        12     2017          NaN           NaN         NaN         NaN   \n",
       "31676        12     2017          NaN           NaN         NaN         NaN   \n",
       "31677        12     2017          NaN           NaN         NaN         NaN   \n",
       "31678        12     2017          NaN           NaN         NaN         NaN   \n",
       "31679        12     2017          NaN           NaN         NaN         NaN   \n",
       "\n",
       "       carCommentVolum  newsReplyVolum  label  mt  \n",
       "31675              NaN             NaN    NaN  24  \n",
       "31676              NaN             NaN    NaN  24  \n",
       "31677              NaN             NaN    NaN  24  \n",
       "31678              NaN             NaN    NaN  24  \n",
       "31679              NaN             NaN    NaN  24  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adcode  model  mt\n",
       "110000  0      1     408\n",
       "               2     160\n",
       "               3     362\n",
       "               4     404\n",
       "               5     445\n",
       "Name: salesVolume, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_sales_feature(df_):\n",
    "# feature_data = pd.DataFrame()\n",
    "stat_dim=[\"adcode\", \"model\", \"mt\"]\n",
    "data=data.groupby(stat_dim)[\"salesVolume\"].apply(lambda x: x.sum())\n",
    "feature_data= data.rolling(3).mean().tolist()\n",
    "data['window'] = feature_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "adcode = list(data.adcode.unique())\n",
    "model = list(data.model.unique())\n",
    "mt = list(data.mt.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data = data.groupby(stat_dim)[\"salesVolume\"].apply(lambda x: x.sum()).rolling(3).mean()\n",
    "# feature_data = feature_data.dropna().unstack(level=-1)\n",
    "# feature_data.index = feature_data.index.droplevel(0)\n",
    "# feature_data.index = feature_data.index.droplevel(0)\n",
    "\n",
    "# feature_data = feature_data.dropna().unstack(level=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adcode  model  mt\n",
       "110000  0      1            NaN\n",
       "               2            NaN\n",
       "               3     310.000000\n",
       "               4     308.666667\n",
       "               5     403.666667\n",
       "Name: salesVolume, dtype: float64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_data.reset_index(drop=True)\n",
    "feature_data.head()\n",
    "# reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to function call (<ipython-input-106-f5ff60eeeed6>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-106-f5ff60eeeed6>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    data.groupby(stat_dim)[\"salesVolume\"].apply(lambda x: x.sum())=feature_data\u001b[0m\n\u001b[1;37m                                                                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m can't assign to function call\n"
     ]
    }
   ],
   "source": [
    "data.groupby(stat_dim)[\"salesVolume\"].apply(lambda x: x.sum())=feature_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(train_search, 'left', on=['province', 'adcode', 'model', 'regYear', 'regMonth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stat_feature(df_):   \n",
    "    df = df_.copy()\n",
    "    stat_feat = []\n",
    "    df['model_adcode'] = df['adcode'] + df['model']\n",
    "    df['model_adcode_mt'] = df['model_adcode'] * 100 + df['mt']\n",
    "    for col in tqdm(['label','popularity']):#,'newsReplyVolum'\n",
    "        # shift\n",
    "        for i in [1,2,3,4,5,6,7,8,9,10,11,12]:\n",
    "            stat_feat.append('shift_model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'] + i\n",
    "            df_last = df[~df[col].isnull()].set_index('model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['shift_model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'].map(df_last[col])    \n",
    "    return df,stat_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_score(data, pred='pred_label', label='label', group='model'):\n",
    "    data['pred_label'] = data['pred_label'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    data_agg = data.groupby('model').agg({\n",
    "        pred:  list,\n",
    "        label: [list, 'mean']\n",
    "    }).reset_index()\n",
    "    data_agg.columns = ['_'.join(col).strip() for col in data_agg.columns]\n",
    "    nrmse_score = []\n",
    "    for raw in data_agg[['{0}_list'.format(pred), '{0}_list'.format(label), '{0}_mean'.format(label)]].values:\n",
    "        nrmse_score.append(\n",
    "            mse(raw[0], raw[1]) ** 0.5 / raw[2]\n",
    "        )\n",
    "    print(1 - np.mean(nrmse_score))\n",
    "    return 1 - np.mean(nrmse_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_score(data, pred='pred_label', label='true_sales', group='model'):\n",
    "    data['pred_label'] = data['pred_label'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    y = pd.read_csv(\"valid_data_y.csv\")\n",
    "    data = data.merge(y, 'left', on=['id'])\n",
    "    data_agg = data.groupby('model').agg({\n",
    "        pred:  list,\n",
    "        label: [list, 'mean']\n",
    "    }).reset_index()\n",
    "    data_agg.columns = ['_'.join(col).strip() for col in data_agg.columns]\n",
    "    nrmse_score = []\n",
    "    for raw in data_agg[['{0}_list'.format(pred), '{0}_list'.format(label), '{0}_mean'.format(label)]].values:\n",
    "        nrmse_score.append(\n",
    "            mse(raw[0], raw[1]) ** 0.5 / raw[2]\n",
    "        )\n",
    "    print(1 - np.mean(nrmse_score))\n",
    "    return 1 - np.mean(nrmse_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_type(train_x,train_y,valid_x,valid_y,m_type='lgb'):   \n",
    "    if m_type == 'lgb':\n",
    "        model = lgb.LGBMRegressor(\n",
    "                                num_leaves=2**5-1, reg_alpha=0.25, reg_lambda=0.25, objective='mse',\n",
    "                                max_depth=-1, learning_rate=0.01, min_child_samples=5, random_state=500,\n",
    "                                n_estimators=2000, subsample=0.9, colsample_bytree=0.7,\n",
    "                                )\n",
    "        model.fit(train_x, train_y, \n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)], \n",
    "              categorical_feature=cate_feat, \n",
    "              early_stopping_rounds=100, verbose=100)      \n",
    "    elif m_type == 'xgb':\n",
    "        model = xgb.XGBRegressor(\n",
    "                                max_depth=5 , learning_rate=0.01, n_estimators=4000, \n",
    "                                objective='reg:gamma', tree_method = 'hist',subsample=0.9, \n",
    "                                colsample_bytree=0.7, min_child_samples=5,eval_metric = 'rmse' \n",
    "                                )\n",
    "        model.fit(train_x, train_y, \n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)], \n",
    "              early_stopping_rounds=100, verbose=100)   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_model(df_, m, m_type):\n",
    "    df = df_.copy()\n",
    "    # 数据集划分\n",
    "    st = 9\n",
    "    all_idx   = (df['mt'].between(st , m-1))\n",
    "    train_idx = (df['mt'].between(st , m-5))\n",
    "    valid_idx = (df['mt'].between(m-4, m-4))\n",
    "    test_idx  = (df['mt'].between(m  , m  ))\n",
    "    \n",
    "    print('all_idx  :',st ,m-1)\n",
    "    print('train_idx:',st ,m-5)\n",
    "    print('valid_idx:',m-4,m-4)\n",
    "    print('test_idx :',m  ,m  )  \n",
    "    # 最终确认\n",
    "    train_x = df[train_idx][features]\n",
    "    train_y = df[train_idx]['label']\n",
    "    valid_x = df[valid_idx][features]\n",
    "    valid_y = df[valid_idx]['label']   \n",
    "    # get model\n",
    "    model = get_model_type(train_x,train_y,valid_x,valid_y,m_type)  \n",
    "    # offline\n",
    "    df['pred_label'] = model.predict(df[features])\n",
    "    best_score = valid_score(df[valid_idx]) \n",
    "    # online\n",
    "    if m_type == 'lgb':\n",
    "        model.n_estimators = model.best_iteration_ + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'], categorical_feature=cate_feat)\n",
    "    elif m_type == 'xgb':\n",
    "        model.n_estimators = model.best_iteration + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'])\n",
    "    df['forecastVolum'] = model.predict(df[features]) \n",
    "    print('valid mean:',df[valid_idx]['pred_label'].mean())\n",
    "    print('true  mean:',df[valid_idx]['label'].mean())\n",
    "    print('test  mean:',df[test_idx]['forecastVolum'].mean())\n",
    "    # 阶段结果\n",
    "    sub = df[test_idx][['id']]\n",
    "    sub['forecastVolum'] = df[test_idx]['forecastVolum'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    print(sub.shape)\n",
    "    return sub,df[valid_idx]['pred_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 29\n",
      "all_idx  : 9 20\n",
      "train_idx: 9 16\n",
      "valid_idx: 17 17\n",
      "test_idx : 21 21\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 128712\tvalid_1's l2: 98700.9\n",
      "[200]\ttraining's l2: 41958.5\tvalid_1's l2: 38841.5\n",
      "[300]\ttraining's l2: 23711.2\tvalid_1's l2: 28937.2\n",
      "[400]\ttraining's l2: 17316.6\tvalid_1's l2: 26511.4\n",
      "[500]\ttraining's l2: 13789.8\tvalid_1's l2: 25838.3\n",
      "[600]\ttraining's l2: 11344.6\tvalid_1's l2: 25413.5\n",
      "[700]\ttraining's l2: 9716.53\tvalid_1's l2: 25005.3\n",
      "[800]\ttraining's l2: 8521.85\tvalid_1's l2: 24786.1\n",
      "[900]\ttraining's l2: 7601.14\tvalid_1's l2: 24786.9\n",
      "[1000]\ttraining's l2: 6807.82\tvalid_1's l2: 24710.5\n",
      "[1100]\ttraining's l2: 6154.66\tvalid_1's l2: 24588.3\n",
      "[1200]\ttraining's l2: 5603.01\tvalid_1's l2: 24436.2\n",
      "[1300]\ttraining's l2: 5128.15\tvalid_1's l2: 24299.6\n",
      "[1400]\ttraining's l2: 4756.47\tvalid_1's l2: 24098.7\n",
      "[1500]\ttraining's l2: 4411.44\tvalid_1's l2: 23997.3\n",
      "[1600]\ttraining's l2: 4081.94\tvalid_1's l2: 23915.1\n",
      "[1700]\ttraining's l2: 3801.56\tvalid_1's l2: 23785.2\n",
      "[1800]\ttraining's l2: 3551.93\tvalid_1's l2: 23733.7\n",
      "[1900]\ttraining's l2: 3322.77\tvalid_1's l2: 23685.3\n",
      "[2000]\ttraining's l2: 3105.34\tvalid_1's l2: 23583.8\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's l2: 3105.34\tvalid_1's l2: 23583.8\n",
      "0.7973272983520384\n",
      "valid mean: 497.2429189926641\n",
      "true  mean: 534.5318181818182\n",
      "test  mean: 641.6628984132291\n",
      "(1320, 2)\n",
      "---\n",
      "(0, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 29\n",
      "all_idx  : 9 21\n",
      "train_idx: 9 17\n",
      "valid_idx: 18 18\n",
      "test_idx : 22 22\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 124896\tvalid_1's l2: 101622\n",
      "[200]\ttraining's l2: 41221.5\tvalid_1's l2: 40668.4\n",
      "[300]\ttraining's l2: 23551.2\tvalid_1's l2: 30796.4\n",
      "[400]\ttraining's l2: 17247.5\tvalid_1's l2: 28629.1\n",
      "[500]\ttraining's l2: 13644.1\tvalid_1's l2: 28447.5\n",
      "[600]\ttraining's l2: 11311.3\tvalid_1's l2: 28214.8\n",
      "[700]\ttraining's l2: 9665.8\tvalid_1's l2: 28306.6\n",
      "Early stopping, best iteration is:\n",
      "[602]\ttraining's l2: 11275.5\tvalid_1's l2: 28202.4\n",
      "0.7483585609319627\n",
      "valid mean: 547.3275192104005\n",
      "true  mean: 523.3159090909091\n",
      "test  mean: 648.8015280661291\n",
      "(1320, 2)\n",
      "---\n",
      "(0, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 29\n",
      "all_idx  : 9 22\n",
      "train_idx: 9 18\n",
      "valid_idx: 19 19\n",
      "test_idx : 23 23\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 121129\tvalid_1's l2: 101400\n",
      "[200]\ttraining's l2: 40304.7\tvalid_1's l2: 38675.6\n",
      "[300]\ttraining's l2: 23218.8\tvalid_1's l2: 27340.3\n",
      "[400]\ttraining's l2: 17179.7\tvalid_1's l2: 24853.9\n",
      "[500]\ttraining's l2: 13713.1\tvalid_1's l2: 23959.2\n",
      "[600]\ttraining's l2: 11471.2\tvalid_1's l2: 23400.8\n",
      "[700]\ttraining's l2: 9962.11\tvalid_1's l2: 22931.2\n",
      "[800]\ttraining's l2: 8881.21\tvalid_1's l2: 22567.1\n",
      "[900]\ttraining's l2: 8007.93\tvalid_1's l2: 22383.6\n",
      "[1000]\ttraining's l2: 7299.37\tvalid_1's l2: 22289.3\n",
      "[1100]\ttraining's l2: 6668.06\tvalid_1's l2: 22270.3\n",
      "[1200]\ttraining's l2: 6149.12\tvalid_1's l2: 22150.4\n",
      "Early stopping, best iteration is:\n",
      "[1196]\ttraining's l2: 6170.05\tvalid_1's l2: 22128.1\n",
      "0.7468931536269028\n",
      "valid mean: 560.7094271141314\n",
      "true  mean: 552.2295454545455\n",
      "test  mean: 734.8046071367794\n",
      "(1320, 2)\n",
      "---\n",
      "(0, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 29\n",
      "all_idx  : 9 23\n",
      "train_idx: 9 19\n",
      "valid_idx: 20 20\n",
      "test_idx : 24 24\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 118772\tvalid_1's l2: 145395\n",
      "[200]\ttraining's l2: 39386.3\tvalid_1's l2: 51071.7\n",
      "[300]\ttraining's l2: 22711.1\tvalid_1's l2: 32006.2\n",
      "[400]\ttraining's l2: 17040\tvalid_1's l2: 27020.4\n",
      "[500]\ttraining's l2: 13774.6\tvalid_1's l2: 25125.4\n",
      "[600]\ttraining's l2: 11675.5\tvalid_1's l2: 24421\n",
      "[700]\ttraining's l2: 10208\tvalid_1's l2: 24129.7\n",
      "[800]\ttraining's l2: 9205.22\tvalid_1's l2: 23964.6\n",
      "[900]\ttraining's l2: 8388.5\tvalid_1's l2: 23799.9\n",
      "[1000]\ttraining's l2: 7727.56\tvalid_1's l2: 23768.7\n",
      "Early stopping, best iteration is:\n",
      "[989]\ttraining's l2: 7801.96\tvalid_1's l2: 23734.8\n",
      "0.7917019686244774\n",
      "valid mean: 595.4352742803294\n",
      "true  mean: 620.0212121212121\n",
      "test  mean: 856.408786058386\n",
      "(1320, 2)\n",
      "---\n",
      "(0, 18)\n",
      "0.6405395240072211\n"
     ]
    }
   ],
   "source": [
    "for month in [21,22,23,24]: \n",
    "    m_type = 'lgb' \n",
    "    \n",
    "    data_df, stat_feat = get_stat_feature(data)\n",
    "    \n",
    "    num_feat = ['regYear','regMonth'] + stat_feat\n",
    "    cate_feat = ['adcode','bodyType','model']\n",
    "    \n",
    "    if m_type == 'lgb':\n",
    "        for i in cate_feat:\n",
    "            data_df[i] = data_df[i].astype('category')\n",
    "    elif m_type == 'xgb':\n",
    "        lbl = LabelEncoder()  \n",
    "        for i in tqdm(cate_feat):\n",
    "            data_df[i] = lbl.fit_transform(data_df[i].astype(str))\n",
    "           \n",
    "    features = num_feat + cate_feat\n",
    "    print(len(features), len(set(features)))   \n",
    "    \n",
    "    sub,val_pred = get_train_model(data_df, month, m_type)\n",
    "    online_test_idx  = (data_df['mt'].between(21  , 24  ))\n",
    "    print(\"---\")\n",
    "    print(data.loc[(data.regMonth==month)].shape)\n",
    "    data.loc[(data.mt==month), 'salesVolume'   ] = sub['forecastVolum'].values\n",
    "    data.loc[(data.mt==(month)), 'label'      ] = sub['forecastVolum'].values\n",
    "    data.loc[(data.mt==(month)), 'pred_label'      ] = sub['forecastVolum'].values\n",
    "# sub = data.loc[(data.regMonth>=1)&(data.regYear==2018), ['id','salesVolume']]\n",
    "# sub.columns = ['id','forecastVolum']\n",
    "# sub[['id','forecastVolum']].round().astype(int).to_csv('submit/yulao_lgb.csv', index=False)\n",
    "best_score = online_score(data[online_test_idx]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.42s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 15.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 53\n",
      "all_idx  : 13 24\n",
      "train_idx: 13 20\n",
      "valid_idx: 21 21\n",
      "test_idx : 25 25\n",
      "[0]\tvalidation_0-rmse:841.387\tvalidation_1-rmse:1046.81\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:840.854\tvalidation_1-rmse:1046.28\n",
      "[200]\tvalidation_0-rmse:839.416\tvalidation_1-rmse:1044.83\n",
      "[300]\tvalidation_0-rmse:835.586\tvalidation_1-rmse:1040.97\n",
      "[400]\tvalidation_0-rmse:825.694\tvalidation_1-rmse:1030.91\n",
      "[500]\tvalidation_0-rmse:801.738\tvalidation_1-rmse:1006.18\n",
      "[600]\tvalidation_0-rmse:750.162\tvalidation_1-rmse:951.587\n",
      "[700]\tvalidation_0-rmse:657.192\tvalidation_1-rmse:849.31\n",
      "[800]\tvalidation_0-rmse:524.723\tvalidation_1-rmse:696.311\n",
      "[900]\tvalidation_0-rmse:380.162\tvalidation_1-rmse:522.151\n",
      "[1000]\tvalidation_0-rmse:259.234\tvalidation_1-rmse:376.202\n",
      "[1100]\tvalidation_0-rmse:179.886\tvalidation_1-rmse:282.214\n",
      "[1200]\tvalidation_0-rmse:145.639\tvalidation_1-rmse:248.148\n",
      "[1300]\tvalidation_0-rmse:132.764\tvalidation_1-rmse:236.328\n",
      "[1400]\tvalidation_0-rmse:123.956\tvalidation_1-rmse:229.286\n",
      "[1500]\tvalidation_0-rmse:117.525\tvalidation_1-rmse:225.476\n",
      "[1600]\tvalidation_0-rmse:112.077\tvalidation_1-rmse:222.002\n",
      "[1700]\tvalidation_0-rmse:108.012\tvalidation_1-rmse:219.62\n",
      "[1800]\tvalidation_0-rmse:105.329\tvalidation_1-rmse:218.541\n",
      "[1900]\tvalidation_0-rmse:102.6\tvalidation_1-rmse:216.826\n",
      "[2000]\tvalidation_0-rmse:100.224\tvalidation_1-rmse:215.662\n",
      "[2100]\tvalidation_0-rmse:98.22\tvalidation_1-rmse:215.319\n",
      "[2200]\tvalidation_0-rmse:96.532\tvalidation_1-rmse:215.243\n",
      "[2300]\tvalidation_0-rmse:95.2175\tvalidation_1-rmse:214.773\n",
      "[2400]\tvalidation_0-rmse:93.5902\tvalidation_1-rmse:213.994\n",
      "[2500]\tvalidation_0-rmse:92.0521\tvalidation_1-rmse:213.366\n",
      "[2600]\tvalidation_0-rmse:90.7138\tvalidation_1-rmse:212.787\n",
      "[2700]\tvalidation_0-rmse:89.3237\tvalidation_1-rmse:212.099\n",
      "[2800]\tvalidation_0-rmse:88.0724\tvalidation_1-rmse:211.505\n",
      "[2900]\tvalidation_0-rmse:86.8326\tvalidation_1-rmse:211.486\n",
      "[3000]\tvalidation_0-rmse:85.4657\tvalidation_1-rmse:210.631\n",
      "[3100]\tvalidation_0-rmse:84.0276\tvalidation_1-rmse:210.01\n",
      "[3200]\tvalidation_0-rmse:82.8386\tvalidation_1-rmse:209.758\n",
      "[3300]\tvalidation_0-rmse:81.721\tvalidation_1-rmse:209.527\n",
      "[3400]\tvalidation_0-rmse:80.6025\tvalidation_1-rmse:209.511\n",
      "[3500]\tvalidation_0-rmse:79.6226\tvalidation_1-rmse:208.998\n",
      "[3600]\tvalidation_0-rmse:78.5413\tvalidation_1-rmse:208.909\n",
      "[3700]\tvalidation_0-rmse:77.562\tvalidation_1-rmse:208.716\n",
      "[3800]\tvalidation_0-rmse:76.4457\tvalidation_1-rmse:208.448\n",
      "[3900]\tvalidation_0-rmse:75.3537\tvalidation_1-rmse:208.069\n",
      "[3999]\tvalidation_0-rmse:74.4427\tvalidation_1-rmse:208.153\n",
      "0.7704167529810075\n",
      "valid mean: 623.15094\n",
      "true  mean: 649.3121212121212\n",
      "test  mean: 458.79114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.34s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 12.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 53\n",
      "all_idx  : 13 25\n",
      "train_idx: 13 21\n",
      "valid_idx: 22 22\n",
      "test_idx : 26 26\n",
      "[0]\tvalidation_0-rmse:866.621\tvalidation_1-rmse:1007.38\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:866.089\tvalidation_1-rmse:1006.85\n",
      "[200]\tvalidation_0-rmse:864.653\tvalidation_1-rmse:1005.43\n",
      "[300]\tvalidation_0-rmse:860.828\tvalidation_1-rmse:1001.62\n",
      "[400]\tvalidation_0-rmse:850.935\tvalidation_1-rmse:991.753\n",
      "[500]\tvalidation_0-rmse:826.915\tvalidation_1-rmse:967.795\n",
      "[600]\tvalidation_0-rmse:774.935\tvalidation_1-rmse:915.746\n",
      "[700]\tvalidation_0-rmse:680.726\tvalidation_1-rmse:819.708\n",
      "[800]\tvalidation_0-rmse:544.976\tvalidation_1-rmse:682.224\n",
      "[900]\tvalidation_0-rmse:395.274\tvalidation_1-rmse:534.143\n",
      "[1000]\tvalidation_0-rmse:268.46\tvalidation_1-rmse:413.542\n",
      "[1100]\tvalidation_0-rmse:185.094\tvalidation_1-rmse:338.885\n",
      "[1200]\tvalidation_0-rmse:148.412\tvalidation_1-rmse:310.795\n",
      "[1300]\tvalidation_0-rmse:135.604\tvalidation_1-rmse:305.034\n",
      "[1400]\tvalidation_0-rmse:127.006\tvalidation_1-rmse:301.104\n",
      "[1500]\tvalidation_0-rmse:120.891\tvalidation_1-rmse:300.462\n",
      "Stopping. Best iteration:\n",
      "[1438]\tvalidation_0-rmse:124.346\tvalidation_1-rmse:300.103\n",
      "\n",
      "0.6135062378600542\n",
      "valid mean: 455.9764\n",
      "true  mean: 616.5537878787878\n",
      "test  mean: 287.6134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.28s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 11.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 53\n",
      "all_idx  : 13 26\n",
      "train_idx: 13 22\n",
      "valid_idx: 23 23\n",
      "test_idx : 27 27\n",
      "[0]\tvalidation_0-rmse:881.709\tvalidation_1-rmse:1071.9\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:881.177\tvalidation_1-rmse:1071.36\n",
      "[200]\tvalidation_0-rmse:879.744\tvalidation_1-rmse:1069.89\n",
      "[300]\tvalidation_0-rmse:875.924\tvalidation_1-rmse:1065.98\n",
      "[400]\tvalidation_0-rmse:866.039\tvalidation_1-rmse:1055.8\n",
      "[500]\tvalidation_0-rmse:842.007\tvalidation_1-rmse:1030.84\n",
      "[600]\tvalidation_0-rmse:789.895\tvalidation_1-rmse:975.336\n",
      "[700]\tvalidation_0-rmse:694.969\tvalidation_1-rmse:871.571\n",
      "[800]\tvalidation_0-rmse:557.798\tvalidation_1-rmse:716.699\n",
      "[900]\tvalidation_0-rmse:405.58\tvalidation_1-rmse:542.434\n",
      "[1000]\tvalidation_0-rmse:276.35\tvalidation_1-rmse:397.253\n",
      "[1100]\tvalidation_0-rmse:190.667\tvalidation_1-rmse:305.207\n",
      "[1200]\tvalidation_0-rmse:154.971\tvalidation_1-rmse:271.795\n",
      "[1300]\tvalidation_0-rmse:140.976\tvalidation_1-rmse:261.29\n",
      "[1400]\tvalidation_0-rmse:131.097\tvalidation_1-rmse:253.97\n",
      "[1500]\tvalidation_0-rmse:123.573\tvalidation_1-rmse:249.8\n",
      "[1600]\tvalidation_0-rmse:117.466\tvalidation_1-rmse:246.017\n",
      "[1700]\tvalidation_0-rmse:113.772\tvalidation_1-rmse:243.643\n",
      "[1800]\tvalidation_0-rmse:110.041\tvalidation_1-rmse:242.037\n",
      "[1900]\tvalidation_0-rmse:106.974\tvalidation_1-rmse:240.72\n",
      "[2000]\tvalidation_0-rmse:104.46\tvalidation_1-rmse:240.411\n",
      "[2100]\tvalidation_0-rmse:102.371\tvalidation_1-rmse:240.26\n",
      "[2200]\tvalidation_0-rmse:100.264\tvalidation_1-rmse:239.565\n",
      "[2300]\tvalidation_0-rmse:98.5715\tvalidation_1-rmse:239.589\n",
      "[2400]\tvalidation_0-rmse:97.1418\tvalidation_1-rmse:239.243\n",
      "[2500]\tvalidation_0-rmse:95.5244\tvalidation_1-rmse:238.933\n",
      "[2600]\tvalidation_0-rmse:94.227\tvalidation_1-rmse:238.502\n",
      "[2700]\tvalidation_0-rmse:92.788\tvalidation_1-rmse:238.087\n",
      "Stopping. Best iteration:\n",
      "[2684]\tvalidation_0-rmse:93.0052\tvalidation_1-rmse:237.949\n",
      "\n",
      "0.7218989650293122\n",
      "valid mean: 568.9693\n",
      "true  mean: 673.0143939393939\n",
      "test  mean: 337.8751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.29s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 53\n",
      "all_idx  : 13 27\n",
      "train_idx: 13 23\n",
      "valid_idx: 24 24\n",
      "test_idx : 28 28\n",
      "[0]\tvalidation_0-rmse:900.66\tvalidation_1-rmse:1451.31\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:900.128\tvalidation_1-rmse:1450.78\n",
      "[200]\tvalidation_0-rmse:898.694\tvalidation_1-rmse:1449.33\n",
      "[300]\tvalidation_0-rmse:894.87\tvalidation_1-rmse:1445.44\n",
      "[400]\tvalidation_0-rmse:884.963\tvalidation_1-rmse:1435.29\n",
      "[500]\tvalidation_0-rmse:860.829\tvalidation_1-rmse:1410.04\n",
      "[600]\tvalidation_0-rmse:808.295\tvalidation_1-rmse:1353.21\n",
      "[700]\tvalidation_0-rmse:712.128\tvalidation_1-rmse:1245.94\n",
      "[800]\tvalidation_0-rmse:572.214\tvalidation_1-rmse:1087.8\n",
      "[900]\tvalidation_0-rmse:415.731\tvalidation_1-rmse:924.84\n",
      "[1000]\tvalidation_0-rmse:282.041\tvalidation_1-rmse:806.888\n",
      "[1100]\tvalidation_0-rmse:193.642\tvalidation_1-rmse:738.259\n",
      "[1200]\tvalidation_0-rmse:155.982\tvalidation_1-rmse:712.916\n",
      "[1300]\tvalidation_0-rmse:143.821\tvalidation_1-rmse:711.15\n",
      "Stopping. Best iteration:\n",
      "[1263]\tvalidation_0-rmse:147.131\tvalidation_1-rmse:709.407\n",
      "\n",
      "0.41897786888760846\n",
      "valid mean: 498.20517\n",
      "true  mean: 899.8204545454546\n",
      "test  mean: 324.48294\n"
     ]
    }
   ],
   "source": [
    "for month in [25,26,27,28]: \n",
    "    m_type = 'xgb' \n",
    "    \n",
    "    data_df, stat_feat = get_stat_feature(data)\n",
    "    \n",
    "    num_feat = ['regYear'] + stat_feat\n",
    "    cate_feat = ['adcode','bodyType','model','regMonth']\n",
    "    \n",
    "    if m_type == 'lgb':\n",
    "        for i in cate_feat:\n",
    "            data_df[i] = data_df[i].astype('category')\n",
    "    elif m_type == 'xgb':\n",
    "        lbl = LabelEncoder()  \n",
    "        for i in tqdm(cate_feat):\n",
    "            data_df[i] = lbl.fit_transform(data_df[i].astype(str))\n",
    "           \n",
    "    features = num_feat + cate_feat\n",
    "    print(len(features), len(set(features)))   \n",
    "    \n",
    "    sub,val_pred = get_train_model(data_df, month, m_type)   \n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'salesVolume'] = sub['forecastVolum'].values\n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'label'      ] = sub['forecastVolum'].values\t\n",
    "sub = data.loc[(data.regMonth>=1)&(data.regYear==2018), ['id','salesVolume']]\n",
    "sub.columns = ['id','forecastVolum']\n",
    "sub[['id','forecastVolum']].round().astype(int).to_csv('submit/yulao_xgb.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_idx  : 13 24\n",
      "train_idx: 13 20\n",
      "valid_idx: 21 21\n",
      "test_idx : 25 25\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 86584.9\tvalid_1's l2: 151719\n",
      "[200]\ttraining's l2: 27784.3\tvalid_1's l2: 71704.5\n",
      "[300]\ttraining's l2: 14902.5\tvalid_1's l2: 57361.3\n",
      "[400]\ttraining's l2: 10243.5\tvalid_1's l2: 52224.7\n",
      "[500]\ttraining's l2: 7869.38\tvalid_1's l2: 50304.7\n",
      "[600]\ttraining's l2: 6385.06\tvalid_1's l2: 49569.7\n",
      "[700]\ttraining's l2: 5380.65\tvalid_1's l2: 48911.9\n",
      "[800]\ttraining's l2: 4634.41\tvalid_1's l2: 48274\n",
      "[900]\ttraining's l2: 4071.47\tvalid_1's l2: 48026.2\n",
      "[1000]\ttraining's l2: 3625\tvalid_1's l2: 47641.9\n",
      "[1100]\ttraining's l2: 3253.2\tvalid_1's l2: 47425.4\n",
      "[1200]\ttraining's l2: 2928.61\tvalid_1's l2: 47143.3\n",
      "[1300]\ttraining's l2: 2653.04\tvalid_1's l2: 46870.8\n",
      "[1400]\ttraining's l2: 2414.07\tvalid_1's l2: 46669.9\n",
      "[1500]\ttraining's l2: 2207.68\tvalid_1's l2: 46487.6\n",
      "[1600]\ttraining's l2: 2028.06\tvalid_1's l2: 46336.7\n",
      "[1700]\ttraining's l2: 1876.96\tvalid_1's l2: 46208.4\n",
      "[1800]\ttraining's l2: 1749.37\tvalid_1's l2: 46176.2\n",
      "[1900]\ttraining's l2: 1632.35\tvalid_1's l2: 46079.2\n",
      "[2000]\ttraining's l2: 1525.02\tvalid_1's l2: 46029.5\n",
      "[2100]\ttraining's l2: 1420.06\tvalid_1's l2: 45984.2\n",
      "[2200]\ttraining's l2: 1322.58\tvalid_1's l2: 45885.2\n",
      "Early stopping, best iteration is:\n",
      "[2188]\ttraining's l2: 1333.16\tvalid_1's l2: 45878\n",
      "0.7657263463789578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_idx  : 13 25\n",
      "train_idx: 13 21\n",
      "valid_idx: 22 22\n",
      "test_idx : 26 26\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 90083.5\tvalid_1's l2: 118412\n",
      "[200]\ttraining's l2: 28475.8\tvalid_1's l2: 59906.1\n",
      "[300]\ttraining's l2: 15309.6\tvalid_1's l2: 52080.3\n",
      "[400]\ttraining's l2: 10785.7\tvalid_1's l2: 50404.3\n",
      "[500]\ttraining's l2: 8324.54\tvalid_1's l2: 49632.1\n",
      "[600]\ttraining's l2: 6828.3\tvalid_1's l2: 49046.4\n",
      "[700]\ttraining's l2: 5813.9\tvalid_1's l2: 48997.8\n",
      "Early stopping, best iteration is:\n",
      "[648]\ttraining's l2: 6301.83\tvalid_1's l2: 48762.4\n",
      "0.7352932759641437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_idx  : 13 26\n",
      "train_idx: 13 22\n",
      "valid_idx: 23 23\n",
      "test_idx : 27 27\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 93591.6\tvalid_1's l2: 135289\n",
      "[200]\ttraining's l2: 29582.9\tvalid_1's l2: 52574.8\n",
      "[300]\ttraining's l2: 15864.8\tvalid_1's l2: 39181.2\n",
      "[400]\ttraining's l2: 11154.7\tvalid_1's l2: 36023.5\n",
      "[500]\ttraining's l2: 8739.67\tvalid_1's l2: 35331.5\n",
      "[600]\ttraining's l2: 7173.39\tvalid_1's l2: 34526.5\n",
      "[700]\ttraining's l2: 6126.06\tvalid_1's l2: 34402.5\n",
      "[800]\ttraining's l2: 5347.97\tvalid_1's l2: 34349\n",
      "[900]\ttraining's l2: 4770.82\tvalid_1's l2: 34426\n",
      "Early stopping, best iteration is:\n",
      "[806]\ttraining's l2: 5308.31\tvalid_1's l2: 34325.1\n",
      "0.7811424903161602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_idx  : 13 27\n",
      "train_idx: 13 23\n",
      "valid_idx: 24 24\n",
      "test_idx : 28 28\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 96023.9\tvalid_1's l2: 552065\n",
      "[200]\ttraining's l2: 29709.3\tvalid_1's l2: 354551\n",
      "[300]\ttraining's l2: 16067.9\tvalid_1's l2: 299015\n",
      "[400]\ttraining's l2: 11490.5\tvalid_1's l2: 282547\n",
      "[500]\ttraining's l2: 9067.98\tvalid_1's l2: 274322\n",
      "[600]\ttraining's l2: 7522.51\tvalid_1's l2: 271372\n",
      "[700]\ttraining's l2: 6477.28\tvalid_1's l2: 271395\n",
      "Early stopping, best iteration is:\n",
      "[658]\ttraining's l2: 6879.88\tvalid_1's l2: 270441\n",
      "0.6226761089064834\n"
     ]
    }
   ],
   "source": [
    "for month in [25,26,27,28]: \n",
    "    m_type = 'lgb' \n",
    "    \n",
    "    data_df, stat_feat = get_stat_feature(data)\n",
    "    \n",
    "    num_feat = ['regYear','regMonth','popularity'] + stat_feat\n",
    "    cate_feat = ['adcode','bodyType','model']\n",
    "    \n",
    "    if m_type == 'lgb':\n",
    "        for i in cate_feat:\n",
    "            data_df[i] = data_df[i].astype('category')\n",
    "    elif m_type == 'xgb':\n",
    "        lbl = LabelEncoder()  \n",
    "        for i in tqdm(cate_feat):\n",
    "            data_df[i] = lbl.fit_transform(data_df[i].astype(str))\n",
    "           \n",
    "    features = num_feat + cate_feat\n",
    "#     print(len(features), len(set(features)))   \n",
    "    \n",
    "    sub,val_pred = get_train_model(data_df, month, m_type)   \n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'salesVolume'] = sub['forecastVolum'].values\n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'label'      ] = sub['forecastVolum'].values\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "sub = data.loc[(data.regMonth>=1)&(data.regYear==2018), ['id','salesVolume']]\n",
    "sub.columns = ['id','forecastVolum']\n",
    "# sub[['id','forecastVolum']].round().astype(int).to_csv('CCF_sales.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[['id','forecastVolum']].round().astype(int).to_csv('CCF_sales0914.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 53\n",
      "all_idx  : 13 24\n",
      "train_idx: 13 20\n",
      "valid_idx: 21 21\n",
      "test_idx : 25 25\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 7291.26\tvalid_1's l2: 37932.3\n",
      "[200]\ttraining's l2: 3715.93\tvalid_1's l2: 35716.9\n",
      "[300]\ttraining's l2: 2515.27\tvalid_1's l2: 35194.8\n",
      "[400]\ttraining's l2: 1831.38\tvalid_1's l2: 34788.8\n",
      "[500]\ttraining's l2: 1397.64\tvalid_1's l2: 34608.6\n",
      "[600]\ttraining's l2: 1065.51\tvalid_1's l2: 34527.1\n",
      "[700]\ttraining's l2: 849.095\tvalid_1's l2: 34415.2\n",
      "[800]\ttraining's l2: 679.238\tvalid_1's l2: 34333.1\n",
      "[900]\ttraining's l2: 545.247\tvalid_1's l2: 34326.4\n",
      "Early stopping, best iteration is:\n",
      "[838]\ttraining's l2: 624.086\tvalid_1's l2: 34316.6\n",
      "0.7559303097480222\n",
      "valid mean: 602.8972278482273\n",
      "true  mean: 649.3121212121212\n",
      "test  mean: 493.9801201875369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 53\n",
      "all_idx  : 13 25\n",
      "train_idx: 13 21\n",
      "valid_idx: 22 22\n",
      "test_idx : 26 26\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 7936.91\tvalid_1's l2: 41558.5\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's l2: 10761.5\tvalid_1's l2: 41117.3\n",
      "0.7414955122487169\n",
      "valid mean: 623.4500376146684\n",
      "true  mean: 616.5537878787878\n",
      "test  mean: 324.6451813135614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 53\n",
      "all_idx  : 13 26\n",
      "train_idx: 13 22\n",
      "valid_idx: 23 23\n",
      "test_idx : 27 27\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 8653.84\tvalid_1's l2: 32560.4\n",
      "[200]\ttraining's l2: 4627.91\tvalid_1's l2: 32133.2\n",
      "Early stopping, best iteration is:\n",
      "[155]\ttraining's l2: 5757.15\tvalid_1's l2: 31853.4\n",
      "0.7794578141087838\n",
      "valid mean: 639.6227869473659\n",
      "true  mean: 673.0143939393939\n",
      "test  mean: 479.55100257280156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 53\n",
      "all_idx  : 13 27\n",
      "train_idx: 13 23\n",
      "valid_idx: 24 24\n",
      "test_idx : 28 28\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 9306.24\tvalid_1's l2: 302435\n",
      "[200]\ttraining's l2: 5107.21\tvalid_1's l2: 292129\n",
      "[300]\ttraining's l2: 3583.18\tvalid_1's l2: 289373\n",
      "[400]\ttraining's l2: 2709.06\tvalid_1's l2: 288389\n",
      "[500]\ttraining's l2: 2162.77\tvalid_1's l2: 287983\n",
      "[600]\ttraining's l2: 1746.75\tvalid_1's l2: 287504\n",
      "[700]\ttraining's l2: 1446.22\tvalid_1's l2: 287029\n",
      "[800]\ttraining's l2: 1196.94\tvalid_1's l2: 286429\n",
      "[900]\ttraining's l2: 1008.26\tvalid_1's l2: 286030\n",
      "Early stopping, best iteration is:\n",
      "[856]\ttraining's l2: 1089.91\tvalid_1's l2: 286004\n",
      "0.588139278724323\n",
      "valid mean: 645.3917897243205\n",
      "true  mean: 899.8204545454546\n",
      "test  mean: 468.0356962498267\n"
     ]
    }
   ],
   "source": [
    "for month in [25,26,27,28]: \n",
    "    m_type = 'lgb' \n",
    "    \n",
    "    data_df, stat_feat = get_stat_feature(data)\n",
    "    \n",
    "    num_feat = ['regYear'] + stat_feat\n",
    "    cate_feat = ['adcode','bodyType','model','regMonth']\n",
    "    \n",
    "    if m_type == 'lgb':\n",
    "        for i in cate_feat:\n",
    "            data_df[i] = data_df[i].astype('category')\n",
    "    elif m_type == 'xgb':\n",
    "        lbl = LabelEncoder()  \n",
    "        for i in tqdm(cate_feat):\n",
    "            data_df[i] = lbl.fit_transform(data_df[i].astype(str))\n",
    "           \n",
    "    features = num_feat + cate_feat\n",
    "    print(len(features), len(set(features)))   \n",
    "    \n",
    "    sub,val_pred = get_train_model(data_df, month, m_type)   \n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'salesVolume'] = sub['forecastVolum'].values\n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'label'      ] = sub['forecastVolum'].values\n",
    "sub = data.loc[(data.regMonth>=1)&(data.regYear==2018), ['id','salesVolume']]\n",
    "sub.columns = ['id','forecastVolum']\n",
    "# sub[['id','forecastVolum']].round().astype(int).to_csv('CCF_sales.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
