{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SALES_DATA_PATH = \"data/train_sales_data.csv\"\n",
    "TRAIN_SEARCH_DATA_PATH = \"data/train_search_data.csv\"\n",
    "TRAIN_USER_REPLY_DATA_PATH = \"data/train_user_reply_data.csv\"\n",
    "TEST_PATH = \"data/evaluation_public.csv\"\n",
    "\n",
    "# import re\n",
    "# import gc\n",
    "# import os\n",
    "# import csv\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook, trange\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "# import catboost as cb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df, data_type):\n",
    "    if data_type == \"train\":\n",
    "        return df[df.regYear == 2016]\n",
    "    elif data_type == \"test\":\n",
    "        return df[df.regYear == 2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sales = pd.read_csv(TRAIN_SALES_DATA_PATH)\n",
    "train_search = pd.read_csv(TRAIN_SEARCH_DATA_PATH)\n",
    "train_user = pd.read_csv(TRAIN_USER_REPLY_DATA_PATH)\n",
    "test_data = pd.read_csv(TEST_PATH)\n",
    "\n",
    "train_sales.salesVolume = train_sales.salesVolume.apply(lambda x: np.log(1+x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征工程\n",
    "def cal_basic_fea(df:pd.DataFrame, cal_col:str, stat_dim:list, data_type:str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    计算原始特征、周期特征、趋势特征\n",
    "    \"\"\"\n",
    "    train_sales_data = get_data(train_sales, data_type)\n",
    "\n",
    "    name_prefix = \"_\".join(stat_dim) + \"_%s\"%cal_col\n",
    "    drop_name = \"level_%d\"%len(stat_dim)\n",
    "\n",
    "    # 原始特征\n",
    "    feature_data = train_sales_data.groupby(stat_dim)[cal_col].apply(lambda x: x.sum()).unstack(level=-1)\n",
    "    feature_data.columns = [name_prefix + \"_%d\"%x for x in feature_data.columns.ravel()]\n",
    "    feature_data = feature_data.reset_index()\n",
    "\n",
    "    # 周期特征\n",
    "    ## shift_div\n",
    "    tmp_df = train_sales_data.groupby(stat_dim)[cal_col].apply(lambda x: x.sum()).groupby(stat_dim[:-1]).apply(lambda x: x / x.shift(1)).reset_index()\n",
    "\n",
    "    tmp_df = tmp_df.rename(columns={\"salesVolume\":\"shift_div\"})\n",
    "\n",
    "    train_sales_data = pd.merge(train_sales_data, tmp_df, on=stat_dim, how=\"left\")\n",
    "\n",
    "    tmp_df = train_sales_data.dropna().groupby(stat_dim).shift_div.apply(lambda x: x.sum()).unstack(level=-1)\n",
    "\n",
    "    tmp_df.columns = [name_prefix + \"_shift_div_%d\"%x for x in tmp_df.columns.ravel()]\n",
    "\n",
    "    feature_data = pd.merge(feature_data, tmp_df, on=stat_dim[:-1], how=\"left\")\n",
    "\n",
    "    ## shift_sub\n",
    "    tmp_df = train_sales_data.groupby(stat_dim)[cal_col].apply(lambda x: x.sum()).groupby(stat_dim[:-1]).apply(lambda x: x - x.shift(1)).reset_index()\n",
    "\n",
    "    tmp_df = tmp_df.rename(columns={\"salesVolume\":\"shift_sub\"})\n",
    "\n",
    "    train_sales_data = pd.merge(train_sales_data, tmp_df, on=stat_dim, how=\"left\")\n",
    "\n",
    "    tmp_df = train_sales_data.dropna().groupby(stat_dim).shift_sub.apply(lambda x: x.sum()).unstack(level=-1)\n",
    "\n",
    "    tmp_df.columns = [name_prefix + \"_shift_sub_%d\"%x for x in tmp_df.columns.ravel()]\n",
    "\n",
    "    feature_data = pd.merge(feature_data, tmp_df, on=stat_dim[:-1], how=\"left\")\n",
    "\n",
    "    # 趋势特征\n",
    "    ## shift_div\n",
    "    tmp_df = train_sales_data.groupby(stat_dim)[\"shift_div\"].apply(lambda x: x.sum()).groupby(stat_dim[:-1]).apply(lambda x: x / x.shift(1)).reset_index()\n",
    "\n",
    "    tmp_df = tmp_df.rename(columns={\"shift_div\":\"shift_2_div\"})\n",
    "\n",
    "    train_sales_data = pd.merge(train_sales_data, tmp_df, on=stat_dim, how=\"left\")\n",
    "\n",
    "    tmp_df = train_sales_data.dropna().groupby(stat_dim).shift_div.apply(lambda x: x.sum()).unstack(level=-1)\n",
    "\n",
    "    tmp_df.columns = [name_prefix + \"_shift_2_div_%d\"%x for x in tmp_df.columns.ravel()]\n",
    "\n",
    "    feature_data = pd.merge(feature_data, tmp_df, on=stat_dim[:-1], how=\"left\")\n",
    "\n",
    "    ## shift_sub\n",
    "    tmp_df = train_sales_data.groupby(stat_dim)[\"shift_sub\"].apply(lambda x: x.sum()).groupby(stat_dim[:-1]).apply(lambda x: x - x.shift(1)).reset_index()\n",
    "\n",
    "    tmp_df = tmp_df.rename(columns={\"shift_sub\":\"shift_2_sub\"})\n",
    "\n",
    "    train_sales_data = pd.merge(train_sales_data, tmp_df, on=stat_dim, how=\"left\")\n",
    "\n",
    "    tmp_df = train_sales_data.dropna().groupby(stat_dim).shift_sub.apply(lambda x: x.sum()).unstack(level=-1)\n",
    "\n",
    "    tmp_df.columns = [name_prefix + \"_shift_2_sub_%d\"%x for x in tmp_df.columns.ravel()]\n",
    "\n",
    "    feature_data = pd.merge(feature_data, tmp_df, on=stat_dim[:-1], how=\"left\")\n",
    "    return feature_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_windows_fea(df:pd.DataFrame, cal_col:str, stat_dim:list, data_type:str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    计算滑窗特征\n",
    "    \"\"\"\n",
    "    train_sales_data = get_data(df, data_type)\n",
    "\n",
    "    name_prefix = \"_\".join(stat_dim) + \"_%s\"%cal_col\n",
    "\n",
    "    # 滑窗特征\n",
    "    ## mean\n",
    "    feature_data = train_sales_data.groupby(stat_dim)[cal_col].apply(lambda x: x.sum()).groupby(stat_dim[:-1]).rolling(3).mean()\n",
    "\n",
    "    feature_data = feature_data.dropna().unstack(level=-1)\n",
    "\n",
    "    if len(stat_dim) == 3:\n",
    "        feature_data.index = feature_data.index.droplevel(0)\n",
    "        feature_data.index = feature_data.index.droplevel(0)\n",
    "    elif len(stat_dim) == 2:\n",
    "        feature_data.index = feature_data.index.droplevel(0)\n",
    "\n",
    "\n",
    "    feature_data.reset_index(inplace=True)\n",
    "    feature_data = feature_data.rename(columns={k:\"%s_rolling_mean_%d\"%(name_prefix, k) for k in range(13)})\n",
    "\n",
    "    ## std\n",
    "    tmp_df = train_sales_data.groupby(stat_dim)[cal_col].apply(lambda x: x.sum()).groupby(stat_dim[:-1]).rolling(3).std()\n",
    "\n",
    "    tmp_df = tmp_df.dropna().unstack(level=-1)\n",
    "\n",
    "    if len(stat_dim) == 3:\n",
    "        tmp_df.index = tmp_df.index.droplevel(0)\n",
    "        tmp_df.index = tmp_df.index.droplevel(0)\n",
    "    elif len(stat_dim) == 2:\n",
    "        tmp_df.index = tmp_df.index.droplevel(0)\n",
    "\n",
    "\n",
    "    tmp_df.reset_index(inplace=True)\n",
    "    tmp_df = tmp_df.rename(columns={k:\"%s_rolling_std_%d\"%(name_prefix, k) for k in range(13)})\n",
    "\n",
    "    feature_data = pd.merge(feature_data, tmp_df, on=stat_dim[:-1], how=\"left\")\n",
    "    \n",
    "    ## var\n",
    "    tmp_df = train_sales_data.groupby(stat_dim)[cal_col].apply(lambda x: x.sum()).groupby(stat_dim[:-1]).rolling(3).var()\n",
    "\n",
    "    tmp_df = tmp_df.dropna().unstack(level=-1)\n",
    "\n",
    "    if len(stat_dim) == 3:\n",
    "        tmp_df.index = tmp_df.index.droplevel(0)\n",
    "        tmp_df.index = tmp_df.index.droplevel(0)\n",
    "    elif len(stat_dim) == 2:\n",
    "        tmp_df.index = tmp_df.index.droplevel(0)\n",
    "\n",
    "\n",
    "    tmp_df.reset_index(inplace=True)\n",
    "    tmp_df = tmp_df.rename(columns={k:\"%s_rolling_std_%d\"%(name_prefix, k) for k in range(13)})\n",
    "\n",
    "    feature_data = pd.merge(feature_data, tmp_df, on=stat_dim[:-1], how=\"left\")\n",
    "    \n",
    "\n",
    "    ## sum\n",
    "    tmp_df = train_sales_data.groupby(stat_dim)[cal_col].apply(lambda x: x.sum()).groupby(stat_dim[:-1]).rolling(3).sum()\n",
    "\n",
    "    tmp_df = tmp_df.dropna().unstack(level=-1)\n",
    "\n",
    "    if len(stat_dim) == 3:\n",
    "        tmp_df.index = tmp_df.index.droplevel(0)\n",
    "        tmp_df.index = tmp_df.index.droplevel(0)\n",
    "    elif len(stat_dim) == 2:\n",
    "        tmp_df.index = tmp_df.index.droplevel(0)\n",
    "\n",
    "    tmp_df.reset_index(inplace=True)\n",
    "    tmp_df = tmp_df.rename(columns={k:\"%s_rolling_sum_%d\"%(name_prefix, k) for k in range(13)})\n",
    "\n",
    "    feature_data = pd.merge(feature_data, tmp_df, on=stat_dim[:-1], how=\"left\")\n",
    "    \n",
    "    # 滑窗特征2222222222222222\n",
    "    ## mean\n",
    "    feature_data = train_sales_data.groupby(stat_dim)[cal_col].apply(lambda x: x.sum()).groupby(stat_dim[:-1]).rolling(4).mean()\n",
    "\n",
    "    feature_data = feature_data.dropna().unstack(level=-1)\n",
    "\n",
    "    if len(stat_dim) == 3:\n",
    "        feature_data.index = feature_data.index.droplevel(0)\n",
    "        feature_data.index = feature_data.index.droplevel(0)\n",
    "    elif len(stat_dim) == 2:\n",
    "        feature_data.index = feature_data.index.droplevel(0)\n",
    "\n",
    "\n",
    "    feature_data.reset_index(inplace=True)\n",
    "    feature_data = feature_data.rename(columns={k:\"%s_rolling_mean_%d\"%(name_prefix, k) for k in range(13)})\n",
    "\n",
    "    ## std\n",
    "    tmp_df = train_sales_data.groupby(stat_dim)[cal_col].apply(lambda x: x.sum()).groupby(stat_dim[:-1]).rolling(4).std()\n",
    "\n",
    "    tmp_df = tmp_df.dropna().unstack(level=-1)\n",
    "\n",
    "    if len(stat_dim) == 3:\n",
    "        tmp_df.index = tmp_df.index.droplevel(0)\n",
    "        tmp_df.index = tmp_df.index.droplevel(0)\n",
    "    elif len(stat_dim) == 2:\n",
    "        tmp_df.index = tmp_df.index.droplevel(0)\n",
    "\n",
    "\n",
    "    tmp_df.reset_index(inplace=True)\n",
    "    tmp_df = tmp_df.rename(columns={k:\"%s_rolling_std_%d\"%(name_prefix, k) for k in range(13)})\n",
    "\n",
    "    feature_data = pd.merge(feature_data, tmp_df, on=stat_dim[:-1], how=\"left\")\n",
    "    \n",
    "\n",
    "\n",
    "    ## sum\n",
    "    tmp_df = train_sales_data.groupby(stat_dim)[cal_col].apply(lambda x: x.sum()).groupby(stat_dim[:-1]).rolling(4).sum()\n",
    "\n",
    "    tmp_df = tmp_df.dropna().unstack(level=-1)\n",
    "\n",
    "    if len(stat_dim) == 3:\n",
    "        tmp_df.index = tmp_df.index.droplevel(0)\n",
    "        tmp_df.index = tmp_df.index.droplevel(0)\n",
    "    elif len(stat_dim) == 2:\n",
    "        tmp_df.index = tmp_df.index.droplevel(0)\n",
    "\n",
    "    tmp_df.reset_index(inplace=True)\n",
    "    tmp_df = tmp_df.rename(columns={k:\"%s_rolling_sum_%d\"%(name_prefix, k) for k in range(13)})\n",
    "\n",
    "    feature_data = pd.merge(feature_data, tmp_df, on=stat_dim[:-1], how=\"left\")\n",
    "    return feature_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立车型与型号的对应字典\n",
    "model2type = train_sales[[\"model\", \"bodyType\"]].drop_duplicates().set_index(\"model\").to_dict()[\"bodyType\"]\n",
    "# 城市+车\n",
    "train_basic_fea = cal_basic_fea(train_sales, \"salesVolume\", [\"adcode\", \"model\", \"regMonth\"], \"train\")\n",
    "# 城市\n",
    "tmp_df = cal_basic_fea(train_sales, \"salesVolume\", [\"adcode\", \"regMonth\"], \"train\")\n",
    "train_basic_fea = pd.merge(train_basic_fea, tmp_df, on=\"adcode\", how=\"left\")\n",
    "# 车\n",
    "tmp_df = cal_basic_fea(train_sales, \"salesVolume\", [\"model\", \"regMonth\"], \"train\")\n",
    "train_basic_fea = pd.merge(train_basic_fea, tmp_df, on=\"model\", how=\"left\")\n",
    "# 城市+车型\n",
    "tmp_df = cal_basic_fea(train_sales, \"salesVolume\", [\"adcode\", \"bodyType\", \"regMonth\"], \"train\")\n",
    "train_basic_fea[\"bodyType\"] = train_basic_fea.model.apply(lambda x: model2type[x])\n",
    "train_basic_fea = pd.merge(train_basic_fea, tmp_df, on=[\"adcode\", \"bodyType\"], how=\"left\")\n",
    "\n",
    "\n",
    "# cal_windows_fea\n",
    "# 城市+车\n",
    "train_windows_fea = cal_windows_fea(train_sales, cal_col=\"salesVolume\", stat_dim=[\"adcode\", \"model\", \"regMonth\"], data_type=\"train\")\n",
    "# 城市\n",
    "tmp_df = cal_windows_fea(train_sales, \"salesVolume\", [\"adcode\", \"regMonth\"], \"train\")\n",
    "train_windows_fea = pd.merge(train_windows_fea, tmp_df, on=\"adcode\", how=\"left\")\n",
    "# 车\n",
    "tmp_df = cal_windows_fea(train_sales, \"salesVolume\", [\"model\", \"regMonth\"], \"train\")\n",
    "train_windows_fea = pd.merge(train_windows_fea, tmp_df, on=\"model\", how=\"left\")\n",
    "# 城市+车型\n",
    "tmp_df = cal_windows_fea(train_sales, \"salesVolume\", [\"adcode\", \"bodyType\", \"regMonth\"], \"train\")\n",
    "train_windows_fea[\"bodyType\"] = train_windows_fea.model.apply(lambda x: model2type[x])\n",
    "train_windows_fea = pd.merge(train_windows_fea, tmp_df, on=[\"adcode\", \"bodyType\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adcode</th>\n",
       "      <th>model</th>\n",
       "      <th>adcode_model_regMonth_salesVolume_1</th>\n",
       "      <th>adcode_model_regMonth_salesVolume_2</th>\n",
       "      <th>adcode_model_regMonth_salesVolume_3</th>\n",
       "      <th>adcode_model_regMonth_salesVolume_4</th>\n",
       "      <th>adcode_model_regMonth_salesVolume_5</th>\n",
       "      <th>adcode_model_regMonth_salesVolume_6</th>\n",
       "      <th>adcode_model_regMonth_salesVolume_7</th>\n",
       "      <th>adcode_model_regMonth_salesVolume_8</th>\n",
       "      <th>...</th>\n",
       "      <th>adcode_bodyType_regMonth_salesVolume_rolling_std_12</th>\n",
       "      <th>adcode_bodyType_regMonth_salesVolume_rolling_sum_4</th>\n",
       "      <th>adcode_bodyType_regMonth_salesVolume_rolling_sum_5</th>\n",
       "      <th>adcode_bodyType_regMonth_salesVolume_rolling_sum_6</th>\n",
       "      <th>adcode_bodyType_regMonth_salesVolume_rolling_sum_7</th>\n",
       "      <th>adcode_bodyType_regMonth_salesVolume_rolling_sum_8</th>\n",
       "      <th>adcode_bodyType_regMonth_salesVolume_rolling_sum_9</th>\n",
       "      <th>adcode_bodyType_regMonth_salesVolume_rolling_sum_10</th>\n",
       "      <th>adcode_bodyType_regMonth_salesVolume_rolling_sum_11</th>\n",
       "      <th>adcode_bodyType_regMonth_salesVolume_rolling_sum_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>110000</td>\n",
       "      <td>02aab221aabc03b9</td>\n",
       "      <td>6.684612</td>\n",
       "      <td>6.052089</td>\n",
       "      <td>6.598509</td>\n",
       "      <td>6.302619</td>\n",
       "      <td>6.340359</td>\n",
       "      <td>6.472346</td>\n",
       "      <td>6.618739</td>\n",
       "      <td>6.742881</td>\n",
       "      <td>...</td>\n",
       "      <td>8.657722</td>\n",
       "      <td>639.799585</td>\n",
       "      <td>636.69988</td>\n",
       "      <td>655.841951</td>\n",
       "      <td>654.532863</td>\n",
       "      <td>655.573478</td>\n",
       "      <td>655.266455</td>\n",
       "      <td>647.766958</td>\n",
       "      <td>648.454342</td>\n",
       "      <td>659.300918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>110000</td>\n",
       "      <td>04e66e578f653ab9</td>\n",
       "      <td>4.912655</td>\n",
       "      <td>4.060443</td>\n",
       "      <td>5.081404</td>\n",
       "      <td>4.955827</td>\n",
       "      <td>4.976734</td>\n",
       "      <td>5.062595</td>\n",
       "      <td>5.111988</td>\n",
       "      <td>5.068904</td>\n",
       "      <td>...</td>\n",
       "      <td>8.657722</td>\n",
       "      <td>639.799585</td>\n",
       "      <td>636.69988</td>\n",
       "      <td>655.841951</td>\n",
       "      <td>654.532863</td>\n",
       "      <td>655.573478</td>\n",
       "      <td>655.266455</td>\n",
       "      <td>647.766958</td>\n",
       "      <td>648.454342</td>\n",
       "      <td>659.300918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>110000</td>\n",
       "      <td>06880909932890ca</td>\n",
       "      <td>6.771936</td>\n",
       "      <td>5.288267</td>\n",
       "      <td>6.204558</td>\n",
       "      <td>6.063785</td>\n",
       "      <td>6.220590</td>\n",
       "      <td>6.003887</td>\n",
       "      <td>6.376727</td>\n",
       "      <td>6.395262</td>\n",
       "      <td>...</td>\n",
       "      <td>8.657722</td>\n",
       "      <td>639.799585</td>\n",
       "      <td>636.69988</td>\n",
       "      <td>655.841951</td>\n",
       "      <td>654.532863</td>\n",
       "      <td>655.573478</td>\n",
       "      <td>655.266455</td>\n",
       "      <td>647.766958</td>\n",
       "      <td>648.454342</td>\n",
       "      <td>659.300918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>110000</td>\n",
       "      <td>0797526c057dcf5b</td>\n",
       "      <td>5.736572</td>\n",
       "      <td>4.672829</td>\n",
       "      <td>6.129050</td>\n",
       "      <td>6.363028</td>\n",
       "      <td>6.429719</td>\n",
       "      <td>6.498282</td>\n",
       "      <td>6.548219</td>\n",
       "      <td>6.612041</td>\n",
       "      <td>...</td>\n",
       "      <td>8.657722</td>\n",
       "      <td>639.799585</td>\n",
       "      <td>636.69988</td>\n",
       "      <td>655.841951</td>\n",
       "      <td>654.532863</td>\n",
       "      <td>655.573478</td>\n",
       "      <td>655.266455</td>\n",
       "      <td>647.766958</td>\n",
       "      <td>648.454342</td>\n",
       "      <td>659.300918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>110000</td>\n",
       "      <td>12f8b7e14947c34d</td>\n",
       "      <td>6.390241</td>\n",
       "      <td>5.393628</td>\n",
       "      <td>5.849325</td>\n",
       "      <td>5.837730</td>\n",
       "      <td>5.926926</td>\n",
       "      <td>5.849325</td>\n",
       "      <td>6.063785</td>\n",
       "      <td>5.986452</td>\n",
       "      <td>...</td>\n",
       "      <td>8.657722</td>\n",
       "      <td>639.799585</td>\n",
       "      <td>636.69988</td>\n",
       "      <td>655.841951</td>\n",
       "      <td>654.532863</td>\n",
       "      <td>655.573478</td>\n",
       "      <td>655.266455</td>\n",
       "      <td>647.766958</td>\n",
       "      <td>648.454342</td>\n",
       "      <td>659.300918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 335 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adcode             model  adcode_model_regMonth_salesVolume_1  \\\n",
       "0  110000  02aab221aabc03b9                             6.684612   \n",
       "1  110000  04e66e578f653ab9                             4.912655   \n",
       "2  110000  06880909932890ca                             6.771936   \n",
       "3  110000  0797526c057dcf5b                             5.736572   \n",
       "4  110000  12f8b7e14947c34d                             6.390241   \n",
       "\n",
       "   adcode_model_regMonth_salesVolume_2  adcode_model_regMonth_salesVolume_3  \\\n",
       "0                             6.052089                             6.598509   \n",
       "1                             4.060443                             5.081404   \n",
       "2                             5.288267                             6.204558   \n",
       "3                             4.672829                             6.129050   \n",
       "4                             5.393628                             5.849325   \n",
       "\n",
       "   adcode_model_regMonth_salesVolume_4  adcode_model_regMonth_salesVolume_5  \\\n",
       "0                             6.302619                             6.340359   \n",
       "1                             4.955827                             4.976734   \n",
       "2                             6.063785                             6.220590   \n",
       "3                             6.363028                             6.429719   \n",
       "4                             5.837730                             5.926926   \n",
       "\n",
       "   adcode_model_regMonth_salesVolume_6  adcode_model_regMonth_salesVolume_7  \\\n",
       "0                             6.472346                             6.618739   \n",
       "1                             5.062595                             5.111988   \n",
       "2                             6.003887                             6.376727   \n",
       "3                             6.498282                             6.548219   \n",
       "4                             5.849325                             6.063785   \n",
       "\n",
       "   adcode_model_regMonth_salesVolume_8  ...  \\\n",
       "0                             6.742881  ...   \n",
       "1                             5.068904  ...   \n",
       "2                             6.395262  ...   \n",
       "3                             6.612041  ...   \n",
       "4                             5.986452  ...   \n",
       "\n",
       "   adcode_bodyType_regMonth_salesVolume_rolling_std_12  \\\n",
       "0                                           8.657722     \n",
       "1                                           8.657722     \n",
       "2                                           8.657722     \n",
       "3                                           8.657722     \n",
       "4                                           8.657722     \n",
       "\n",
       "   adcode_bodyType_regMonth_salesVolume_rolling_sum_4  \\\n",
       "0                                         639.799585    \n",
       "1                                         639.799585    \n",
       "2                                         639.799585    \n",
       "3                                         639.799585    \n",
       "4                                         639.799585    \n",
       "\n",
       "   adcode_bodyType_regMonth_salesVolume_rolling_sum_5  \\\n",
       "0                                          636.69988    \n",
       "1                                          636.69988    \n",
       "2                                          636.69988    \n",
       "3                                          636.69988    \n",
       "4                                          636.69988    \n",
       "\n",
       "   adcode_bodyType_regMonth_salesVolume_rolling_sum_6  \\\n",
       "0                                         655.841951    \n",
       "1                                         655.841951    \n",
       "2                                         655.841951    \n",
       "3                                         655.841951    \n",
       "4                                         655.841951    \n",
       "\n",
       "   adcode_bodyType_regMonth_salesVolume_rolling_sum_7  \\\n",
       "0                                         654.532863    \n",
       "1                                         654.532863    \n",
       "2                                         654.532863    \n",
       "3                                         654.532863    \n",
       "4                                         654.532863    \n",
       "\n",
       "   adcode_bodyType_regMonth_salesVolume_rolling_sum_8  \\\n",
       "0                                         655.573478    \n",
       "1                                         655.573478    \n",
       "2                                         655.573478    \n",
       "3                                         655.573478    \n",
       "4                                         655.573478    \n",
       "\n",
       "   adcode_bodyType_regMonth_salesVolume_rolling_sum_9  \\\n",
       "0                                         655.266455    \n",
       "1                                         655.266455    \n",
       "2                                         655.266455    \n",
       "3                                         655.266455    \n",
       "4                                         655.266455    \n",
       "\n",
       "   adcode_bodyType_regMonth_salesVolume_rolling_sum_10  \\\n",
       "0                                         647.766958     \n",
       "1                                         647.766958     \n",
       "2                                         647.766958     \n",
       "3                                         647.766958     \n",
       "4                                         647.766958     \n",
       "\n",
       "   adcode_bodyType_regMonth_salesVolume_rolling_sum_11  \\\n",
       "0                                         648.454342     \n",
       "1                                         648.454342     \n",
       "2                                         648.454342     \n",
       "3                                         648.454342     \n",
       "4                                         648.454342     \n",
       "\n",
       "   adcode_bodyType_regMonth_salesVolume_rolling_sum_12  \n",
       "0                                         659.300918    \n",
       "1                                         659.300918    \n",
       "2                                         659.300918    \n",
       "3                                         659.300918    \n",
       "4                                         659.300918    \n",
       "\n",
       "[5 rows x 335 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.merge(train_basic_fea, train_windows_fea, on=[\"adcode\", \"model\", \"bodyType\"], how=\"left\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1320, 14)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaild_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并特征\n",
    "train_data = pd.merge(train_basic_fea, train_windows_fea, on=[\"adcode\", \"model\", \"bodyType\"], how=\"left\")\n",
    "vaild_data = get_data(train_sales, \"test\").groupby([\"adcode\", \"model\"])[\"salesVolume\"].apply(lambda x: pd.DataFrame(np.array(x)).T).reset_index().drop(\"level_2\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train_columns: ['adcode', 'model', 'adcode_model_regMonth_salesVolume_1', 'adcode_model_regMonth_salesVolume_2', 'adcode_model_regMonth_salesVolume_3', 'adcode_model_regMonth_salesVolume_4', 'adcode_model_regMonth_salesVolume_5', 'adcode_model_regMonth_salesVolume_6', 'adcode_model_regMonth_salesVolume_7', 'adcode_model_regMonth_salesVolume_8', 'adcode_model_regMonth_salesVolume_9', 'adcode_model_regMonth_salesVolume_10', 'adcode_model_regMonth_salesVolume_11', 'adcode_model_regMonth_salesVolume_12', 'adcode_model_regMonth_salesVolume_shift_div_2', 'adcode_model_regMonth_salesVolume_shift_div_3', 'adcode_model_regMonth_salesVolume_shift_div_4', 'adcode_model_regMonth_salesVolume_shift_div_5', 'adcode_model_regMonth_salesVolume_shift_div_6', 'adcode_model_regMonth_salesVolume_shift_div_7', 'adcode_model_regMonth_salesVolume_shift_div_8', 'adcode_model_regMonth_salesVolume_shift_div_9', 'adcode_model_regMonth_salesVolume_shift_div_10', 'adcode_model_regMonth_salesVolume_shift_div_11', 'adcode_model_regMonth_salesVolume_shift_div_12', 'adcode_model_regMonth_salesVolume_shift_sub_2', 'adcode_model_regMonth_salesVolume_shift_sub_3', 'adcode_model_regMonth_salesVolume_shift_sub_4', 'adcode_model_regMonth_salesVolume_shift_sub_5', 'adcode_model_regMonth_salesVolume_shift_sub_6', 'adcode_model_regMonth_salesVolume_shift_sub_7', 'adcode_model_regMonth_salesVolume_shift_sub_8', 'adcode_model_regMonth_salesVolume_shift_sub_9', 'adcode_model_regMonth_salesVolume_shift_sub_10', 'adcode_model_regMonth_salesVolume_shift_sub_11', 'adcode_model_regMonth_salesVolume_shift_sub_12', 'adcode_model_regMonth_salesVolume_shift_2_div_2', 'adcode_model_regMonth_salesVolume_shift_2_div_3', 'adcode_model_regMonth_salesVolume_shift_2_div_4', 'adcode_model_regMonth_salesVolume_shift_2_div_5', 'adcode_model_regMonth_salesVolume_shift_2_div_6', 'adcode_model_regMonth_salesVolume_shift_2_div_7', 'adcode_model_regMonth_salesVolume_shift_2_div_8', 'adcode_model_regMonth_salesVolume_shift_2_div_9', 'adcode_model_regMonth_salesVolume_shift_2_div_10', 'adcode_model_regMonth_salesVolume_shift_2_div_11', 'adcode_model_regMonth_salesVolume_shift_2_div_12', 'adcode_model_regMonth_salesVolume_shift_2_sub_2', 'adcode_model_regMonth_salesVolume_shift_2_sub_3', 'adcode_model_regMonth_salesVolume_shift_2_sub_4', 'adcode_model_regMonth_salesVolume_shift_2_sub_5', 'adcode_model_regMonth_salesVolume_shift_2_sub_6', 'adcode_model_regMonth_salesVolume_shift_2_sub_7', 'adcode_model_regMonth_salesVolume_shift_2_sub_8', 'adcode_model_regMonth_salesVolume_shift_2_sub_9', 'adcode_model_regMonth_salesVolume_shift_2_sub_10', 'adcode_model_regMonth_salesVolume_shift_2_sub_11', 'adcode_model_regMonth_salesVolume_shift_2_sub_12', 'adcode_regMonth_salesVolume_1', 'adcode_regMonth_salesVolume_2', 'adcode_regMonth_salesVolume_3', 'adcode_regMonth_salesVolume_4', 'adcode_regMonth_salesVolume_5', 'adcode_regMonth_salesVolume_6', 'adcode_regMonth_salesVolume_7', 'adcode_regMonth_salesVolume_8', 'adcode_regMonth_salesVolume_9', 'adcode_regMonth_salesVolume_10', 'adcode_regMonth_salesVolume_11', 'adcode_regMonth_salesVolume_12', 'adcode_regMonth_salesVolume_shift_div_2', 'adcode_regMonth_salesVolume_shift_div_3', 'adcode_regMonth_salesVolume_shift_div_4', 'adcode_regMonth_salesVolume_shift_div_5', 'adcode_regMonth_salesVolume_shift_div_6', 'adcode_regMonth_salesVolume_shift_div_7', 'adcode_regMonth_salesVolume_shift_div_8', 'adcode_regMonth_salesVolume_shift_div_9', 'adcode_regMonth_salesVolume_shift_div_10', 'adcode_regMonth_salesVolume_shift_div_11', 'adcode_regMonth_salesVolume_shift_div_12', 'adcode_regMonth_salesVolume_shift_sub_2', 'adcode_regMonth_salesVolume_shift_sub_3', 'adcode_regMonth_salesVolume_shift_sub_4', 'adcode_regMonth_salesVolume_shift_sub_5', 'adcode_regMonth_salesVolume_shift_sub_6', 'adcode_regMonth_salesVolume_shift_sub_7', 'adcode_regMonth_salesVolume_shift_sub_8', 'adcode_regMonth_salesVolume_shift_sub_9', 'adcode_regMonth_salesVolume_shift_sub_10', 'adcode_regMonth_salesVolume_shift_sub_11', 'adcode_regMonth_salesVolume_shift_sub_12', 'adcode_regMonth_salesVolume_shift_2_div_2', 'adcode_regMonth_salesVolume_shift_2_div_3', 'adcode_regMonth_salesVolume_shift_2_div_4', 'adcode_regMonth_salesVolume_shift_2_div_5', 'adcode_regMonth_salesVolume_shift_2_div_6', 'adcode_regMonth_salesVolume_shift_2_div_7', 'adcode_regMonth_salesVolume_shift_2_div_8', 'adcode_regMonth_salesVolume_shift_2_div_9', 'adcode_regMonth_salesVolume_shift_2_div_10', 'adcode_regMonth_salesVolume_shift_2_div_11', 'adcode_regMonth_salesVolume_shift_2_div_12', 'adcode_regMonth_salesVolume_shift_2_sub_2', 'adcode_regMonth_salesVolume_shift_2_sub_3', 'adcode_regMonth_salesVolume_shift_2_sub_4', 'adcode_regMonth_salesVolume_shift_2_sub_5', 'adcode_regMonth_salesVolume_shift_2_sub_6', 'adcode_regMonth_salesVolume_shift_2_sub_7', 'adcode_regMonth_salesVolume_shift_2_sub_8', 'adcode_regMonth_salesVolume_shift_2_sub_9', 'adcode_regMonth_salesVolume_shift_2_sub_10', 'adcode_regMonth_salesVolume_shift_2_sub_11', 'adcode_regMonth_salesVolume_shift_2_sub_12', 'model_regMonth_salesVolume_1', 'model_regMonth_salesVolume_2', 'model_regMonth_salesVolume_3', 'model_regMonth_salesVolume_4', 'model_regMonth_salesVolume_5', 'model_regMonth_salesVolume_6', 'model_regMonth_salesVolume_7', 'model_regMonth_salesVolume_8', 'model_regMonth_salesVolume_9', 'model_regMonth_salesVolume_10', 'model_regMonth_salesVolume_11', 'model_regMonth_salesVolume_12', 'model_regMonth_salesVolume_shift_div_2', 'model_regMonth_salesVolume_shift_div_3', 'model_regMonth_salesVolume_shift_div_4', 'model_regMonth_salesVolume_shift_div_5', 'model_regMonth_salesVolume_shift_div_6', 'model_regMonth_salesVolume_shift_div_7', 'model_regMonth_salesVolume_shift_div_8', 'model_regMonth_salesVolume_shift_div_9', 'model_regMonth_salesVolume_shift_div_10', 'model_regMonth_salesVolume_shift_div_11', 'model_regMonth_salesVolume_shift_div_12', 'model_regMonth_salesVolume_shift_sub_2', 'model_regMonth_salesVolume_shift_sub_3', 'model_regMonth_salesVolume_shift_sub_4', 'model_regMonth_salesVolume_shift_sub_5', 'model_regMonth_salesVolume_shift_sub_6', 'model_regMonth_salesVolume_shift_sub_7', 'model_regMonth_salesVolume_shift_sub_8', 'model_regMonth_salesVolume_shift_sub_9', 'model_regMonth_salesVolume_shift_sub_10', 'model_regMonth_salesVolume_shift_sub_11', 'model_regMonth_salesVolume_shift_sub_12', 'model_regMonth_salesVolume_shift_2_div_2', 'model_regMonth_salesVolume_shift_2_div_3', 'model_regMonth_salesVolume_shift_2_div_4', 'model_regMonth_salesVolume_shift_2_div_5', 'model_regMonth_salesVolume_shift_2_div_6', 'model_regMonth_salesVolume_shift_2_div_7', 'model_regMonth_salesVolume_shift_2_div_8', 'model_regMonth_salesVolume_shift_2_div_9', 'model_regMonth_salesVolume_shift_2_div_10', 'model_regMonth_salesVolume_shift_2_div_11', 'model_regMonth_salesVolume_shift_2_div_12', 'model_regMonth_salesVolume_shift_2_sub_2', 'model_regMonth_salesVolume_shift_2_sub_3', 'model_regMonth_salesVolume_shift_2_sub_4', 'model_regMonth_salesVolume_shift_2_sub_5', 'model_regMonth_salesVolume_shift_2_sub_6', 'model_regMonth_salesVolume_shift_2_sub_7', 'model_regMonth_salesVolume_shift_2_sub_8', 'model_regMonth_salesVolume_shift_2_sub_9', 'model_regMonth_salesVolume_shift_2_sub_10', 'model_regMonth_salesVolume_shift_2_sub_11', 'model_regMonth_salesVolume_shift_2_sub_12', 'bodyType', 'adcode_bodyType_regMonth_salesVolume_1', 'adcode_bodyType_regMonth_salesVolume_2', 'adcode_bodyType_regMonth_salesVolume_3', 'adcode_bodyType_regMonth_salesVolume_4', 'adcode_bodyType_regMonth_salesVolume_5', 'adcode_bodyType_regMonth_salesVolume_6', 'adcode_bodyType_regMonth_salesVolume_7', 'adcode_bodyType_regMonth_salesVolume_8', 'adcode_bodyType_regMonth_salesVolume_9', 'adcode_bodyType_regMonth_salesVolume_10', 'adcode_bodyType_regMonth_salesVolume_11', 'adcode_bodyType_regMonth_salesVolume_12', 'adcode_bodyType_regMonth_salesVolume_shift_div_2', 'adcode_bodyType_regMonth_salesVolume_shift_div_3', 'adcode_bodyType_regMonth_salesVolume_shift_div_4', 'adcode_bodyType_regMonth_salesVolume_shift_div_5', 'adcode_bodyType_regMonth_salesVolume_shift_div_6', 'adcode_bodyType_regMonth_salesVolume_shift_div_7', 'adcode_bodyType_regMonth_salesVolume_shift_div_8', 'adcode_bodyType_regMonth_salesVolume_shift_div_9', 'adcode_bodyType_regMonth_salesVolume_shift_div_10', 'adcode_bodyType_regMonth_salesVolume_shift_div_11', 'adcode_bodyType_regMonth_salesVolume_shift_div_12', 'adcode_bodyType_regMonth_salesVolume_shift_sub_2', 'adcode_bodyType_regMonth_salesVolume_shift_sub_3', 'adcode_bodyType_regMonth_salesVolume_shift_sub_4', 'adcode_bodyType_regMonth_salesVolume_shift_sub_5', 'adcode_bodyType_regMonth_salesVolume_shift_sub_6', 'adcode_bodyType_regMonth_salesVolume_shift_sub_7', 'adcode_bodyType_regMonth_salesVolume_shift_sub_8', 'adcode_bodyType_regMonth_salesVolume_shift_sub_9', 'adcode_bodyType_regMonth_salesVolume_shift_sub_10', 'adcode_bodyType_regMonth_salesVolume_shift_sub_11', 'adcode_bodyType_regMonth_salesVolume_shift_sub_12', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_2', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_3', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_4', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_5', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_6', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_7', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_8', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_9', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_10', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_11', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_12', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_2', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_3', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_4', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_5', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_6', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_7', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_8', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_9', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_10', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_11', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_12', 'adcode_model_regMonth_salesVolume_rolling_mean_4', 'adcode_model_regMonth_salesVolume_rolling_mean_5', 'adcode_model_regMonth_salesVolume_rolling_mean_6', 'adcode_model_regMonth_salesVolume_rolling_mean_7', 'adcode_model_regMonth_salesVolume_rolling_mean_8', 'adcode_model_regMonth_salesVolume_rolling_mean_9', 'adcode_model_regMonth_salesVolume_rolling_mean_10', 'adcode_model_regMonth_salesVolume_rolling_mean_11', 'adcode_model_regMonth_salesVolume_rolling_mean_12', 'adcode_model_regMonth_salesVolume_rolling_std_4', 'adcode_model_regMonth_salesVolume_rolling_std_5', 'adcode_model_regMonth_salesVolume_rolling_std_6', 'adcode_model_regMonth_salesVolume_rolling_std_7', 'adcode_model_regMonth_salesVolume_rolling_std_8', 'adcode_model_regMonth_salesVolume_rolling_std_9', 'adcode_model_regMonth_salesVolume_rolling_std_10', 'adcode_model_regMonth_salesVolume_rolling_std_11', 'adcode_model_regMonth_salesVolume_rolling_std_12', 'adcode_model_regMonth_salesVolume_rolling_sum_4', 'adcode_model_regMonth_salesVolume_rolling_sum_5', 'adcode_model_regMonth_salesVolume_rolling_sum_6', 'adcode_model_regMonth_salesVolume_rolling_sum_7', 'adcode_model_regMonth_salesVolume_rolling_sum_8', 'adcode_model_regMonth_salesVolume_rolling_sum_9', 'adcode_model_regMonth_salesVolume_rolling_sum_10', 'adcode_model_regMonth_salesVolume_rolling_sum_11', 'adcode_model_regMonth_salesVolume_rolling_sum_12', 'adcode_regMonth_salesVolume_rolling_mean_4', 'adcode_regMonth_salesVolume_rolling_mean_5', 'adcode_regMonth_salesVolume_rolling_mean_6', 'adcode_regMonth_salesVolume_rolling_mean_7', 'adcode_regMonth_salesVolume_rolling_mean_8', 'adcode_regMonth_salesVolume_rolling_mean_9', 'adcode_regMonth_salesVolume_rolling_mean_10', 'adcode_regMonth_salesVolume_rolling_mean_11', 'adcode_regMonth_salesVolume_rolling_mean_12', 'adcode_regMonth_salesVolume_rolling_std_4', 'adcode_regMonth_salesVolume_rolling_std_5', 'adcode_regMonth_salesVolume_rolling_std_6', 'adcode_regMonth_salesVolume_rolling_std_7', 'adcode_regMonth_salesVolume_rolling_std_8', 'adcode_regMonth_salesVolume_rolling_std_9', 'adcode_regMonth_salesVolume_rolling_std_10', 'adcode_regMonth_salesVolume_rolling_std_11', 'adcode_regMonth_salesVolume_rolling_std_12', 'adcode_regMonth_salesVolume_rolling_sum_4', 'adcode_regMonth_salesVolume_rolling_sum_5', 'adcode_regMonth_salesVolume_rolling_sum_6', 'adcode_regMonth_salesVolume_rolling_sum_7', 'adcode_regMonth_salesVolume_rolling_sum_8', 'adcode_regMonth_salesVolume_rolling_sum_9', 'adcode_regMonth_salesVolume_rolling_sum_10', 'adcode_regMonth_salesVolume_rolling_sum_11', 'adcode_regMonth_salesVolume_rolling_sum_12', 'model_regMonth_salesVolume_rolling_mean_4', 'model_regMonth_salesVolume_rolling_mean_5', 'model_regMonth_salesVolume_rolling_mean_6', 'model_regMonth_salesVolume_rolling_mean_7', 'model_regMonth_salesVolume_rolling_mean_8', 'model_regMonth_salesVolume_rolling_mean_9', 'model_regMonth_salesVolume_rolling_mean_10', 'model_regMonth_salesVolume_rolling_mean_11', 'model_regMonth_salesVolume_rolling_mean_12', 'model_regMonth_salesVolume_rolling_std_4', 'model_regMonth_salesVolume_rolling_std_5', 'model_regMonth_salesVolume_rolling_std_6', 'model_regMonth_salesVolume_rolling_std_7', 'model_regMonth_salesVolume_rolling_std_8', 'model_regMonth_salesVolume_rolling_std_9', 'model_regMonth_salesVolume_rolling_std_10', 'model_regMonth_salesVolume_rolling_std_11', 'model_regMonth_salesVolume_rolling_std_12', 'model_regMonth_salesVolume_rolling_sum_4', 'model_regMonth_salesVolume_rolling_sum_5', 'model_regMonth_salesVolume_rolling_sum_6', 'model_regMonth_salesVolume_rolling_sum_7', 'model_regMonth_salesVolume_rolling_sum_8', 'model_regMonth_salesVolume_rolling_sum_9', 'model_regMonth_salesVolume_rolling_sum_10', 'model_regMonth_salesVolume_rolling_sum_11', 'model_regMonth_salesVolume_rolling_sum_12', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_4', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_5', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_6', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_7', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_8', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_9', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_10', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_11', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_12', 'adcode_bodyType_regMonth_salesVolume_rolling_std_4', 'adcode_bodyType_regMonth_salesVolume_rolling_std_5', 'adcode_bodyType_regMonth_salesVolume_rolling_std_6', 'adcode_bodyType_regMonth_salesVolume_rolling_std_7', 'adcode_bodyType_regMonth_salesVolume_rolling_std_8', 'adcode_bodyType_regMonth_salesVolume_rolling_std_9', 'adcode_bodyType_regMonth_salesVolume_rolling_std_10', 'adcode_bodyType_regMonth_salesVolume_rolling_std_11', 'adcode_bodyType_regMonth_salesVolume_rolling_std_12', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_4', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_5', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_6', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_7', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_8', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_9', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_10', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_11', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_12']"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(1320, 335)\n",
      "335\n",
      "fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\lightgbm\\engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['adcode', 'bodyType', 'model']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\lightgbm\\basic.py:762: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0791586\tvalid_1's l2: 0.127653\n",
      "[400]\ttraining's l2: 0.0256935\tvalid_1's l2: 0.0640422\n",
      "[600]\ttraining's l2: 0.0162166\tvalid_1's l2: 0.0516776\n",
      "[800]\ttraining's l2: 0.0120997\tvalid_1's l2: 0.0475752\n",
      "[1000]\ttraining's l2: 0.00948978\tvalid_1's l2: 0.0460382\n",
      "[1200]\ttraining's l2: 0.00776839\tvalid_1's l2: 0.0455201\n",
      "[1400]\ttraining's l2: 0.00658673\tvalid_1's l2: 0.0451363\n",
      "[1600]\ttraining's l2: 0.00562753\tvalid_1's l2: 0.0449572\n",
      "[1800]\ttraining's l2: 0.00489398\tvalid_1's l2: 0.0448303\n",
      "[2000]\ttraining's l2: 0.0043544\tvalid_1's l2: 0.04474\n",
      "[2200]\ttraining's l2: 0.00398942\tvalid_1's l2: 0.0447454\n",
      "Early stopping, best iteration is:\n",
      "[2056]\ttraining's l2: 0.00424143\tvalid_1's l2: 0.0447138\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0696984\tvalid_1's l2: 0.103014\n",
      "[400]\ttraining's l2: 0.0235283\tvalid_1's l2: 0.056339\n",
      "[600]\ttraining's l2: 0.0158953\tvalid_1's l2: 0.0474621\n",
      "[800]\ttraining's l2: 0.0126013\tvalid_1's l2: 0.0443735\n",
      "[1000]\ttraining's l2: 0.0100721\tvalid_1's l2: 0.0432265\n",
      "[1200]\ttraining's l2: 0.00831708\tvalid_1's l2: 0.0427801\n",
      "[1400]\ttraining's l2: 0.00697251\tvalid_1's l2: 0.0425454\n",
      "[1600]\ttraining's l2: 0.00600679\tvalid_1's l2: 0.0424106\n",
      "[1800]\ttraining's l2: 0.00526457\tvalid_1's l2: 0.0423981\n",
      "Early stopping, best iteration is:\n",
      "[1721]\ttraining's l2: 0.00552877\tvalid_1's l2: 0.0423694\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0676374\tvalid_1's l2: 0.113504\n",
      "[400]\ttraining's l2: 0.0228546\tvalid_1's l2: 0.0654548\n",
      "[600]\ttraining's l2: 0.0149384\tvalid_1's l2: 0.0576238\n",
      "[800]\ttraining's l2: 0.0112651\tvalid_1's l2: 0.0542518\n",
      "[1000]\ttraining's l2: 0.00904758\tvalid_1's l2: 0.0527487\n",
      "[1200]\ttraining's l2: 0.0074972\tvalid_1's l2: 0.0522319\n",
      "[1400]\ttraining's l2: 0.00639011\tvalid_1's l2: 0.0517702\n",
      "[1600]\ttraining's l2: 0.00554596\tvalid_1's l2: 0.0515104\n",
      "[1800]\ttraining's l2: 0.00486281\tvalid_1's l2: 0.0514701\n",
      "[2000]\ttraining's l2: 0.00436795\tvalid_1's l2: 0.0513326\n",
      "[2200]\ttraining's l2: 0.00434334\tvalid_1's l2: 0.0513282\n",
      "Early stopping, best iteration is:\n",
      "[2012]\ttraining's l2: 0.0043498\tvalid_1's l2: 0.05132\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0741855\tvalid_1's l2: 0.145956\n",
      "[400]\ttraining's l2: 0.0251884\tvalid_1's l2: 0.0898881\n",
      "[600]\ttraining's l2: 0.0165106\tvalid_1's l2: 0.0805795\n",
      "[800]\ttraining's l2: 0.0125035\tvalid_1's l2: 0.0779615\n",
      "[1000]\ttraining's l2: 0.00984264\tvalid_1's l2: 0.0771419\n",
      "[1200]\ttraining's l2: 0.00801341\tvalid_1's l2: 0.0767637\n",
      "[1400]\ttraining's l2: 0.00678207\tvalid_1's l2: 0.0765685\n",
      "[1600]\ttraining's l2: 0.00579198\tvalid_1's l2: 0.0765695\n",
      "Early stopping, best iteration is:\n",
      "[1546]\ttraining's l2: 0.00603012\tvalid_1's l2: 0.0765151\n",
      "fold 1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0815002\tvalid_1's l2: 0.100127\n",
      "[400]\ttraining's l2: 0.025389\tvalid_1's l2: 0.052026\n",
      "[600]\ttraining's l2: 0.0159082\tvalid_1's l2: 0.04603\n",
      "[800]\ttraining's l2: 0.011877\tvalid_1's l2: 0.0441468\n",
      "[1000]\ttraining's l2: 0.00950477\tvalid_1's l2: 0.043206\n",
      "[1200]\ttraining's l2: 0.00794201\tvalid_1's l2: 0.0426685\n",
      "[1400]\ttraining's l2: 0.00670003\tvalid_1's l2: 0.0422557\n",
      "[1600]\ttraining's l2: 0.00578026\tvalid_1's l2: 0.0421869\n",
      "[1800]\ttraining's l2: 0.00497208\tvalid_1's l2: 0.0419216\n",
      "[2000]\ttraining's l2: 0.00439319\tvalid_1's l2: 0.0418818\n",
      "Early stopping, best iteration is:\n",
      "[1978]\ttraining's l2: 0.00444808\tvalid_1's l2: 0.0418754\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0709177\tvalid_1's l2: 0.102898\n",
      "[400]\ttraining's l2: 0.0234881\tvalid_1's l2: 0.0572499\n",
      "[600]\ttraining's l2: 0.015694\tvalid_1's l2: 0.0505929\n",
      "[800]\ttraining's l2: 0.0121017\tvalid_1's l2: 0.0492915\n",
      "[1000]\ttraining's l2: 0.00968531\tvalid_1's l2: 0.0488135\n",
      "[1200]\ttraining's l2: 0.00796319\tvalid_1's l2: 0.0486244\n",
      "[1400]\ttraining's l2: 0.00671949\tvalid_1's l2: 0.0485216\n",
      "[1600]\ttraining's l2: 0.00575002\tvalid_1's l2: 0.0484243\n",
      "[1800]\ttraining's l2: 0.00508095\tvalid_1's l2: 0.0484384\n",
      "Early stopping, best iteration is:\n",
      "[1675]\ttraining's l2: 0.00547037\tvalid_1's l2: 0.0483653\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0711739\tvalid_1's l2: 0.0905849\n",
      "[400]\ttraining's l2: 0.0244689\tvalid_1's l2: 0.0501204\n",
      "[600]\ttraining's l2: 0.0162086\tvalid_1's l2: 0.0438919\n",
      "[800]\ttraining's l2: 0.0122562\tvalid_1's l2: 0.0423935\n",
      "[1000]\ttraining's l2: 0.00975019\tvalid_1's l2: 0.0419644\n",
      "[1200]\ttraining's l2: 0.00805269\tvalid_1's l2: 0.0416824\n",
      "[1400]\ttraining's l2: 0.00681183\tvalid_1's l2: 0.0416648\n",
      "[1600]\ttraining's l2: 0.00581666\tvalid_1's l2: 0.0416519\n",
      "Early stopping, best iteration is:\n",
      "[1500]\ttraining's l2: 0.00626877\tvalid_1's l2: 0.041607\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0802577\tvalid_1's l2: 0.107104\n",
      "[400]\ttraining's l2: 0.0284705\tvalid_1's l2: 0.0661446\n",
      "[600]\ttraining's l2: 0.0186878\tvalid_1's l2: 0.0600911\n",
      "[800]\ttraining's l2: 0.0138896\tvalid_1's l2: 0.0585416\n",
      "[1000]\ttraining's l2: 0.0109127\tvalid_1's l2: 0.0582876\n",
      "Early stopping, best iteration is:\n",
      "[966]\ttraining's l2: 0.0113346\tvalid_1's l2: 0.0582441\n",
      "fold 2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0796648\tvalid_1's l2: 0.108971\n",
      "[400]\ttraining's l2: 0.0241372\tvalid_1's l2: 0.0589356\n",
      "[600]\ttraining's l2: 0.0150463\tvalid_1's l2: 0.0495814\n",
      "[800]\ttraining's l2: 0.011367\tvalid_1's l2: 0.0470374\n",
      "[1000]\ttraining's l2: 0.00905411\tvalid_1's l2: 0.0461069\n",
      "[1200]\ttraining's l2: 0.00742486\tvalid_1's l2: 0.0456007\n",
      "[1400]\ttraining's l2: 0.00629648\tvalid_1's l2: 0.0454142\n",
      "[1600]\ttraining's l2: 0.00538105\tvalid_1's l2: 0.0452433\n",
      "[1800]\ttraining's l2: 0.00470014\tvalid_1's l2: 0.0453781\n",
      "Early stopping, best iteration is:\n",
      "[1615]\ttraining's l2: 0.00531708\tvalid_1's l2: 0.0452018\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0711593\tvalid_1's l2: 0.114933\n",
      "[400]\ttraining's l2: 0.0228917\tvalid_1's l2: 0.0585666\n",
      "[600]\ttraining's l2: 0.0153455\tvalid_1's l2: 0.0485695\n",
      "[800]\ttraining's l2: 0.0123241\tvalid_1's l2: 0.0454744\n",
      "[1000]\ttraining's l2: 0.0102018\tvalid_1's l2: 0.043987\n",
      "[1200]\ttraining's l2: 0.0084653\tvalid_1's l2: 0.0431338\n",
      "[1400]\ttraining's l2: 0.00711604\tvalid_1's l2: 0.0425482\n",
      "[1600]\ttraining's l2: 0.00607058\tvalid_1's l2: 0.0423317\n",
      "[1800]\ttraining's l2: 0.00527818\tvalid_1's l2: 0.0422206\n",
      "[2000]\ttraining's l2: 0.00472382\tvalid_1's l2: 0.0421331\n",
      "Early stopping, best iteration is:\n",
      "[1961]\ttraining's l2: 0.00480452\tvalid_1's l2: 0.0421245\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0707491\tvalid_1's l2: 0.0992692\n",
      "[400]\ttraining's l2: 0.0227374\tvalid_1's l2: 0.0546176\n",
      "[600]\ttraining's l2: 0.0145815\tvalid_1's l2: 0.048525\n",
      "[800]\ttraining's l2: 0.0113714\tvalid_1's l2: 0.0474464\n",
      "[1000]\ttraining's l2: 0.00922095\tvalid_1's l2: 0.0466709\n",
      "[1200]\ttraining's l2: 0.00760361\tvalid_1's l2: 0.0460922\n",
      "[1400]\ttraining's l2: 0.0064292\tvalid_1's l2: 0.0458213\n",
      "[1600]\ttraining's l2: 0.00557184\tvalid_1's l2: 0.0453729\n",
      "[1800]\ttraining's l2: 0.00491076\tvalid_1's l2: 0.0450772\n",
      "[2000]\ttraining's l2: 0.00457613\tvalid_1's l2: 0.0449882\n",
      "Early stopping, best iteration is:\n",
      "[1941]\ttraining's l2: 0.00458427\tvalid_1's l2: 0.0449867\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0806909\tvalid_1's l2: 0.099966\n",
      "[400]\ttraining's l2: 0.0267427\tvalid_1's l2: 0.0598933\n",
      "[600]\ttraining's l2: 0.0175925\tvalid_1's l2: 0.0546437\n",
      "[800]\ttraining's l2: 0.0136541\tvalid_1's l2: 0.0525761\n",
      "[1000]\ttraining's l2: 0.0109958\tvalid_1's l2: 0.0523034\n",
      "[1200]\ttraining's l2: 0.00904888\tvalid_1's l2: 0.0518378\n",
      "[1400]\ttraining's l2: 0.00760712\tvalid_1's l2: 0.0517474\n",
      "[1600]\ttraining's l2: 0.00653997\tvalid_1's l2: 0.0516482\n",
      "Early stopping, best iteration is:\n",
      "[1531]\ttraining's l2: 0.00688355\tvalid_1's l2: 0.0516124\n",
      "fold 3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0766449\tvalid_1's l2: 0.138121\n",
      "[400]\ttraining's l2: 0.0238162\tvalid_1's l2: 0.0734054\n",
      "[600]\ttraining's l2: 0.0148532\tvalid_1's l2: 0.063433\n",
      "[800]\ttraining's l2: 0.0112929\tvalid_1's l2: 0.0610122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttraining's l2: 0.00897308\tvalid_1's l2: 0.060204\n",
      "[1200]\ttraining's l2: 0.00739045\tvalid_1's l2: 0.0598475\n",
      "[1400]\ttraining's l2: 0.00624387\tvalid_1's l2: 0.0598654\n",
      "[1600]\ttraining's l2: 0.00538173\tvalid_1's l2: 0.0597002\n",
      "Early stopping, best iteration is:\n",
      "[1529]\ttraining's l2: 0.00565825\tvalid_1's l2: 0.0596569\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0705325\tvalid_1's l2: 0.109221\n",
      "[400]\ttraining's l2: 0.0226614\tvalid_1's l2: 0.0591424\n",
      "[600]\ttraining's l2: 0.0149151\tvalid_1's l2: 0.052471\n",
      "[800]\ttraining's l2: 0.0115468\tvalid_1's l2: 0.0508696\n",
      "[1000]\ttraining's l2: 0.00940199\tvalid_1's l2: 0.0503871\n",
      "[1200]\ttraining's l2: 0.00783556\tvalid_1's l2: 0.0505419\n",
      "Early stopping, best iteration is:\n",
      "[1010]\ttraining's l2: 0.00931228\tvalid_1's l2: 0.0503751\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0707011\tvalid_1's l2: 0.0926085\n",
      "[400]\ttraining's l2: 0.0239635\tvalid_1's l2: 0.0456264\n",
      "[600]\ttraining's l2: 0.0156305\tvalid_1's l2: 0.0407542\n",
      "[800]\ttraining's l2: 0.0119235\tvalid_1's l2: 0.0401177\n",
      "Early stopping, best iteration is:\n",
      "[779]\ttraining's l2: 0.0122612\tvalid_1's l2: 0.0400729\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0804863\tvalid_1's l2: 0.106662\n",
      "[400]\ttraining's l2: 0.028653\tvalid_1's l2: 0.0499411\n",
      "[600]\ttraining's l2: 0.0187316\tvalid_1's l2: 0.0421325\n",
      "[800]\ttraining's l2: 0.0141448\tvalid_1's l2: 0.0399614\n",
      "[1000]\ttraining's l2: 0.0110367\tvalid_1's l2: 0.0389184\n",
      "[1200]\ttraining's l2: 0.00888642\tvalid_1's l2: 0.0384846\n",
      "[1400]\ttraining's l2: 0.00744009\tvalid_1's l2: 0.0382383\n",
      "[1600]\ttraining's l2: 0.00638763\tvalid_1's l2: 0.0380582\n",
      "[1800]\ttraining's l2: 0.00554985\tvalid_1's l2: 0.0377351\n",
      "[2000]\ttraining's l2: 0.00493222\tvalid_1's l2: 0.0374242\n",
      "[2200]\ttraining's l2: 0.00464047\tvalid_1's l2: 0.0373611\n",
      "Early stopping, best iteration is:\n",
      "[2132]\ttraining's l2: 0.00464047\tvalid_1's l2: 0.0373611\n",
      "fold 4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0776129\tvalid_1's l2: 0.122408\n",
      "[400]\ttraining's l2: 0.0229918\tvalid_1's l2: 0.0738469\n",
      "[600]\ttraining's l2: 0.0141796\tvalid_1's l2: 0.063844\n",
      "[800]\ttraining's l2: 0.0107834\tvalid_1's l2: 0.0605641\n",
      "[1000]\ttraining's l2: 0.00866277\tvalid_1's l2: 0.0585752\n",
      "[1200]\ttraining's l2: 0.00720865\tvalid_1's l2: 0.0575167\n",
      "[1400]\ttraining's l2: 0.0061291\tvalid_1's l2: 0.056754\n",
      "[1600]\ttraining's l2: 0.00531467\tvalid_1's l2: 0.0563067\n",
      "[1800]\ttraining's l2: 0.00465371\tvalid_1's l2: 0.0559057\n",
      "[2000]\ttraining's l2: 0.00421146\tvalid_1's l2: 0.0557774\n",
      "Early stopping, best iteration is:\n",
      "[1965]\ttraining's l2: 0.00426725\tvalid_1's l2: 0.0557387\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0713935\tvalid_1's l2: 0.0956358\n",
      "[400]\ttraining's l2: 0.0226088\tvalid_1's l2: 0.0564596\n",
      "[600]\ttraining's l2: 0.0148612\tvalid_1's l2: 0.0499976\n",
      "[800]\ttraining's l2: 0.0117906\tvalid_1's l2: 0.0478998\n",
      "[1000]\ttraining's l2: 0.00976546\tvalid_1's l2: 0.0471454\n",
      "[1200]\ttraining's l2: 0.00820625\tvalid_1's l2: 0.0467679\n",
      "[1400]\ttraining's l2: 0.00690589\tvalid_1's l2: 0.0466391\n",
      "Early stopping, best iteration is:\n",
      "[1389]\ttraining's l2: 0.00696056\tvalid_1's l2: 0.0466243\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0711786\tvalid_1's l2: 0.0871293\n",
      "[400]\ttraining's l2: 0.0239572\tvalid_1's l2: 0.0460923\n",
      "[600]\ttraining's l2: 0.015714\tvalid_1's l2: 0.0396327\n",
      "[800]\ttraining's l2: 0.0120037\tvalid_1's l2: 0.0378913\n",
      "[1000]\ttraining's l2: 0.00944311\tvalid_1's l2: 0.0373103\n",
      "[1200]\ttraining's l2: 0.00773055\tvalid_1's l2: 0.0369529\n",
      "[1400]\ttraining's l2: 0.00655024\tvalid_1's l2: 0.0367457\n",
      "[1600]\ttraining's l2: 0.00569607\tvalid_1's l2: 0.0366635\n",
      "[1800]\ttraining's l2: 0.00501988\tvalid_1's l2: 0.0366778\n",
      "Early stopping, best iteration is:\n",
      "[1631]\ttraining's l2: 0.00558442\tvalid_1's l2: 0.0366414\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0810053\tvalid_1's l2: 0.112137\n",
      "[400]\ttraining's l2: 0.0279567\tvalid_1's l2: 0.0620004\n",
      "[600]\ttraining's l2: 0.0183837\tvalid_1's l2: 0.0540287\n",
      "[800]\ttraining's l2: 0.0142292\tvalid_1's l2: 0.0515187\n",
      "[1000]\ttraining's l2: 0.0114531\tvalid_1's l2: 0.0504296\n",
      "[1200]\ttraining's l2: 0.00933279\tvalid_1's l2: 0.0495088\n",
      "[1400]\ttraining's l2: 0.00773707\tvalid_1's l2: 0.0489492\n",
      "[1600]\ttraining's l2: 0.00660077\tvalid_1's l2: 0.0487635\n",
      "[1800]\ttraining's l2: 0.00576411\tvalid_1's l2: 0.0487256\n",
      "[2000]\ttraining's l2: 0.00506336\tvalid_1's l2: 0.0485763\n",
      "[2200]\ttraining's l2: 0.00472516\tvalid_1's l2: 0.0483941\n",
      "Early stopping, best iteration is:\n",
      "[2151]\ttraining's l2: 0.00472516\tvalid_1's l2: 0.0483941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\ipykernel_launcher.py:157: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\ipykernel_launcher.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\ipykernel_launcher.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\ipykernel_launcher.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# 模型\n",
    "le_model = preprocessing.LabelEncoder()\n",
    "le_bodyType = preprocessing.LabelEncoder()\n",
    "\n",
    "le_model.fit(train_data.model)\n",
    "le_bodyType.fit(train_data.bodyType)\n",
    "\n",
    "lgb_params = {\n",
    "    \"num_leaves\":32,\n",
    "    \"reg_alpha\":1,\n",
    "    \"reg_lambda\":0.1,\n",
    "    \"objective\":'mse',\n",
    "    \"max_depth\": 4,\n",
    "    \"learning_rate\":0.01,\n",
    "    \"min_child_samples\":5,\n",
    "    \"random_state\":2019,\n",
    "    \"n_estimators\":4000,\n",
    "    \"subsample\":0.8,\n",
    "    \"colsample_bytree\":0.8\n",
    "}\n",
    "\n",
    "df_train_columns = [c for c in train_data.columns if c not in []]\n",
    "print(\"df_train_columns:\",df_train_columns)\n",
    "cate_fea = [\"adcode\", \"model\", \"bodyType\"]\n",
    "train_data.model = le_model.transform(train_data.model)\n",
    "train_data.bodyType = le_bodyType.transform(train_data.bodyType)\n",
    "print(train_data.shape)\n",
    "print(len(df_train_columns))\n",
    "\n",
    "\n",
    "y_score = []    # 交叉验证\n",
    "cv_pred = []    # 各折的预测值\n",
    "predictions = 0\n",
    "feature_importance_df = pd.DataFrame()\n",
    "skf = KFold(n_splits=5, random_state=random.randint(100, 10000), shuffle=True)\n",
    "\n",
    "\n",
    "label_0 = vaild_data[0]\n",
    "label_1 = vaild_data[1]\n",
    "label_2 = vaild_data[2]\n",
    "label_3 = vaild_data[3]\n",
    "\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(skf.split(train_data, label_0)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train_data.iloc[trn_idx][df_train_columns], label=label_0.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_data.iloc[val_idx][df_train_columns], label=label_0.iloc[val_idx])\n",
    "\n",
    "    result_df = train_data.iloc[val_idx][[\"adcode\", \"model\"]]\n",
    "\n",
    "    gbm_1 = lgb.train(lgb_params,\n",
    "                    trn_data,\n",
    "                    # init_model=gbm,\n",
    "                    num_boost_round=150000,\n",
    "                    valid_sets=[trn_data, val_data],\n",
    "                    early_stopping_rounds=200,\n",
    "                    verbose_eval=200,\n",
    "                    categorical_feature=cate_fea)     # 训练\n",
    "\n",
    "    trn_data = lgb.Dataset(train_data.iloc[trn_idx][df_train_columns], label=label_1.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_data.iloc[val_idx][df_train_columns], label=label_1.iloc[val_idx])\n",
    "\n",
    "    gbm_2 = lgb.train(lgb_params,\n",
    "                    trn_data,\n",
    "                    # init_model=gbm,\n",
    "                    num_boost_round=150000,\n",
    "                    valid_sets=[trn_data, val_data],\n",
    "                    early_stopping_rounds=200,\n",
    "                    verbose_eval=200,\n",
    "                    categorical_feature=cate_fea)     # 训练\n",
    "\n",
    "    trn_data = lgb.Dataset(train_data.iloc[trn_idx][df_train_columns], label=label_2.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_data.iloc[val_idx][df_train_columns], label=label_2.iloc[val_idx])\n",
    "\n",
    "    gbm_3 = lgb.train(lgb_params,\n",
    "                    trn_data,\n",
    "                    # init_model=gbm,\n",
    "                    num_boost_round=3000,\n",
    "                    valid_sets=[trn_data, val_data],\n",
    "                    early_stopping_rounds=200,\n",
    "                    verbose_eval=200,\n",
    "                    categorical_feature=cate_fea)     # 训练\n",
    "\n",
    "    trn_data = lgb.Dataset(train_data.iloc[trn_idx][df_train_columns], label=label_3.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_data.iloc[val_idx][df_train_columns], label=label_3.iloc[val_idx])\n",
    "\n",
    "    gbm_4 = lgb.train(lgb_params,\n",
    "                    trn_data,\n",
    "                    # init_model=gbm,\n",
    "                    num_boost_round=150000,\n",
    "                    valid_sets=[trn_data, val_data],\n",
    "                    early_stopping_rounds=200,\n",
    "                    verbose_eval=200,\n",
    "                    categorical_feature=cate_fea)     # 训练\n",
    "\n",
    "    result_df[\"y_pred_1\"] = gbm_1.predict(train_data.iloc[val_idx][df_train_columns])\n",
    "    result_df[\"y_pred_2\"] = gbm_2.predict(train_data.iloc[val_idx][df_train_columns])\n",
    "    result_df[\"y_pred_3\"] = gbm_3.predict(train_data.iloc[val_idx][df_train_columns])\n",
    "    result_df[\"y_pred_4\"] = gbm_4.predict(train_data.iloc[val_idx][df_train_columns])\n",
    "    # break\n",
    "\n",
    "result_df[\"y_true_1\"] = label_0\n",
    "result_df[\"y_true_2\"] = label_1\n",
    "result_df[\"y_true_3\"] = label_2\n",
    "result_df[\"y_true_4\"] = label_3\n",
    "\n",
    "# 预测\n",
    "# 基础特征\n",
    "# 城市+车\n",
    "test_basic_fea = cal_basic_fea(train_sales, \"salesVolume\", [\"adcode\", \"model\", \"regMonth\"], \"test\")\n",
    "# 城市\n",
    "tmp_df = cal_basic_fea(train_sales, \"salesVolume\", [\"adcode\", \"regMonth\"], \"test\")\n",
    "test_basic_fea = pd.merge(test_basic_fea, tmp_df, on=\"adcode\", how=\"left\")\n",
    "# 车\n",
    "tmp_df = cal_basic_fea(train_sales, \"salesVolume\", [\"model\", \"regMonth\"], \"test\")\n",
    "test_basic_fea = pd.merge(test_basic_fea, tmp_df, on=\"model\", how=\"left\")\n",
    "# 城市+车型\n",
    "tmp_df = cal_basic_fea(train_sales, \"salesVolume\", [\"adcode\", \"bodyType\", \"regMonth\"], \"test\")\n",
    "test_basic_fea[\"bodyType\"] = test_basic_fea.model.apply(lambda x: model2type[x])\n",
    "test_basic_fea = pd.merge(test_basic_fea, tmp_df, on=[\"adcode\", \"bodyType\"], how=\"left\")\n",
    "\n",
    "# 滑窗特征\n",
    "# 城市+车\n",
    "test_windows_fea = cal_windows_fea(train_sales, cal_col=\"salesVolume\", stat_dim=[\"adcode\", \"model\", \"regMonth\"], data_type=\"test\")\n",
    "# 城市\n",
    "tmp_df = cal_windows_fea(train_sales, \"salesVolume\", [\"adcode\", \"regMonth\"], \"test\")\n",
    "test_windows_fea = pd.merge(test_windows_fea, tmp_df, on=\"adcode\", how=\"left\")\n",
    "# 车\n",
    "tmp_df = cal_windows_fea(train_sales, \"salesVolume\", [\"model\", \"regMonth\"], \"test\")\n",
    "test_windows_fea = pd.merge(test_windows_fea, tmp_df, on=\"model\", how=\"left\")\n",
    "# 城市+车型\n",
    "tmp_df = cal_windows_fea(train_sales, \"salesVolume\", [\"adcode\", \"bodyType\", \"regMonth\"], \"test\")\n",
    "test_windows_fea[\"bodyType\"] = test_windows_fea.model.apply(lambda x: model2type[x])\n",
    "test_windows_fea = pd.merge(test_windows_fea, tmp_df, on=[\"adcode\", \"bodyType\"], how=\"left\")\n",
    "\n",
    "# 合并\n",
    "test_data = pd.merge(test_basic_fea, test_windows_fea, on=[\"adcode\", \"model\", \"bodyType\"], how=\"left\")\n",
    "\n",
    "test_data.model = le_model.transform(test_data.model)\n",
    "test_data.bodyType = le_bodyType.transform(test_data.bodyType)\n",
    "\n",
    "y_pred_1 = gbm_1.predict(test_data[df_train_columns])\n",
    "y_pred_2 = gbm_2.predict(test_data[df_train_columns])\n",
    "y_pred_3 = gbm_3.predict(test_data[df_train_columns])\n",
    "y_pred_4 = gbm_4.predict(test_data[df_train_columns])\n",
    "\n",
    "y_pred_1 = (np.e ** y_pred_1 - 1).astype(int)\n",
    "y_pred_2 = (np.e ** y_pred_2 - 1).astype(int)\n",
    "y_pred_3 = (np.e ** y_pred_3 - 1).astype(int)\n",
    "y_pred_4 = (np.e ** y_pred_4 - 1).astype(int)\n",
    "\n",
    "result_df = test_basic_fea[[\"adcode\", \"model\"]]\n",
    "result_df[\"y_pred_1\"] = y_pred_1\n",
    "result_df[\"y_pred_2\"] = y_pred_2\n",
    "result_df[\"y_pred_3\"] = y_pred_3\n",
    "result_df[\"y_pred_4\"] = y_pred_4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train_columns: ['adcode', 'model', 'adcode_model_regMonth_salesVolume_1', 'adcode_model_regMonth_salesVolume_2', 'adcode_model_regMonth_salesVolume_3', 'adcode_model_regMonth_salesVolume_4', 'adcode_model_regMonth_salesVolume_5', 'adcode_model_regMonth_salesVolume_6', 'adcode_model_regMonth_salesVolume_7', 'adcode_model_regMonth_salesVolume_8', 'adcode_model_regMonth_salesVolume_9', 'adcode_model_regMonth_salesVolume_10', 'adcode_model_regMonth_salesVolume_11', 'adcode_model_regMonth_salesVolume_12', 'adcode_model_regMonth_salesVolume_shift_div_2', 'adcode_model_regMonth_salesVolume_shift_div_3', 'adcode_model_regMonth_salesVolume_shift_div_4', 'adcode_model_regMonth_salesVolume_shift_div_5', 'adcode_model_regMonth_salesVolume_shift_div_6', 'adcode_model_regMonth_salesVolume_shift_div_7', 'adcode_model_regMonth_salesVolume_shift_div_8', 'adcode_model_regMonth_salesVolume_shift_div_9', 'adcode_model_regMonth_salesVolume_shift_div_10', 'adcode_model_regMonth_salesVolume_shift_div_11', 'adcode_model_regMonth_salesVolume_shift_div_12', 'adcode_model_regMonth_salesVolume_shift_sub_2', 'adcode_model_regMonth_salesVolume_shift_sub_3', 'adcode_model_regMonth_salesVolume_shift_sub_4', 'adcode_model_regMonth_salesVolume_shift_sub_5', 'adcode_model_regMonth_salesVolume_shift_sub_6', 'adcode_model_regMonth_salesVolume_shift_sub_7', 'adcode_model_regMonth_salesVolume_shift_sub_8', 'adcode_model_regMonth_salesVolume_shift_sub_9', 'adcode_model_regMonth_salesVolume_shift_sub_10', 'adcode_model_regMonth_salesVolume_shift_sub_11', 'adcode_model_regMonth_salesVolume_shift_sub_12', 'adcode_model_regMonth_salesVolume_shift_2_div_2', 'adcode_model_regMonth_salesVolume_shift_2_div_3', 'adcode_model_regMonth_salesVolume_shift_2_div_4', 'adcode_model_regMonth_salesVolume_shift_2_div_5', 'adcode_model_regMonth_salesVolume_shift_2_div_6', 'adcode_model_regMonth_salesVolume_shift_2_div_7', 'adcode_model_regMonth_salesVolume_shift_2_div_8', 'adcode_model_regMonth_salesVolume_shift_2_div_9', 'adcode_model_regMonth_salesVolume_shift_2_div_10', 'adcode_model_regMonth_salesVolume_shift_2_div_11', 'adcode_model_regMonth_salesVolume_shift_2_div_12', 'adcode_model_regMonth_salesVolume_shift_2_sub_2', 'adcode_model_regMonth_salesVolume_shift_2_sub_3', 'adcode_model_regMonth_salesVolume_shift_2_sub_4', 'adcode_model_regMonth_salesVolume_shift_2_sub_5', 'adcode_model_regMonth_salesVolume_shift_2_sub_6', 'adcode_model_regMonth_salesVolume_shift_2_sub_7', 'adcode_model_regMonth_salesVolume_shift_2_sub_8', 'adcode_model_regMonth_salesVolume_shift_2_sub_9', 'adcode_model_regMonth_salesVolume_shift_2_sub_10', 'adcode_model_regMonth_salesVolume_shift_2_sub_11', 'adcode_model_regMonth_salesVolume_shift_2_sub_12', 'adcode_regMonth_salesVolume_1', 'adcode_regMonth_salesVolume_2', 'adcode_regMonth_salesVolume_3', 'adcode_regMonth_salesVolume_4', 'adcode_regMonth_salesVolume_5', 'adcode_regMonth_salesVolume_6', 'adcode_regMonth_salesVolume_7', 'adcode_regMonth_salesVolume_8', 'adcode_regMonth_salesVolume_9', 'adcode_regMonth_salesVolume_10', 'adcode_regMonth_salesVolume_11', 'adcode_regMonth_salesVolume_12', 'adcode_regMonth_salesVolume_shift_div_2', 'adcode_regMonth_salesVolume_shift_div_3', 'adcode_regMonth_salesVolume_shift_div_4', 'adcode_regMonth_salesVolume_shift_div_5', 'adcode_regMonth_salesVolume_shift_div_6', 'adcode_regMonth_salesVolume_shift_div_7', 'adcode_regMonth_salesVolume_shift_div_8', 'adcode_regMonth_salesVolume_shift_div_9', 'adcode_regMonth_salesVolume_shift_div_10', 'adcode_regMonth_salesVolume_shift_div_11', 'adcode_regMonth_salesVolume_shift_div_12', 'adcode_regMonth_salesVolume_shift_sub_2', 'adcode_regMonth_salesVolume_shift_sub_3', 'adcode_regMonth_salesVolume_shift_sub_4', 'adcode_regMonth_salesVolume_shift_sub_5', 'adcode_regMonth_salesVolume_shift_sub_6', 'adcode_regMonth_salesVolume_shift_sub_7', 'adcode_regMonth_salesVolume_shift_sub_8', 'adcode_regMonth_salesVolume_shift_sub_9', 'adcode_regMonth_salesVolume_shift_sub_10', 'adcode_regMonth_salesVolume_shift_sub_11', 'adcode_regMonth_salesVolume_shift_sub_12', 'adcode_regMonth_salesVolume_shift_2_div_2', 'adcode_regMonth_salesVolume_shift_2_div_3', 'adcode_regMonth_salesVolume_shift_2_div_4', 'adcode_regMonth_salesVolume_shift_2_div_5', 'adcode_regMonth_salesVolume_shift_2_div_6', 'adcode_regMonth_salesVolume_shift_2_div_7', 'adcode_regMonth_salesVolume_shift_2_div_8', 'adcode_regMonth_salesVolume_shift_2_div_9', 'adcode_regMonth_salesVolume_shift_2_div_10', 'adcode_regMonth_salesVolume_shift_2_div_11', 'adcode_regMonth_salesVolume_shift_2_div_12', 'adcode_regMonth_salesVolume_shift_2_sub_2', 'adcode_regMonth_salesVolume_shift_2_sub_3', 'adcode_regMonth_salesVolume_shift_2_sub_4', 'adcode_regMonth_salesVolume_shift_2_sub_5', 'adcode_regMonth_salesVolume_shift_2_sub_6', 'adcode_regMonth_salesVolume_shift_2_sub_7', 'adcode_regMonth_salesVolume_shift_2_sub_8', 'adcode_regMonth_salesVolume_shift_2_sub_9', 'adcode_regMonth_salesVolume_shift_2_sub_10', 'adcode_regMonth_salesVolume_shift_2_sub_11', 'adcode_regMonth_salesVolume_shift_2_sub_12', 'model_regMonth_salesVolume_1', 'model_regMonth_salesVolume_2', 'model_regMonth_salesVolume_3', 'model_regMonth_salesVolume_4', 'model_regMonth_salesVolume_5', 'model_regMonth_salesVolume_6', 'model_regMonth_salesVolume_7', 'model_regMonth_salesVolume_8', 'model_regMonth_salesVolume_9', 'model_regMonth_salesVolume_10', 'model_regMonth_salesVolume_11', 'model_regMonth_salesVolume_12', 'model_regMonth_salesVolume_shift_div_2', 'model_regMonth_salesVolume_shift_div_3', 'model_regMonth_salesVolume_shift_div_4', 'model_regMonth_salesVolume_shift_div_5', 'model_regMonth_salesVolume_shift_div_6', 'model_regMonth_salesVolume_shift_div_7', 'model_regMonth_salesVolume_shift_div_8', 'model_regMonth_salesVolume_shift_div_9', 'model_regMonth_salesVolume_shift_div_10', 'model_regMonth_salesVolume_shift_div_11', 'model_regMonth_salesVolume_shift_div_12', 'model_regMonth_salesVolume_shift_sub_2', 'model_regMonth_salesVolume_shift_sub_3', 'model_regMonth_salesVolume_shift_sub_4', 'model_regMonth_salesVolume_shift_sub_5', 'model_regMonth_salesVolume_shift_sub_6', 'model_regMonth_salesVolume_shift_sub_7', 'model_regMonth_salesVolume_shift_sub_8', 'model_regMonth_salesVolume_shift_sub_9', 'model_regMonth_salesVolume_shift_sub_10', 'model_regMonth_salesVolume_shift_sub_11', 'model_regMonth_salesVolume_shift_sub_12', 'model_regMonth_salesVolume_shift_2_div_2', 'model_regMonth_salesVolume_shift_2_div_3', 'model_regMonth_salesVolume_shift_2_div_4', 'model_regMonth_salesVolume_shift_2_div_5', 'model_regMonth_salesVolume_shift_2_div_6', 'model_regMonth_salesVolume_shift_2_div_7', 'model_regMonth_salesVolume_shift_2_div_8', 'model_regMonth_salesVolume_shift_2_div_9', 'model_regMonth_salesVolume_shift_2_div_10', 'model_regMonth_salesVolume_shift_2_div_11', 'model_regMonth_salesVolume_shift_2_div_12', 'model_regMonth_salesVolume_shift_2_sub_2', 'model_regMonth_salesVolume_shift_2_sub_3', 'model_regMonth_salesVolume_shift_2_sub_4', 'model_regMonth_salesVolume_shift_2_sub_5', 'model_regMonth_salesVolume_shift_2_sub_6', 'model_regMonth_salesVolume_shift_2_sub_7', 'model_regMonth_salesVolume_shift_2_sub_8', 'model_regMonth_salesVolume_shift_2_sub_9', 'model_regMonth_salesVolume_shift_2_sub_10', 'model_regMonth_salesVolume_shift_2_sub_11', 'model_regMonth_salesVolume_shift_2_sub_12', 'bodyType', 'adcode_bodyType_regMonth_salesVolume_1', 'adcode_bodyType_regMonth_salesVolume_2', 'adcode_bodyType_regMonth_salesVolume_3', 'adcode_bodyType_regMonth_salesVolume_4', 'adcode_bodyType_regMonth_salesVolume_5', 'adcode_bodyType_regMonth_salesVolume_6', 'adcode_bodyType_regMonth_salesVolume_7', 'adcode_bodyType_regMonth_salesVolume_8', 'adcode_bodyType_regMonth_salesVolume_9', 'adcode_bodyType_regMonth_salesVolume_10', 'adcode_bodyType_regMonth_salesVolume_11', 'adcode_bodyType_regMonth_salesVolume_12', 'adcode_bodyType_regMonth_salesVolume_shift_div_2', 'adcode_bodyType_regMonth_salesVolume_shift_div_3', 'adcode_bodyType_regMonth_salesVolume_shift_div_4', 'adcode_bodyType_regMonth_salesVolume_shift_div_5', 'adcode_bodyType_regMonth_salesVolume_shift_div_6', 'adcode_bodyType_regMonth_salesVolume_shift_div_7', 'adcode_bodyType_regMonth_salesVolume_shift_div_8', 'adcode_bodyType_regMonth_salesVolume_shift_div_9', 'adcode_bodyType_regMonth_salesVolume_shift_div_10', 'adcode_bodyType_regMonth_salesVolume_shift_div_11', 'adcode_bodyType_regMonth_salesVolume_shift_div_12', 'adcode_bodyType_regMonth_salesVolume_shift_sub_2', 'adcode_bodyType_regMonth_salesVolume_shift_sub_3', 'adcode_bodyType_regMonth_salesVolume_shift_sub_4', 'adcode_bodyType_regMonth_salesVolume_shift_sub_5', 'adcode_bodyType_regMonth_salesVolume_shift_sub_6', 'adcode_bodyType_regMonth_salesVolume_shift_sub_7', 'adcode_bodyType_regMonth_salesVolume_shift_sub_8', 'adcode_bodyType_regMonth_salesVolume_shift_sub_9', 'adcode_bodyType_regMonth_salesVolume_shift_sub_10', 'adcode_bodyType_regMonth_salesVolume_shift_sub_11', 'adcode_bodyType_regMonth_salesVolume_shift_sub_12', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_2', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_3', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_4', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_5', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_6', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_7', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_8', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_9', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_10', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_11', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_12', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_2', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_3', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_4', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_5', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_6', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_7', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_8', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_9', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_10', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_11', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_12', 'adcode_model_regMonth_salesVolume_rolling_mean_3', 'adcode_model_regMonth_salesVolume_rolling_mean_4', 'adcode_model_regMonth_salesVolume_rolling_mean_5', 'adcode_model_regMonth_salesVolume_rolling_mean_6', 'adcode_model_regMonth_salesVolume_rolling_mean_7', 'adcode_model_regMonth_salesVolume_rolling_mean_8', 'adcode_model_regMonth_salesVolume_rolling_mean_9', 'adcode_model_regMonth_salesVolume_rolling_mean_10', 'adcode_model_regMonth_salesVolume_rolling_mean_11', 'adcode_model_regMonth_salesVolume_rolling_mean_12', 'adcode_model_regMonth_salesVolume_rolling_std_3', 'adcode_model_regMonth_salesVolume_rolling_std_4', 'adcode_model_regMonth_salesVolume_rolling_std_5', 'adcode_model_regMonth_salesVolume_rolling_std_6', 'adcode_model_regMonth_salesVolume_rolling_std_7', 'adcode_model_regMonth_salesVolume_rolling_std_8', 'adcode_model_regMonth_salesVolume_rolling_std_9', 'adcode_model_regMonth_salesVolume_rolling_std_10', 'adcode_model_regMonth_salesVolume_rolling_std_11', 'adcode_model_regMonth_salesVolume_rolling_std_12', 'adcode_model_regMonth_salesVolume_rolling_sum_3', 'adcode_model_regMonth_salesVolume_rolling_sum_4', 'adcode_model_regMonth_salesVolume_rolling_sum_5', 'adcode_model_regMonth_salesVolume_rolling_sum_6', 'adcode_model_regMonth_salesVolume_rolling_sum_7', 'adcode_model_regMonth_salesVolume_rolling_sum_8', 'adcode_model_regMonth_salesVolume_rolling_sum_9', 'adcode_model_regMonth_salesVolume_rolling_sum_10', 'adcode_model_regMonth_salesVolume_rolling_sum_11', 'adcode_model_regMonth_salesVolume_rolling_sum_12', 'adcode_regMonth_salesVolume_rolling_mean_3', 'adcode_regMonth_salesVolume_rolling_mean_4', 'adcode_regMonth_salesVolume_rolling_mean_5', 'adcode_regMonth_salesVolume_rolling_mean_6', 'adcode_regMonth_salesVolume_rolling_mean_7', 'adcode_regMonth_salesVolume_rolling_mean_8', 'adcode_regMonth_salesVolume_rolling_mean_9', 'adcode_regMonth_salesVolume_rolling_mean_10', 'adcode_regMonth_salesVolume_rolling_mean_11', 'adcode_regMonth_salesVolume_rolling_mean_12', 'adcode_regMonth_salesVolume_rolling_std_3', 'adcode_regMonth_salesVolume_rolling_std_4', 'adcode_regMonth_salesVolume_rolling_std_5', 'adcode_regMonth_salesVolume_rolling_std_6', 'adcode_regMonth_salesVolume_rolling_std_7', 'adcode_regMonth_salesVolume_rolling_std_8', 'adcode_regMonth_salesVolume_rolling_std_9', 'adcode_regMonth_salesVolume_rolling_std_10', 'adcode_regMonth_salesVolume_rolling_std_11', 'adcode_regMonth_salesVolume_rolling_std_12', 'adcode_regMonth_salesVolume_rolling_sum_3', 'adcode_regMonth_salesVolume_rolling_sum_4', 'adcode_regMonth_salesVolume_rolling_sum_5', 'adcode_regMonth_salesVolume_rolling_sum_6', 'adcode_regMonth_salesVolume_rolling_sum_7', 'adcode_regMonth_salesVolume_rolling_sum_8', 'adcode_regMonth_salesVolume_rolling_sum_9', 'adcode_regMonth_salesVolume_rolling_sum_10', 'adcode_regMonth_salesVolume_rolling_sum_11', 'adcode_regMonth_salesVolume_rolling_sum_12', 'model_regMonth_salesVolume_rolling_mean_3', 'model_regMonth_salesVolume_rolling_mean_4', 'model_regMonth_salesVolume_rolling_mean_5', 'model_regMonth_salesVolume_rolling_mean_6', 'model_regMonth_salesVolume_rolling_mean_7', 'model_regMonth_salesVolume_rolling_mean_8', 'model_regMonth_salesVolume_rolling_mean_9', 'model_regMonth_salesVolume_rolling_mean_10', 'model_regMonth_salesVolume_rolling_mean_11', 'model_regMonth_salesVolume_rolling_mean_12', 'model_regMonth_salesVolume_rolling_std_3', 'model_regMonth_salesVolume_rolling_std_4', 'model_regMonth_salesVolume_rolling_std_5', 'model_regMonth_salesVolume_rolling_std_6', 'model_regMonth_salesVolume_rolling_std_7', 'model_regMonth_salesVolume_rolling_std_8', 'model_regMonth_salesVolume_rolling_std_9', 'model_regMonth_salesVolume_rolling_std_10', 'model_regMonth_salesVolume_rolling_std_11', 'model_regMonth_salesVolume_rolling_std_12', 'model_regMonth_salesVolume_rolling_sum_3', 'model_regMonth_salesVolume_rolling_sum_4', 'model_regMonth_salesVolume_rolling_sum_5', 'model_regMonth_salesVolume_rolling_sum_6', 'model_regMonth_salesVolume_rolling_sum_7', 'model_regMonth_salesVolume_rolling_sum_8', 'model_regMonth_salesVolume_rolling_sum_9', 'model_regMonth_salesVolume_rolling_sum_10', 'model_regMonth_salesVolume_rolling_sum_11', 'model_regMonth_salesVolume_rolling_sum_12', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_3', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_4', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_5', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_6', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_7', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_8', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_9', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_10', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_11', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_12', 'adcode_bodyType_regMonth_salesVolume_rolling_std_3', 'adcode_bodyType_regMonth_salesVolume_rolling_std_4', 'adcode_bodyType_regMonth_salesVolume_rolling_std_5', 'adcode_bodyType_regMonth_salesVolume_rolling_std_6', 'adcode_bodyType_regMonth_salesVolume_rolling_std_7', 'adcode_bodyType_regMonth_salesVolume_rolling_std_8', 'adcode_bodyType_regMonth_salesVolume_rolling_std_9', 'adcode_bodyType_regMonth_salesVolume_rolling_std_10', 'adcode_bodyType_regMonth_salesVolume_rolling_std_11', 'adcode_bodyType_regMonth_salesVolume_rolling_std_12', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_3', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_4', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_5', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_6', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_7', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_8', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_9', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_10', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_11', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_12']"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(1320, 347)\n",
      "347\n",
      "fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\lightgbm\\engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['adcode', 'bodyType', 'model']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\lightgbm\\basic.py:762: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0784653\tvalid_1's l2: 0.117199\n",
      "[400]\ttraining's l2: 0.0234233\tvalid_1's l2: 0.0624278\n",
      "[600]\ttraining's l2: 0.0146224\tvalid_1's l2: 0.05196\n",
      "[800]\ttraining's l2: 0.0110052\tvalid_1's l2: 0.0484078\n",
      "[1000]\ttraining's l2: 0.00881217\tvalid_1's l2: 0.0465347\n",
      "[1200]\ttraining's l2: 0.00730667\tvalid_1's l2: 0.0455504\n",
      "[1400]\ttraining's l2: 0.00614076\tvalid_1's l2: 0.0451977\n",
      "[1600]\ttraining's l2: 0.00525662\tvalid_1's l2: 0.0448401\n",
      "[1800]\ttraining's l2: 0.00459806\tvalid_1's l2: 0.0445541\n",
      "[2000]\ttraining's l2: 0.00413173\tvalid_1's l2: 0.0445176\n",
      "[2200]\ttraining's l2: 0.00400036\tvalid_1's l2: 0.0445261\n",
      "Early stopping, best iteration is:\n",
      "[2030]\ttraining's l2: 0.00407556\tvalid_1's l2: 0.0445\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.070053\tvalid_1's l2: 0.107385\n",
      "[400]\ttraining's l2: 0.0226529\tvalid_1's l2: 0.0600138\n",
      "[600]\ttraining's l2: 0.0150841\tvalid_1's l2: 0.0512898\n",
      "[800]\ttraining's l2: 0.0116219\tvalid_1's l2: 0.0487931\n",
      "[1000]\ttraining's l2: 0.00896842\tvalid_1's l2: 0.0477422\n",
      "[1200]\ttraining's l2: 0.00732658\tvalid_1's l2: 0.0472662\n",
      "[1400]\ttraining's l2: 0.0061547\tvalid_1's l2: 0.0471669\n",
      "[1600]\ttraining's l2: 0.00531947\tvalid_1's l2: 0.0470493\n",
      "[1800]\ttraining's l2: 0.00471556\tvalid_1's l2: 0.0470152\n",
      "[2000]\ttraining's l2: 0.00430463\tvalid_1's l2: 0.0469892\n",
      "Early stopping, best iteration is:\n",
      "[1881]\ttraining's l2: 0.00452788\tvalid_1's l2: 0.0469678\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0698108\tvalid_1's l2: 0.0831942\n",
      "[400]\ttraining's l2: 0.0233006\tvalid_1's l2: 0.0548883\n",
      "[600]\ttraining's l2: 0.01545\tvalid_1's l2: 0.0504882\n",
      "[800]\ttraining's l2: 0.0117201\tvalid_1's l2: 0.0498258\n",
      "[1000]\ttraining's l2: 0.00909231\tvalid_1's l2: 0.049088\n",
      "[1200]\ttraining's l2: 0.00735726\tvalid_1's l2: 0.0490589\n",
      "Early stopping, best iteration is:\n",
      "[1090]\ttraining's l2: 0.00821995\tvalid_1's l2: 0.0489958\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0765871\tvalid_1's l2: 0.10254\n",
      "[400]\ttraining's l2: 0.0247729\tvalid_1's l2: 0.0740763\n",
      "[600]\ttraining's l2: 0.0159581\tvalid_1's l2: 0.0707481\n",
      "[800]\ttraining's l2: 0.0120835\tvalid_1's l2: 0.0693613\n",
      "[1000]\ttraining's l2: 0.00956921\tvalid_1's l2: 0.0687244\n",
      "[1200]\ttraining's l2: 0.00792891\tvalid_1's l2: 0.0683213\n",
      "[1400]\ttraining's l2: 0.0066698\tvalid_1's l2: 0.0680971\n",
      "[1600]\ttraining's l2: 0.00571976\tvalid_1's l2: 0.0676763\n",
      "[1800]\ttraining's l2: 0.00503078\tvalid_1's l2: 0.0674418\n",
      "[2000]\ttraining's l2: 0.00449501\tvalid_1's l2: 0.06733\n",
      "[2200]\ttraining's l2: 0.00430374\tvalid_1's l2: 0.0673226\n",
      "Early stopping, best iteration is:\n",
      "[2021]\ttraining's l2: 0.00444356\tvalid_1's l2: 0.0673094\n",
      "fold 1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0797794\tvalid_1's l2: 0.0884348\n",
      "[400]\ttraining's l2: 0.0246286\tvalid_1's l2: 0.046042\n",
      "[600]\ttraining's l2: 0.0152044\tvalid_1's l2: 0.0398629\n",
      "[800]\ttraining's l2: 0.0113243\tvalid_1's l2: 0.0378887\n",
      "[1000]\ttraining's l2: 0.00897169\tvalid_1's l2: 0.0372084\n",
      "[1200]\ttraining's l2: 0.00734315\tvalid_1's l2: 0.0368514\n",
      "[1400]\ttraining's l2: 0.00613529\tvalid_1's l2: 0.0367004\n",
      "[1600]\ttraining's l2: 0.00522529\tvalid_1's l2: 0.0365532\n",
      "[1800]\ttraining's l2: 0.00456679\tvalid_1's l2: 0.0365744\n",
      "Early stopping, best iteration is:\n",
      "[1660]\ttraining's l2: 0.00501152\tvalid_1's l2: 0.0365249\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0696814\tvalid_1's l2: 0.111477\n",
      "[400]\ttraining's l2: 0.022344\tvalid_1's l2: 0.0632744\n",
      "[600]\ttraining's l2: 0.0147375\tvalid_1's l2: 0.0558031\n",
      "[800]\ttraining's l2: 0.011643\tvalid_1's l2: 0.0534118\n",
      "[1000]\ttraining's l2: 0.00958455\tvalid_1's l2: 0.0523475\n",
      "[1200]\ttraining's l2: 0.00793775\tvalid_1's l2: 0.0520149\n",
      "[1400]\ttraining's l2: 0.00666886\tvalid_1's l2: 0.0517308\n",
      "[1600]\ttraining's l2: 0.00573431\tvalid_1's l2: 0.0515705\n",
      "[1800]\ttraining's l2: 0.00502217\tvalid_1's l2: 0.0513669\n",
      "[2000]\ttraining's l2: 0.00448749\tvalid_1's l2: 0.0512747\n",
      "[2200]\ttraining's l2: 0.00418453\tvalid_1's l2: 0.0512484\n",
      "Early stopping, best iteration is:\n",
      "[2062]\ttraining's l2: 0.00434648\tvalid_1's l2: 0.0512408\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.070445\tvalid_1's l2: 0.0888603\n",
      "[400]\ttraining's l2: 0.0239325\tvalid_1's l2: 0.0479415\n",
      "[600]\ttraining's l2: 0.0156669\tvalid_1's l2: 0.0432334\n",
      "[800]\ttraining's l2: 0.0119669\tvalid_1's l2: 0.0417139\n",
      "[1000]\ttraining's l2: 0.00947666\tvalid_1's l2: 0.0413165\n",
      "[1200]\ttraining's l2: 0.00766376\tvalid_1's l2: 0.0413544\n",
      "[1400]\ttraining's l2: 0.00640478\tvalid_1's l2: 0.0411191\n",
      "[1600]\ttraining's l2: 0.00547674\tvalid_1's l2: 0.0409824\n",
      "[1800]\ttraining's l2: 0.00480055\tvalid_1's l2: 0.0410155\n",
      "Early stopping, best iteration is:\n",
      "[1681]\ttraining's l2: 0.00519033\tvalid_1's l2: 0.0409479\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0785003\tvalid_1's l2: 0.105077\n",
      "[400]\ttraining's l2: 0.0268495\tvalid_1's l2: 0.0583863\n",
      "[600]\ttraining's l2: 0.0176382\tvalid_1's l2: 0.0510375\n",
      "[800]\ttraining's l2: 0.013471\tvalid_1's l2: 0.0482212\n",
      "[1000]\ttraining's l2: 0.0106358\tvalid_1's l2: 0.0469634\n",
      "[1200]\ttraining's l2: 0.0085502\tvalid_1's l2: 0.0461867\n",
      "[1400]\ttraining's l2: 0.00711767\tvalid_1's l2: 0.0455941\n",
      "[1600]\ttraining's l2: 0.00604201\tvalid_1's l2: 0.045159\n",
      "[1800]\ttraining's l2: 0.0053098\tvalid_1's l2: 0.0449922\n",
      "Early stopping, best iteration is:\n",
      "[1771]\ttraining's l2: 0.00540613\tvalid_1's l2: 0.0449708\n",
      "fold 2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0770478\tvalid_1's l2: 0.12366\n",
      "[400]\ttraining's l2: 0.0234796\tvalid_1's l2: 0.0713103\n",
      "[600]\ttraining's l2: 0.0144099\tvalid_1's l2: 0.0613735\n",
      "[800]\ttraining's l2: 0.0107741\tvalid_1's l2: 0.0582979\n",
      "[1000]\ttraining's l2: 0.00857118\tvalid_1's l2: 0.0562674\n",
      "[1200]\ttraining's l2: 0.00717353\tvalid_1's l2: 0.0551418\n",
      "[1400]\ttraining's l2: 0.00610573\tvalid_1's l2: 0.0544623\n",
      "[1600]\ttraining's l2: 0.00531354\tvalid_1's l2: 0.0541643\n",
      "[1800]\ttraining's l2: 0.0046848\tvalid_1's l2: 0.0538519\n",
      "[2000]\ttraining's l2: 0.00425486\tvalid_1's l2: 0.0535768\n",
      "[2200]\ttraining's l2: 0.00424293\tvalid_1's l2: 0.053577\n",
      "Early stopping, best iteration is:\n",
      "[2002]\ttraining's l2: 0.00425194\tvalid_1's l2: 0.053573\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.070637\tvalid_1's l2: 0.100834\n",
      "[400]\ttraining's l2: 0.022691\tvalid_1's l2: 0.0590935\n",
      "[600]\ttraining's l2: 0.0148207\tvalid_1's l2: 0.0527012\n",
      "[800]\ttraining's l2: 0.0114621\tvalid_1's l2: 0.0507223\n",
      "[1000]\ttraining's l2: 0.00918446\tvalid_1's l2: 0.0500037\n",
      "[1200]\ttraining's l2: 0.00764805\tvalid_1's l2: 0.0495743\n",
      "[1400]\ttraining's l2: 0.00642174\tvalid_1's l2: 0.0492538\n",
      "[1600]\ttraining's l2: 0.00549785\tvalid_1's l2: 0.0490259\n",
      "[1800]\ttraining's l2: 0.00480487\tvalid_1's l2: 0.0490799\n",
      "Early stopping, best iteration is:\n",
      "[1679]\ttraining's l2: 0.0052037\tvalid_1's l2: 0.0489776\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0690353\tvalid_1's l2: 0.0868664\n",
      "[400]\ttraining's l2: 0.0226042\tvalid_1's l2: 0.0475694\n",
      "[600]\ttraining's l2: 0.0146346\tvalid_1's l2: 0.0434313\n",
      "[800]\ttraining's l2: 0.0111798\tvalid_1's l2: 0.0421331\n",
      "[1000]\ttraining's l2: 0.00883146\tvalid_1's l2: 0.0417516\n",
      "[1200]\ttraining's l2: 0.00720212\tvalid_1's l2: 0.0413982\n",
      "[1400]\ttraining's l2: 0.00608557\tvalid_1's l2: 0.0411268\n",
      "Early stopping, best iteration is:\n",
      "[1368]\ttraining's l2: 0.00624098\tvalid_1's l2: 0.0411105\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0795256\tvalid_1's l2: 0.106137\n",
      "[400]\ttraining's l2: 0.0278074\tvalid_1's l2: 0.0573847\n",
      "[600]\ttraining's l2: 0.0182068\tvalid_1's l2: 0.0515064\n",
      "[800]\ttraining's l2: 0.0137818\tvalid_1's l2: 0.0503346\n",
      "[1000]\ttraining's l2: 0.0109143\tvalid_1's l2: 0.05009\n",
      "[1200]\ttraining's l2: 0.00889348\tvalid_1's l2: 0.0499913\n",
      "[1400]\ttraining's l2: 0.00742103\tvalid_1's l2: 0.0498892\n",
      "[1600]\ttraining's l2: 0.00631038\tvalid_1's l2: 0.0496972\n",
      "[1800]\ttraining's l2: 0.00546642\tvalid_1's l2: 0.0495654\n",
      "[2000]\ttraining's l2: 0.00486527\tvalid_1's l2: 0.0494361\n",
      "[2200]\ttraining's l2: 0.00469942\tvalid_1's l2: 0.0493999\n",
      "Early stopping, best iteration is:\n",
      "[2054]\ttraining's l2: 0.00473866\tvalid_1's l2: 0.0493907\n",
      "fold 3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0800761\tvalid_1's l2: 0.105828\n",
      "[400]\ttraining's l2: 0.0246418\tvalid_1's l2: 0.0603088\n",
      "[600]\ttraining's l2: 0.0153651\tvalid_1's l2: 0.0522328\n",
      "[800]\ttraining's l2: 0.0116687\tvalid_1's l2: 0.0494819\n",
      "[1000]\ttraining's l2: 0.0093873\tvalid_1's l2: 0.0481424\n",
      "[1200]\ttraining's l2: 0.00769763\tvalid_1's l2: 0.0474181\n",
      "[1400]\ttraining's l2: 0.00646596\tvalid_1's l2: 0.0470517\n",
      "[1600]\ttraining's l2: 0.0055448\tvalid_1's l2: 0.0466307\n",
      "[1800]\ttraining's l2: 0.00483467\tvalid_1's l2: 0.0463829\n",
      "[2000]\ttraining's l2: 0.00435148\tvalid_1's l2: 0.0462268\n",
      "Early stopping, best iteration is:\n",
      "[1935]\ttraining's l2: 0.00448413\tvalid_1's l2: 0.0462159\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0719638\tvalid_1's l2: 0.0863845\n",
      "[400]\ttraining's l2: 0.0237687\tvalid_1's l2: 0.0470884\n",
      "[600]\ttraining's l2: 0.0160651\tvalid_1's l2: 0.0400354\n",
      "[800]\ttraining's l2: 0.0126898\tvalid_1's l2: 0.0379274\n",
      "[1000]\ttraining's l2: 0.0101744\tvalid_1's l2: 0.0371917\n",
      "[1200]\ttraining's l2: 0.00830725\tvalid_1's l2: 0.036832\n",
      "[1400]\ttraining's l2: 0.0069886\tvalid_1's l2: 0.0366827\n",
      "Early stopping, best iteration is:\n",
      "[1346]\ttraining's l2: 0.00731912\tvalid_1's l2: 0.0366539\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0706683\tvalid_1's l2: 0.0958999\n",
      "[400]\ttraining's l2: 0.0237326\tvalid_1's l2: 0.0504636\n",
      "[600]\ttraining's l2: 0.0157073\tvalid_1's l2: 0.042205\n",
      "[800]\ttraining's l2: 0.0121191\tvalid_1's l2: 0.0397557\n",
      "[1000]\ttraining's l2: 0.00950237\tvalid_1's l2: 0.0385214\n",
      "[1200]\ttraining's l2: 0.00774844\tvalid_1's l2: 0.0380873\n",
      "[1400]\ttraining's l2: 0.00651783\tvalid_1's l2: 0.0380426\n",
      "[1600]\ttraining's l2: 0.00558933\tvalid_1's l2: 0.038006\n",
      "[1800]\ttraining's l2: 0.00493514\tvalid_1's l2: 0.0378983\n",
      "[2000]\ttraining's l2: 0.00448933\tvalid_1's l2: 0.0379102\n",
      "Early stopping, best iteration is:\n",
      "[1859]\ttraining's l2: 0.00477009\tvalid_1's l2: 0.0378858\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0796086\tvalid_1's l2: 0.111992\n",
      "[400]\ttraining's l2: 0.0275633\tvalid_1's l2: 0.0650351\n",
      "[600]\ttraining's l2: 0.0183302\tvalid_1's l2: 0.0577452\n",
      "[800]\ttraining's l2: 0.0142673\tvalid_1's l2: 0.0551027\n",
      "[1000]\ttraining's l2: 0.0114731\tvalid_1's l2: 0.0541465\n",
      "[1200]\ttraining's l2: 0.00944278\tvalid_1's l2: 0.0536767\n",
      "[1400]\ttraining's l2: 0.00796949\tvalid_1's l2: 0.0531875\n",
      "[1600]\ttraining's l2: 0.00681412\tvalid_1's l2: 0.0529823\n",
      "[1800]\ttraining's l2: 0.00590666\tvalid_1's l2: 0.0527047\n",
      "[2000]\ttraining's l2: 0.00523435\tvalid_1's l2: 0.0525092\n",
      "[2200]\ttraining's l2: 0.00492946\tvalid_1's l2: 0.0524158\n",
      "Early stopping, best iteration is:\n",
      "[2087]\ttraining's l2: 0.00500334\tvalid_1's l2: 0.0524081\n",
      "fold 4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0758642\tvalid_1's l2: 0.175222\n",
      "[400]\ttraining's l2: 0.0238755\tvalid_1's l2: 0.0882258\n",
      "[600]\ttraining's l2: 0.0148054\tvalid_1's l2: 0.0703938\n",
      "[800]\ttraining's l2: 0.011127\tvalid_1's l2: 0.0652503\n",
      "[1000]\ttraining's l2: 0.00885651\tvalid_1's l2: 0.0633881\n",
      "[1200]\ttraining's l2: 0.00726363\tvalid_1's l2: 0.0620307\n",
      "[1400]\ttraining's l2: 0.00612347\tvalid_1's l2: 0.0613319\n",
      "[1600]\ttraining's l2: 0.00523956\tvalid_1's l2: 0.0610065\n",
      "[1800]\ttraining's l2: 0.00463275\tvalid_1's l2: 0.0607528\n",
      "[2000]\ttraining's l2: 0.00414116\tvalid_1's l2: 0.0606016\n",
      "[2200]\ttraining's l2: 0.00389029\tvalid_1's l2: 0.0605331\n",
      "Early stopping, best iteration is:\n",
      "[2129]\ttraining's l2: 0.00391029\tvalid_1's l2: 0.0605267\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0700134\tvalid_1's l2: 0.132909\n",
      "[400]\ttraining's l2: 0.0233448\tvalid_1's l2: 0.066823\n",
      "[600]\ttraining's l2: 0.0158373\tvalid_1's l2: 0.0551385\n",
      "[800]\ttraining's l2: 0.0125566\tvalid_1's l2: 0.051547\n",
      "[1000]\ttraining's l2: 0.0101416\tvalid_1's l2: 0.0501498\n",
      "[1200]\ttraining's l2: 0.00836686\tvalid_1's l2: 0.0492616\n",
      "[1400]\ttraining's l2: 0.00695596\tvalid_1's l2: 0.0486736\n",
      "[1600]\ttraining's l2: 0.00593705\tvalid_1's l2: 0.0484774\n",
      "[1800]\ttraining's l2: 0.0052251\tvalid_1's l2: 0.0483791\n",
      "Early stopping, best iteration is:\n",
      "[1759]\ttraining's l2: 0.00535019\tvalid_1's l2: 0.0483488\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.067868\tvalid_1's l2: 0.127791\n",
      "[400]\ttraining's l2: 0.0225025\tvalid_1's l2: 0.0692954\n",
      "[600]\ttraining's l2: 0.0148395\tvalid_1's l2: 0.0596769\n",
      "[800]\ttraining's l2: 0.0113634\tvalid_1's l2: 0.0565092\n",
      "[1000]\ttraining's l2: 0.00916327\tvalid_1's l2: 0.0549093\n",
      "[1200]\ttraining's l2: 0.00749387\tvalid_1's l2: 0.0540646\n",
      "[1400]\ttraining's l2: 0.0063612\tvalid_1's l2: 0.0537593\n",
      "[1600]\ttraining's l2: 0.00550022\tvalid_1's l2: 0.0534501\n",
      "[1800]\ttraining's l2: 0.00488577\tvalid_1's l2: 0.0532136\n",
      "[2000]\ttraining's l2: 0.00436693\tvalid_1's l2: 0.053182\n",
      "Early stopping, best iteration is:\n",
      "[1928]\ttraining's l2: 0.00452625\tvalid_1's l2: 0.0531478\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.077706\tvalid_1's l2: 0.139305\n",
      "[400]\ttraining's l2: 0.0275568\tvalid_1's l2: 0.0722875\n",
      "[600]\ttraining's l2: 0.0179607\tvalid_1's l2: 0.0623847\n",
      "[800]\ttraining's l2: 0.0137136\tvalid_1's l2: 0.0587396\n",
      "[1000]\ttraining's l2: 0.0108082\tvalid_1's l2: 0.0568336\n",
      "[1200]\ttraining's l2: 0.00877511\tvalid_1's l2: 0.0562371\n",
      "[1400]\ttraining's l2: 0.00735349\tvalid_1's l2: 0.0558\n",
      "[1600]\ttraining's l2: 0.00628409\tvalid_1's l2: 0.0558113\n",
      "Early stopping, best iteration is:\n",
      "[1510]\ttraining's l2: 0.00671718\tvalid_1's l2: 0.0557362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\ipykernel_launcher.py:157: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\ipykernel_launcher.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\ipykernel_launcher.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\ipykernel_launcher.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# 模型\n",
    "le_model = preprocessing.LabelEncoder()\n",
    "le_bodyType = preprocessing.LabelEncoder()\n",
    "\n",
    "le_model.fit(train_data.model)\n",
    "le_bodyType.fit(train_data.bodyType)\n",
    "\n",
    "lgb_params = {\n",
    "    \"num_leaves\":32,\n",
    "    \"reg_alpha\":1,\n",
    "    \"reg_lambda\":0.1,\n",
    "    \"objective\":'mse',\n",
    "    \"max_depth\": 4,\n",
    "    \"learning_rate\":0.01,\n",
    "    \"min_child_samples\":5,\n",
    "    \"random_state\":random.randint(100, 10000),\n",
    "    \"n_estimators\":5000,\n",
    "    \"subsample\":0.8,\n",
    "    \"colsample_bytree\":0.8\n",
    "}\n",
    "\n",
    "df_train_columns = [c for c in train_data.columns if c not in []]\n",
    "print(\"df_train_columns:\",df_train_columns)\n",
    "cate_fea = [\"adcode\", \"model\", \"bodyType\"]\n",
    "train_data.model = le_model.transform(train_data.model)\n",
    "train_data.bodyType = le_bodyType.transform(train_data.bodyType)\n",
    "print(train_data.shape)\n",
    "print(len(df_train_columns))\n",
    "\n",
    "\n",
    "y_score = []    # 交叉验证\n",
    "cv_pred = []    # 各折的预测值\n",
    "predictions = 0\n",
    "feature_importance_df = pd.DataFrame()\n",
    "skf = KFold(n_splits=5, random_state=random.randint(100, 10000), shuffle=True)\n",
    "\n",
    "\n",
    "label_0 = vaild_data[0]\n",
    "label_1 = vaild_data[1]\n",
    "label_2 = vaild_data[2]\n",
    "label_3 = vaild_data[3]\n",
    "\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(skf.split(train_data, label_0)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train_data.iloc[trn_idx][df_train_columns], label=label_0.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_data.iloc[val_idx][df_train_columns], label=label_0.iloc[val_idx])\n",
    "\n",
    "    result_df = train_data.iloc[val_idx][[\"adcode\", \"model\"]]\n",
    "\n",
    "    gbm_1 = lgb.train(lgb_params,\n",
    "                    trn_data,\n",
    "                    # init_model=gbm,\n",
    "                    num_boost_round=150000,\n",
    "                    valid_sets=[trn_data, val_data],\n",
    "                    early_stopping_rounds=200,\n",
    "                    verbose_eval=200,\n",
    "                    categorical_feature=cate_fea)     # 训练\n",
    "\n",
    "    trn_data = lgb.Dataset(train_data.iloc[trn_idx][df_train_columns], label=label_1.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_data.iloc[val_idx][df_train_columns], label=label_1.iloc[val_idx])\n",
    "\n",
    "    gbm_2 = lgb.train(lgb_params,\n",
    "                    trn_data,\n",
    "                    # init_model=gbm,\n",
    "                    num_boost_round=150000,\n",
    "                    valid_sets=[trn_data, val_data],\n",
    "                    early_stopping_rounds=200,\n",
    "                    verbose_eval=200,\n",
    "                    categorical_feature=cate_fea)     # 训练\n",
    "\n",
    "    trn_data = lgb.Dataset(train_data.iloc[trn_idx][df_train_columns], label=label_2.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_data.iloc[val_idx][df_train_columns], label=label_2.iloc[val_idx])\n",
    "\n",
    "    gbm_3 = lgb.train(lgb_params,\n",
    "                    trn_data,\n",
    "                    # init_model=gbm,\n",
    "                    num_boost_round=3000,\n",
    "                    valid_sets=[trn_data, val_data],\n",
    "                    early_stopping_rounds=200,\n",
    "                    verbose_eval=200,\n",
    "                    categorical_feature=cate_fea)     # 训练\n",
    "\n",
    "    trn_data = lgb.Dataset(train_data.iloc[trn_idx][df_train_columns], label=label_3.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_data.iloc[val_idx][df_train_columns], label=label_3.iloc[val_idx])\n",
    "\n",
    "    gbm_4 = lgb.train(lgb_params,\n",
    "                    trn_data,\n",
    "                    # init_model=gbm,\n",
    "                    num_boost_round=150000,\n",
    "                    valid_sets=[trn_data, val_data],\n",
    "                    early_stopping_rounds=200,\n",
    "                    verbose_eval=200,\n",
    "                    categorical_feature=cate_fea)     # 训练\n",
    "\n",
    "    result_df[\"y_pred_1\"] = gbm_1.predict(train_data.iloc[val_idx][df_train_columns])\n",
    "    result_df[\"y_pred_2\"] = gbm_2.predict(train_data.iloc[val_idx][df_train_columns])\n",
    "    result_df[\"y_pred_3\"] = gbm_3.predict(train_data.iloc[val_idx][df_train_columns])\n",
    "    result_df[\"y_pred_4\"] = gbm_4.predict(train_data.iloc[val_idx][df_train_columns])\n",
    "    # break\n",
    "\n",
    "result_df[\"y_true_1\"] = label_0\n",
    "result_df[\"y_true_2\"] = label_1\n",
    "result_df[\"y_true_3\"] = label_2\n",
    "result_df[\"y_true_4\"] = label_3\n",
    "\n",
    "# 预测\n",
    "# 基础特征\n",
    "# 城市+车\n",
    "test_basic_fea = cal_basic_fea(train_sales, \"salesVolume\", [\"adcode\", \"model\", \"regMonth\"], \"test\")\n",
    "# 城市\n",
    "tmp_df = cal_basic_fea(train_sales, \"salesVolume\", [\"adcode\", \"regMonth\"], \"test\")\n",
    "test_basic_fea = pd.merge(test_basic_fea, tmp_df, on=\"adcode\", how=\"left\")\n",
    "# 车\n",
    "tmp_df = cal_basic_fea(train_sales, \"salesVolume\", [\"model\", \"regMonth\"], \"test\")\n",
    "test_basic_fea = pd.merge(test_basic_fea, tmp_df, on=\"model\", how=\"left\")\n",
    "# 城市+车型\n",
    "tmp_df = cal_basic_fea(train_sales, \"salesVolume\", [\"adcode\", \"bodyType\", \"regMonth\"], \"test\")\n",
    "test_basic_fea[\"bodyType\"] = test_basic_fea.model.apply(lambda x: model2type[x])\n",
    "test_basic_fea = pd.merge(test_basic_fea, tmp_df, on=[\"adcode\", \"bodyType\"], how=\"left\")\n",
    "\n",
    "# 滑窗特征\n",
    "# 城市+车\n",
    "test_windows_fea = cal_windows_fea(train_sales, cal_col=\"salesVolume\", stat_dim=[\"adcode\", \"model\", \"regMonth\"], data_type=\"test\")\n",
    "# 城市\n",
    "tmp_df = cal_windows_fea(train_sales, \"salesVolume\", [\"adcode\", \"regMonth\"], \"test\")\n",
    "test_windows_fea = pd.merge(test_windows_fea, tmp_df, on=\"adcode\", how=\"left\")\n",
    "# 车\n",
    "tmp_df = cal_windows_fea(train_sales, \"salesVolume\", [\"model\", \"regMonth\"], \"test\")\n",
    "test_windows_fea = pd.merge(test_windows_fea, tmp_df, on=\"model\", how=\"left\")\n",
    "# 城市+车型\n",
    "tmp_df = cal_windows_fea(train_sales, \"salesVolume\", [\"adcode\", \"bodyType\", \"regMonth\"], \"test\")\n",
    "test_windows_fea[\"bodyType\"] = test_windows_fea.model.apply(lambda x: model2type[x])\n",
    "test_windows_fea = pd.merge(test_windows_fea, tmp_df, on=[\"adcode\", \"bodyType\"], how=\"left\")\n",
    "\n",
    "# 合并\n",
    "test_data = pd.merge(test_basic_fea, test_windows_fea, on=[\"adcode\", \"model\", \"bodyType\"], how=\"left\")\n",
    "\n",
    "test_data.model = le_model.transform(test_data.model)\n",
    "test_data.bodyType = le_bodyType.transform(test_data.bodyType)\n",
    "\n",
    "y_pred_1 = gbm_1.predict(test_data[df_train_columns])\n",
    "y_pred_2 = gbm_2.predict(test_data[df_train_columns])\n",
    "y_pred_3 = gbm_3.predict(test_data[df_train_columns])\n",
    "y_pred_4 = gbm_4.predict(test_data[df_train_columns])\n",
    "\n",
    "y_pred_1 = (np.e ** y_pred_1 - 1).astype(int)\n",
    "y_pred_2 = (np.e ** y_pred_2 - 1).astype(int)\n",
    "y_pred_3 = (np.e ** y_pred_3 - 1).astype(int)\n",
    "y_pred_4 = (np.e ** y_pred_4 - 1).astype(int)\n",
    "\n",
    "result_df = test_basic_fea[[\"adcode\", \"model\"]]\n",
    "result_df[\"y_pred_1\"] = y_pred_1\n",
    "result_df[\"y_pred_2\"] = y_pred_2\n",
    "result_df[\"y_pred_3\"] = y_pred_3\n",
    "result_df[\"y_pred_4\"] = y_pred_4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(TEST_PATH)\n",
    "test_data = test_data.drop(\"forecastVolum\", axis=1)\n",
    "test_data_1 = pd.merge(test_data.loc[test_data.regMonth == 1], result_df[[\"adcode\", \"model\", \"y_pred_1\"]].rename(columns={\"y_pred_1\":\"forecastVolum\"}),\\\n",
    "                       how=\"left\", on=[\"adcode\", \"model\"])\n",
    "test_data_2 = pd.merge(test_data.loc[test_data.regMonth == 2], result_df[[\"adcode\", \"model\", \"y_pred_2\"]].rename(columns={\"y_pred_2\":\"forecastVolum\"}),\\\n",
    "                       how=\"left\", on=[\"adcode\", \"model\"])\n",
    "test_data_3 = pd.merge(test_data.loc[test_data.regMonth == 3], result_df[[\"adcode\", \"model\", \"y_pred_3\"]].rename(columns={\"y_pred_3\":\"forecastVolum\"}),\\\n",
    "                       how=\"left\", on=[\"adcode\", \"model\"])\n",
    "test_data_4 = pd.merge(test_data.loc[test_data.regMonth == 4], result_df[[\"adcode\", \"model\", \"y_pred_4\"]].rename(columns={\"y_pred_4\":\"forecastVolum\"}),\\\n",
    "                       how=\"left\", on=[\"adcode\", \"model\"])\n",
    "result = pd.concat([test_data_1, test_data_2, test_data_3, test_data_4]).reset_index(drop=True)\n",
    "result.forecastVolum = result.forecastVolum.astype(int)\n",
    "result.loc[(result.forecastVolum < 0), \"forecastVolum\"] = 1\n",
    "print((result.forecastVolum < 0 ).sum())\n",
    "result[[\"id\", \"forecastVolum\"]].to_csv(\"submit/evaluation_public_2019091602_lgb.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
