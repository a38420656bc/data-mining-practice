{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# from __future__ import print_function\n",
    "# import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "# %matplotlib inline\n",
    "np.random.seed(1671) # for reproducibility\n",
    "# from help_function import LoadData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"nn_all_data.csv\")\n",
    "train = data[data['mt']<25]\n",
    "test = data[data['mt']>=25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adcode',\n",
       " 'bodyType',\n",
       " 'forecastVolum',\n",
       " 'id',\n",
       " 'model',\n",
       " 'province',\n",
       " 'regMonth',\n",
       " 'regYear',\n",
       " 'salesVolume',\n",
       " 'popularity',\n",
       " 'carCommentVolum',\n",
       " 'newsReplyVolum',\n",
       " 'label',\n",
       " 'mt',\n",
       " 'model_adcode',\n",
       " 'windows4_var',\n",
       " 'windows5_var',\n",
       " 'windows12_var',\n",
       " 'model_adcode_mt',\n",
       " 'model_adcode_mt_label_1',\n",
       " 'shift_model_adcode_mt_label_1',\n",
       " 'model_adcode_mt_label_2',\n",
       " 'shift_model_adcode_mt_label_2',\n",
       " 'model_adcode_mt_label_3',\n",
       " 'shift_model_adcode_mt_label_3',\n",
       " 'model_adcode_mt_label_4',\n",
       " 'shift_model_adcode_mt_label_4',\n",
       " 'model_adcode_mt_label_5',\n",
       " 'shift_model_adcode_mt_label_5',\n",
       " 'model_adcode_mt_label_6',\n",
       " 'shift_model_adcode_mt_label_6',\n",
       " 'model_adcode_mt_label_7',\n",
       " 'shift_model_adcode_mt_label_7',\n",
       " 'model_adcode_mt_label_8',\n",
       " 'shift_model_adcode_mt_label_8',\n",
       " 'model_adcode_mt_label_9',\n",
       " 'shift_model_adcode_mt_label_9',\n",
       " 'model_adcode_mt_label_10',\n",
       " 'shift_model_adcode_mt_label_10',\n",
       " 'model_adcode_mt_label_11',\n",
       " 'shift_model_adcode_mt_label_11',\n",
       " 'model_adcode_mt_label_12',\n",
       " 'shift_model_adcode_mt_label_12',\n",
       " 'differ_label_1',\n",
       " 'differ_label_2',\n",
       " 'differ_label_3',\n",
       " 'differ_label_4',\n",
       " 'differ2_label_1',\n",
       " 'differ2_label_2',\n",
       " 'differ2_label_3',\n",
       " 'model_adcode_mt_popularity_1',\n",
       " 'shift_model_adcode_mt_popularity_1',\n",
       " 'model_adcode_mt_popularity_2',\n",
       " 'shift_model_adcode_mt_popularity_2',\n",
       " 'model_adcode_mt_popularity_3',\n",
       " 'shift_model_adcode_mt_popularity_3',\n",
       " 'model_adcode_mt_popularity_4',\n",
       " 'shift_model_adcode_mt_popularity_4',\n",
       " 'model_adcode_mt_popularity_5',\n",
       " 'shift_model_adcode_mt_popularity_5',\n",
       " 'model_adcode_mt_popularity_6',\n",
       " 'shift_model_adcode_mt_popularity_6',\n",
       " 'model_adcode_mt_popularity_7',\n",
       " 'shift_model_adcode_mt_popularity_7',\n",
       " 'model_adcode_mt_popularity_8',\n",
       " 'shift_model_adcode_mt_popularity_8',\n",
       " 'model_adcode_mt_popularity_9',\n",
       " 'shift_model_adcode_mt_popularity_9',\n",
       " 'model_adcode_mt_popularity_10',\n",
       " 'shift_model_adcode_mt_popularity_10',\n",
       " 'model_adcode_mt_popularity_11',\n",
       " 'shift_model_adcode_mt_popularity_11',\n",
       " 'model_adcode_mt_popularity_12',\n",
       " 'shift_model_adcode_mt_popularity_12',\n",
       " 'differ_popularity_1',\n",
       " 'differ_popularity_2',\n",
       " 'differ_popularity_3',\n",
       " 'differ_popularity_4',\n",
       " 'differ2_popularity_1',\n",
       " 'differ2_popularity_2',\n",
       " 'differ2_popularity_3']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = list(train.columns)\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "## load data\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "epochs = 3\n",
    "batch_size = 1024\n",
    "classes = 1\n",
    "\n",
    "## category feature one_hot\n",
    "test_data['label'] = -1\n",
    "data = pd.concat([train_data, test_data])\n",
    "cate_feature = ['gender', 'cell_province', 'id_province', 'id_city', 'rate', 'term']\n",
    "for item in cate_feature:\n",
    "    data[item] = LabelEncoder().fit_transform(data[item])\n",
    "    item_dummies = pd.get_dummies(data[item])\n",
    "    item_dummies.columns = [item + str(i + 1) for i in range(item_dummies.shape[1])]\n",
    "    data = pd.concat([data, item_dummies], axis=1)\n",
    "data.drop(cate_feature,axis=1,inplace=True)\n",
    "\n",
    "train = data[data['label'] != -1]\n",
    "test = data[data['label'] == -1]\n",
    "\n",
    "##Clean up the memory\n",
    "del data, train_data, test_data\n",
    "gc.collect()\n",
    "\n",
    "## get train feature\n",
    "del_feature = ['auditing_date', 'due_date', 'label']\n",
    "features = [i for i in train.columns if i not in del_feature]\n",
    "\n",
    "train_x = train[features]\n",
    "train_y = train['label'].values\n",
    "test = test[features]\n",
    "\n",
    "## Fill missing value\n",
    "for i in train_x.columns:\n",
    "    # print(i, train_x[i].isnull().sum(), test[i].isnull().sum())\n",
    "    if train_x[i].isnull().sum() != 0:\n",
    "        train_x[i].fillna(-1, inplace=True)\n",
    "        test[i].fillna(-1, inplace=True)\n",
    "\n",
    "## normalized\n",
    "scaler = StandardScaler()\n",
    "train_X = scaler.fit_transform(train_x)\n",
    "test_X = scaler.transform(test)\n",
    "\n",
    "K.clear_session()\n",
    "def MLP(dropout_rate=0.25, activation='relu'):\n",
    "    start_neurons = 512\n",
    "    model = Sequential()\n",
    "    model.add(Dense(start_neurons, input_dim=train_X.shape[1], activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(start_neurons // 2, activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(start_neurons // 4, activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(start_neurons // 8, activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate / 2))\n",
    "\n",
    "    model.add(Dense(classes, activation='linear'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def plot_loss_acc(history, fold):\n",
    "    plt.plot(history.history['loss'][1:])\n",
    "    plt.plot(history.history['val_loss'][1:])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('val_loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'Validation'], loc='upper left')\n",
    "    plt.savefig('../../result/model_loss' + str(fold) + '.png')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(history.history['acc'][1:])\n",
    "    plt.plot(history.history['val_acc'][1:])\n",
    "    plt.title('model Accuracy')\n",
    "    plt.ylabel('val_acc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'Validation'], loc='upper left')\n",
    "    plt.savefig('../../result/model_accuracy' + str(fold) + '.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "NN_predictions = np.zeros((test_X.shape[0], 1))\n",
    "oof_preds = np.zeros((train_X.shape[0], 1))\n",
    "\n",
    "patience = 50   ## How many steps to stop\n",
    "call_ES = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=patience, verbose=1,\n",
    "                                        mode='auto', baseline=None)\n",
    "\n",
    "for fold_, (trn_, val_) in enumerate(folds.split(train_x)):\n",
    "    print(\"fold {}\".format(fold_ + 1))\n",
    "    x_train, y_train = train_X[trn_], train_y[trn_]\n",
    "    x_valid, y_valid = train_X[val_], train_y[val_]\n",
    "\n",
    "\n",
    "    model = MLP(dropout_rate=0.5, activation='relu')\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae', 'acc'])\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        validation_data=[x_valid, y_valid],\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        callbacks=[call_ES, ],\n",
    "                        shuffle=True,\n",
    "                        verbose=1)\n",
    "\n",
    "    # plot_loss_acc(history, fold_ + 1)\n",
    "\n",
    "    print('Loading Best Model')\n",
    "    # # Get predicted probabilities for each class\n",
    "    oof_preds[val_] = model.predict(x_valid, batch_size=batch_size)\n",
    "    NN_predictions += model.predict(test_X, batch_size=batch_size) / folds.n_splits\n",
    "\n",
    "print(NN_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
