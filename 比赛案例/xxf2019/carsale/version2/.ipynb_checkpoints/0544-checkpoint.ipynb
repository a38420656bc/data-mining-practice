{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SALES_DATA_PATH = \"data/train_sales_data.csv\"\n",
    "TRAIN_SEARCH_DATA_PATH = \"data/train_search_data.csv\"\n",
    "TRAIN_USER_REPLY_DATA_PATH = \"data/train_user_reply_data.csv\"\n",
    "TEST_PATH = \"data/evaluation_public.csv\"\n",
    "\n",
    "# import re\n",
    "# import gc\n",
    "# import os\n",
    "# import csv\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook, trange\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "# import catboost as cb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df, data_type):\n",
    "    if data_type == \"train\":\n",
    "        return df[df.regYear == 2016]\n",
    "    elif data_type == \"test\":\n",
    "        return df[df.regYear == 2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'data/train_sales_data.csv' does not exist: b'data/train_sales_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-2f12aa99dd9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_sales\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTRAIN_SALES_DATA_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtrain_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTRAIN_SEARCH_DATA_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrain_user\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTRAIN_USER_REPLY_DATA_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTEST_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'data/train_sales_data.csv' does not exist: b'data/train_sales_data.csv'"
     ]
    }
   ],
   "source": [
    "train_sales = pd.read_csv(TRAIN_SALES_DATA_PATH)\n",
    "train_search = pd.read_csv(TRAIN_SEARCH_DATA_PATH)\n",
    "train_user = pd.read_csv(TRAIN_USER_REPLY_DATA_PATH)\n",
    "test_data = pd.read_csv(TEST_PATH)\n",
    "\n",
    "train_sales.salesVolume = train_sales.salesVolume.apply(lambda x: np.log(1+x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征工程\n",
    "def cal_basic_fea(df:pd.DataFrame, cal_col:str, stat_dim:list, data_type:str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    计算原始特征、周期特征、趋势特征\n",
    "    \"\"\"\n",
    "    train_sales_data = get_data(train_sales, data_type)\n",
    "\n",
    "    name_prefix = \"_\".join(stat_dim) + \"_%s\"%cal_col\n",
    "    drop_name = \"level_%d\"%len(stat_dim)\n",
    "\n",
    "    # 原始特征\n",
    "    feature_data = train_sales_data.groupby(stat_dim)[cal_col].apply(lambda x: x.sum()).unstack(level=-1)\n",
    "    feature_data.columns = [name_prefix + \"_%d\"%x for x in feature_data.columns.ravel()]\n",
    "    feature_data = feature_data.reset_index()\n",
    "\n",
    "    # 周期特征\n",
    "    ## shift_div\n",
    "    tmp_df = train_sales_data.groupby(stat_dim)[cal_col].apply(lambda x: x.sum()).groupby(stat_dim[:-1]).apply(lambda x: x / x.shift(1)).reset_index()\n",
    "\n",
    "    tmp_df = tmp_df.rename(columns={\"salesVolume\":\"shift_div\"})\n",
    "\n",
    "    train_sales_data = pd.merge(train_sales_data, tmp_df, on=stat_dim, how=\"left\")\n",
    "\n",
    "    tmp_df = train_sales_data.dropna().groupby(stat_dim).shift_div.apply(lambda x: x.sum()).unstack(level=-1)\n",
    "\n",
    "    tmp_df.columns = [name_prefix + \"_shift_div_%d\"%x for x in tmp_df.columns.ravel()]\n",
    "\n",
    "    feature_data = pd.merge(feature_data, tmp_df, on=stat_dim[:-1], how=\"left\")\n",
    "\n",
    "    ## shift_sub\n",
    "    tmp_df = train_sales_data.groupby(stat_dim)[cal_col].apply(lambda x: x.sum()).groupby(stat_dim[:-1]).apply(lambda x: x - x.shift(1)).reset_index()\n",
    "\n",
    "    tmp_df = tmp_df.rename(columns={\"salesVolume\":\"shift_sub\"})\n",
    "\n",
    "    train_sales_data = pd.merge(train_sales_data, tmp_df, on=stat_dim, how=\"left\")\n",
    "\n",
    "    tmp_df = train_sales_data.dropna().groupby(stat_dim).shift_sub.apply(lambda x: x.sum()).unstack(level=-1)\n",
    "\n",
    "    tmp_df.columns = [name_prefix + \"_shift_sub_%d\"%x for x in tmp_df.columns.ravel()]\n",
    "\n",
    "    feature_data = pd.merge(feature_data, tmp_df, on=stat_dim[:-1], how=\"left\")\n",
    "\n",
    "    # 趋势特征\n",
    "    ## shift_div\n",
    "    tmp_df = train_sales_data.groupby(stat_dim)[\"shift_div\"].apply(lambda x: x.sum()).groupby(stat_dim[:-1]).apply(lambda x: x / x.shift(1)).reset_index()\n",
    "\n",
    "    tmp_df = tmp_df.rename(columns={\"shift_div\":\"shift_2_div\"})\n",
    "\n",
    "    train_sales_data = pd.merge(train_sales_data, tmp_df, on=stat_dim, how=\"left\")\n",
    "\n",
    "    tmp_df = train_sales_data.dropna().groupby(stat_dim).shift_div.apply(lambda x: x.sum()).unstack(level=-1)\n",
    "\n",
    "    tmp_df.columns = [name_prefix + \"_shift_2_div_%d\"%x for x in tmp_df.columns.ravel()]\n",
    "\n",
    "    feature_data = pd.merge(feature_data, tmp_df, on=stat_dim[:-1], how=\"left\")\n",
    "\n",
    "    ## shift_sub\n",
    "    tmp_df = train_sales_data.groupby(stat_dim)[\"shift_sub\"].apply(lambda x: x.sum()).groupby(stat_dim[:-1]).apply(lambda x: x - x.shift(1)).reset_index()\n",
    "\n",
    "    tmp_df = tmp_df.rename(columns={\"shift_sub\":\"shift_2_sub\"})\n",
    "\n",
    "    train_sales_data = pd.merge(train_sales_data, tmp_df, on=stat_dim, how=\"left\")\n",
    "\n",
    "    tmp_df = train_sales_data.dropna().groupby(stat_dim).shift_sub.apply(lambda x: x.sum()).unstack(level=-1)\n",
    "\n",
    "    tmp_df.columns = [name_prefix + \"_shift_2_sub_%d\"%x for x in tmp_df.columns.ravel()]\n",
    "\n",
    "    feature_data = pd.merge(feature_data, tmp_df, on=stat_dim[:-1], how=\"left\")\n",
    "    return feature_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_windows_fea(df:pd.DataFrame, cal_col:str, stat_dim:list, data_type:str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    计算滑窗特征\n",
    "    \"\"\"\n",
    "    train_sales_data = get_data(df, data_type)\n",
    "\n",
    "    name_prefix = \"_\".join(stat_dim) + \"_%s\"%cal_col\n",
    "\n",
    "    # 滑窗特征\n",
    "    ## mean\n",
    "    feature_data = train_sales_data.groupby(stat_dim)[cal_col].apply(lambda x: x.sum()).groupby(stat_dim[:-1]).rolling(3).mean()\n",
    "\n",
    "    feature_data = feature_data.dropna().unstack(level=-1)\n",
    "\n",
    "    if len(stat_dim) == 3:\n",
    "        feature_data.index = feature_data.index.droplevel(0)\n",
    "        feature_data.index = feature_data.index.droplevel(0)\n",
    "    elif len(stat_dim) == 2:\n",
    "        feature_data.index = feature_data.index.droplevel(0)\n",
    "\n",
    "\n",
    "    feature_data.reset_index(inplace=True)\n",
    "    feature_data = feature_data.rename(columns={k:\"%s_rolling_mean_%d\"%(name_prefix, k) for k in range(13)})\n",
    "\n",
    "    ## std\n",
    "    tmp_df = train_sales_data.groupby(stat_dim)[cal_col].apply(lambda x: x.sum()).groupby(stat_dim[:-1]).rolling(3).std()\n",
    "\n",
    "    tmp_df = tmp_df.dropna().unstack(level=-1)\n",
    "\n",
    "    if len(stat_dim) == 3:\n",
    "        tmp_df.index = tmp_df.index.droplevel(0)\n",
    "        tmp_df.index = tmp_df.index.droplevel(0)\n",
    "    elif len(stat_dim) == 2:\n",
    "        tmp_df.index = tmp_df.index.droplevel(0)\n",
    "\n",
    "\n",
    "    tmp_df.reset_index(inplace=True)\n",
    "    tmp_df = tmp_df.rename(columns={k:\"%s_rolling_std_%d\"%(name_prefix, k) for k in range(13)})\n",
    "\n",
    "    feature_data = pd.merge(feature_data, tmp_df, on=stat_dim[:-1], how=\"left\")\n",
    "    \n",
    "    ## var\n",
    "    tmp_df = train_sales_data.groupby(stat_dim)[cal_col].apply(lambda x: x.sum()).groupby(stat_dim[:-1]).rolling(3).var()\n",
    "\n",
    "    tmp_df = tmp_df.dropna().unstack(level=-1)\n",
    "\n",
    "    if len(stat_dim) == 3:\n",
    "        tmp_df.index = tmp_df.index.droplevel(0)\n",
    "        tmp_df.index = tmp_df.index.droplevel(0)\n",
    "    elif len(stat_dim) == 2:\n",
    "        tmp_df.index = tmp_df.index.droplevel(0)\n",
    "\n",
    "\n",
    "    tmp_df.reset_index(inplace=True)\n",
    "    tmp_df = tmp_df.rename(columns={k:\"%s_rolling_std_%d\"%(name_prefix, k) for k in range(13)})\n",
    "\n",
    "    feature_data = pd.merge(feature_data, tmp_df, on=stat_dim[:-1], how=\"left\")\n",
    "    \n",
    "\n",
    "    ## sum\n",
    "    tmp_df = train_sales_data.groupby(stat_dim)[cal_col].apply(lambda x: x.sum()).groupby(stat_dim[:-1]).rolling(3).sum()\n",
    "\n",
    "    tmp_df = tmp_df.dropna().unstack(level=-1)\n",
    "\n",
    "    if len(stat_dim) == 3:\n",
    "        tmp_df.index = tmp_df.index.droplevel(0)\n",
    "        tmp_df.index = tmp_df.index.droplevel(0)\n",
    "    elif len(stat_dim) == 2:\n",
    "        tmp_df.index = tmp_df.index.droplevel(0)\n",
    "\n",
    "    tmp_df.reset_index(inplace=True)\n",
    "    tmp_df = tmp_df.rename(columns={k:\"%s_rolling_sum_%d\"%(name_prefix, k) for k in range(13)})\n",
    "\n",
    "    feature_data = pd.merge(feature_data, tmp_df, on=stat_dim[:-1], how=\"left\")\n",
    "    \n",
    "    # 滑窗特征2222222222222222\n",
    "    ## mean\n",
    "    feature_data = train_sales_data.groupby(stat_dim)[cal_col].apply(lambda x: x.sum()).groupby(stat_dim[:-1]).rolling(4).mean()\n",
    "\n",
    "    feature_data = feature_data.dropna().unstack(level=-1)\n",
    "\n",
    "    if len(stat_dim) == 3:\n",
    "        feature_data.index = feature_data.index.droplevel(0)\n",
    "        feature_data.index = feature_data.index.droplevel(0)\n",
    "    elif len(stat_dim) == 2:\n",
    "        feature_data.index = feature_data.index.droplevel(0)\n",
    "\n",
    "\n",
    "    feature_data.reset_index(inplace=True)\n",
    "    feature_data = feature_data.rename(columns={k:\"%s_rolling_mean_%d\"%(name_prefix, k) for k in range(13)})\n",
    "\n",
    "    ## std\n",
    "    tmp_df = train_sales_data.groupby(stat_dim)[cal_col].apply(lambda x: x.sum()).groupby(stat_dim[:-1]).rolling(4).std()\n",
    "\n",
    "    tmp_df = tmp_df.dropna().unstack(level=-1)\n",
    "\n",
    "    if len(stat_dim) == 3:\n",
    "        tmp_df.index = tmp_df.index.droplevel(0)\n",
    "        tmp_df.index = tmp_df.index.droplevel(0)\n",
    "    elif len(stat_dim) == 2:\n",
    "        tmp_df.index = tmp_df.index.droplevel(0)\n",
    "\n",
    "\n",
    "    tmp_df.reset_index(inplace=True)\n",
    "    tmp_df = tmp_df.rename(columns={k:\"%s_rolling_std_%d\"%(name_prefix, k) for k in range(13)})\n",
    "\n",
    "    feature_data = pd.merge(feature_data, tmp_df, on=stat_dim[:-1], how=\"left\")\n",
    "    \n",
    "\n",
    "\n",
    "    ## sum\n",
    "    tmp_df = train_sales_data.groupby(stat_dim)[cal_col].apply(lambda x: x.sum()).groupby(stat_dim[:-1]).rolling(4).sum()\n",
    "\n",
    "    tmp_df = tmp_df.dropna().unstack(level=-1)\n",
    "\n",
    "    if len(stat_dim) == 3:\n",
    "        tmp_df.index = tmp_df.index.droplevel(0)\n",
    "        tmp_df.index = tmp_df.index.droplevel(0)\n",
    "    elif len(stat_dim) == 2:\n",
    "        tmp_df.index = tmp_df.index.droplevel(0)\n",
    "\n",
    "    tmp_df.reset_index(inplace=True)\n",
    "    tmp_df = tmp_df.rename(columns={k:\"%s_rolling_sum_%d\"%(name_prefix, k) for k in range(13)})\n",
    "\n",
    "    feature_data = pd.merge(feature_data, tmp_df, on=stat_dim[:-1], how=\"left\")\n",
    "    return feature_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_sales' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4e909a507868>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel2type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_sales\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"bodyType\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"bodyType\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# 城市+车\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrain_basic_fea\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcal_basic_fea\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_sales\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"salesVolume\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"adcode\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"regMonth\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"train\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_sales' is not defined"
     ]
    }
   ],
   "source": [
    "model2type = train_sales[[\"model\", \"bodyType\"]].drop_duplicates().set_index(\"model\").to_dict()[\"bodyType\"]\n",
    "# 城市+车\n",
    "train_basic_fea = cal_basic_fea(train_sales, \"salesVolume\", [\"adcode\", \"model\", \"regMonth\"], \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立车型与型号的对应字典\n",
    "model2type = train_sales[[\"model\", \"bodyType\"]].drop_duplicates().set_index(\"model\").to_dict()[\"bodyType\"]\n",
    "# 城市+车\n",
    "train_basic_fea = cal_basic_fea(train_sales, \"salesVolume\", [\"adcode\", \"model\", \"regMonth\"], \"train\")\n",
    "# 城市\n",
    "tmp_df = cal_basic_fea(train_sales, \"salesVolume\", [\"adcode\", \"regMonth\"], \"train\")\n",
    "train_basic_fea = pd.merge(train_basic_fea, tmp_df, on=\"adcode\", how=\"left\")\n",
    "# 车\n",
    "tmp_df = cal_basic_fea(train_sales, \"salesVolume\", [\"model\", \"regMonth\"], \"train\")\n",
    "train_basic_fea = pd.merge(train_basic_fea, tmp_df, on=\"model\", how=\"left\")\n",
    "# 城市+车型\n",
    "tmp_df = cal_basic_fea(train_sales, \"salesVolume\", [\"adcode\", \"bodyType\", \"regMonth\"], \"train\")\n",
    "train_basic_fea[\"bodyType\"] = train_basic_fea.model.apply(lambda x: model2type[x])\n",
    "train_basic_fea = pd.merge(train_basic_fea, tmp_df, on=[\"adcode\", \"bodyType\"], how=\"left\")\n",
    "\n",
    "\n",
    "# cal_windows_fea\n",
    "# 城市+车\n",
    "train_windows_fea = cal_windows_fea(train_sales, cal_col=\"salesVolume\", stat_dim=[\"adcode\", \"model\", \"regMonth\"], data_type=\"train\")\n",
    "# 城市\n",
    "tmp_df = cal_windows_fea(train_sales, \"salesVolume\", [\"adcode\", \"regMonth\"], \"train\")\n",
    "train_windows_fea = pd.merge(train_windows_fea, tmp_df, on=\"adcode\", how=\"left\")\n",
    "# 车\n",
    "tmp_df = cal_windows_fea(train_sales, \"salesVolume\", [\"model\", \"regMonth\"], \"train\")\n",
    "train_windows_fea = pd.merge(train_windows_fea, tmp_df, on=\"model\", how=\"left\")\n",
    "# 城市+车型\n",
    "tmp_df = cal_windows_fea(train_sales, \"salesVolume\", [\"adcode\", \"bodyType\", \"regMonth\"], \"train\")\n",
    "train_windows_fea[\"bodyType\"] = train_windows_fea.model.apply(lambda x: model2type[x])\n",
    "train_windows_fea = pd.merge(train_windows_fea, tmp_df, on=[\"adcode\", \"bodyType\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adcode</th>\n",
       "      <th>model</th>\n",
       "      <th>adcode_model_regMonth_salesVolume_1</th>\n",
       "      <th>adcode_model_regMonth_salesVolume_2</th>\n",
       "      <th>adcode_model_regMonth_salesVolume_3</th>\n",
       "      <th>adcode_model_regMonth_salesVolume_4</th>\n",
       "      <th>adcode_model_regMonth_salesVolume_5</th>\n",
       "      <th>adcode_model_regMonth_salesVolume_6</th>\n",
       "      <th>adcode_model_regMonth_salesVolume_7</th>\n",
       "      <th>adcode_model_regMonth_salesVolume_8</th>\n",
       "      <th>...</th>\n",
       "      <th>adcode_bodyType_regMonth_salesVolume_rolling_std_12</th>\n",
       "      <th>adcode_bodyType_regMonth_salesVolume_rolling_sum_4</th>\n",
       "      <th>adcode_bodyType_regMonth_salesVolume_rolling_sum_5</th>\n",
       "      <th>adcode_bodyType_regMonth_salesVolume_rolling_sum_6</th>\n",
       "      <th>adcode_bodyType_regMonth_salesVolume_rolling_sum_7</th>\n",
       "      <th>adcode_bodyType_regMonth_salesVolume_rolling_sum_8</th>\n",
       "      <th>adcode_bodyType_regMonth_salesVolume_rolling_sum_9</th>\n",
       "      <th>adcode_bodyType_regMonth_salesVolume_rolling_sum_10</th>\n",
       "      <th>adcode_bodyType_regMonth_salesVolume_rolling_sum_11</th>\n",
       "      <th>adcode_bodyType_regMonth_salesVolume_rolling_sum_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>110000</td>\n",
       "      <td>02aab221aabc03b9</td>\n",
       "      <td>6.684612</td>\n",
       "      <td>6.052089</td>\n",
       "      <td>6.598509</td>\n",
       "      <td>6.302619</td>\n",
       "      <td>6.340359</td>\n",
       "      <td>6.472346</td>\n",
       "      <td>6.618739</td>\n",
       "      <td>6.742881</td>\n",
       "      <td>...</td>\n",
       "      <td>8.657722</td>\n",
       "      <td>639.799585</td>\n",
       "      <td>636.69988</td>\n",
       "      <td>655.841951</td>\n",
       "      <td>654.532863</td>\n",
       "      <td>655.573478</td>\n",
       "      <td>655.266455</td>\n",
       "      <td>647.766958</td>\n",
       "      <td>648.454342</td>\n",
       "      <td>659.300918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>110000</td>\n",
       "      <td>04e66e578f653ab9</td>\n",
       "      <td>4.912655</td>\n",
       "      <td>4.060443</td>\n",
       "      <td>5.081404</td>\n",
       "      <td>4.955827</td>\n",
       "      <td>4.976734</td>\n",
       "      <td>5.062595</td>\n",
       "      <td>5.111988</td>\n",
       "      <td>5.068904</td>\n",
       "      <td>...</td>\n",
       "      <td>8.657722</td>\n",
       "      <td>639.799585</td>\n",
       "      <td>636.69988</td>\n",
       "      <td>655.841951</td>\n",
       "      <td>654.532863</td>\n",
       "      <td>655.573478</td>\n",
       "      <td>655.266455</td>\n",
       "      <td>647.766958</td>\n",
       "      <td>648.454342</td>\n",
       "      <td>659.300918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>110000</td>\n",
       "      <td>06880909932890ca</td>\n",
       "      <td>6.771936</td>\n",
       "      <td>5.288267</td>\n",
       "      <td>6.204558</td>\n",
       "      <td>6.063785</td>\n",
       "      <td>6.220590</td>\n",
       "      <td>6.003887</td>\n",
       "      <td>6.376727</td>\n",
       "      <td>6.395262</td>\n",
       "      <td>...</td>\n",
       "      <td>8.657722</td>\n",
       "      <td>639.799585</td>\n",
       "      <td>636.69988</td>\n",
       "      <td>655.841951</td>\n",
       "      <td>654.532863</td>\n",
       "      <td>655.573478</td>\n",
       "      <td>655.266455</td>\n",
       "      <td>647.766958</td>\n",
       "      <td>648.454342</td>\n",
       "      <td>659.300918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>110000</td>\n",
       "      <td>0797526c057dcf5b</td>\n",
       "      <td>5.736572</td>\n",
       "      <td>4.672829</td>\n",
       "      <td>6.129050</td>\n",
       "      <td>6.363028</td>\n",
       "      <td>6.429719</td>\n",
       "      <td>6.498282</td>\n",
       "      <td>6.548219</td>\n",
       "      <td>6.612041</td>\n",
       "      <td>...</td>\n",
       "      <td>8.657722</td>\n",
       "      <td>639.799585</td>\n",
       "      <td>636.69988</td>\n",
       "      <td>655.841951</td>\n",
       "      <td>654.532863</td>\n",
       "      <td>655.573478</td>\n",
       "      <td>655.266455</td>\n",
       "      <td>647.766958</td>\n",
       "      <td>648.454342</td>\n",
       "      <td>659.300918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>110000</td>\n",
       "      <td>12f8b7e14947c34d</td>\n",
       "      <td>6.390241</td>\n",
       "      <td>5.393628</td>\n",
       "      <td>5.849325</td>\n",
       "      <td>5.837730</td>\n",
       "      <td>5.926926</td>\n",
       "      <td>5.849325</td>\n",
       "      <td>6.063785</td>\n",
       "      <td>5.986452</td>\n",
       "      <td>...</td>\n",
       "      <td>8.657722</td>\n",
       "      <td>639.799585</td>\n",
       "      <td>636.69988</td>\n",
       "      <td>655.841951</td>\n",
       "      <td>654.532863</td>\n",
       "      <td>655.573478</td>\n",
       "      <td>655.266455</td>\n",
       "      <td>647.766958</td>\n",
       "      <td>648.454342</td>\n",
       "      <td>659.300918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 335 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adcode             model  adcode_model_regMonth_salesVolume_1  \\\n",
       "0  110000  02aab221aabc03b9                             6.684612   \n",
       "1  110000  04e66e578f653ab9                             4.912655   \n",
       "2  110000  06880909932890ca                             6.771936   \n",
       "3  110000  0797526c057dcf5b                             5.736572   \n",
       "4  110000  12f8b7e14947c34d                             6.390241   \n",
       "\n",
       "   adcode_model_regMonth_salesVolume_2  adcode_model_regMonth_salesVolume_3  \\\n",
       "0                             6.052089                             6.598509   \n",
       "1                             4.060443                             5.081404   \n",
       "2                             5.288267                             6.204558   \n",
       "3                             4.672829                             6.129050   \n",
       "4                             5.393628                             5.849325   \n",
       "\n",
       "   adcode_model_regMonth_salesVolume_4  adcode_model_regMonth_salesVolume_5  \\\n",
       "0                             6.302619                             6.340359   \n",
       "1                             4.955827                             4.976734   \n",
       "2                             6.063785                             6.220590   \n",
       "3                             6.363028                             6.429719   \n",
       "4                             5.837730                             5.926926   \n",
       "\n",
       "   adcode_model_regMonth_salesVolume_6  adcode_model_regMonth_salesVolume_7  \\\n",
       "0                             6.472346                             6.618739   \n",
       "1                             5.062595                             5.111988   \n",
       "2                             6.003887                             6.376727   \n",
       "3                             6.498282                             6.548219   \n",
       "4                             5.849325                             6.063785   \n",
       "\n",
       "   adcode_model_regMonth_salesVolume_8  ...  \\\n",
       "0                             6.742881  ...   \n",
       "1                             5.068904  ...   \n",
       "2                             6.395262  ...   \n",
       "3                             6.612041  ...   \n",
       "4                             5.986452  ...   \n",
       "\n",
       "   adcode_bodyType_regMonth_salesVolume_rolling_std_12  \\\n",
       "0                                           8.657722     \n",
       "1                                           8.657722     \n",
       "2                                           8.657722     \n",
       "3                                           8.657722     \n",
       "4                                           8.657722     \n",
       "\n",
       "   adcode_bodyType_regMonth_salesVolume_rolling_sum_4  \\\n",
       "0                                         639.799585    \n",
       "1                                         639.799585    \n",
       "2                                         639.799585    \n",
       "3                                         639.799585    \n",
       "4                                         639.799585    \n",
       "\n",
       "   adcode_bodyType_regMonth_salesVolume_rolling_sum_5  \\\n",
       "0                                          636.69988    \n",
       "1                                          636.69988    \n",
       "2                                          636.69988    \n",
       "3                                          636.69988    \n",
       "4                                          636.69988    \n",
       "\n",
       "   adcode_bodyType_regMonth_salesVolume_rolling_sum_6  \\\n",
       "0                                         655.841951    \n",
       "1                                         655.841951    \n",
       "2                                         655.841951    \n",
       "3                                         655.841951    \n",
       "4                                         655.841951    \n",
       "\n",
       "   adcode_bodyType_regMonth_salesVolume_rolling_sum_7  \\\n",
       "0                                         654.532863    \n",
       "1                                         654.532863    \n",
       "2                                         654.532863    \n",
       "3                                         654.532863    \n",
       "4                                         654.532863    \n",
       "\n",
       "   adcode_bodyType_regMonth_salesVolume_rolling_sum_8  \\\n",
       "0                                         655.573478    \n",
       "1                                         655.573478    \n",
       "2                                         655.573478    \n",
       "3                                         655.573478    \n",
       "4                                         655.573478    \n",
       "\n",
       "   adcode_bodyType_regMonth_salesVolume_rolling_sum_9  \\\n",
       "0                                         655.266455    \n",
       "1                                         655.266455    \n",
       "2                                         655.266455    \n",
       "3                                         655.266455    \n",
       "4                                         655.266455    \n",
       "\n",
       "   adcode_bodyType_regMonth_salesVolume_rolling_sum_10  \\\n",
       "0                                         647.766958     \n",
       "1                                         647.766958     \n",
       "2                                         647.766958     \n",
       "3                                         647.766958     \n",
       "4                                         647.766958     \n",
       "\n",
       "   adcode_bodyType_regMonth_salesVolume_rolling_sum_11  \\\n",
       "0                                         648.454342     \n",
       "1                                         648.454342     \n",
       "2                                         648.454342     \n",
       "3                                         648.454342     \n",
       "4                                         648.454342     \n",
       "\n",
       "   adcode_bodyType_regMonth_salesVolume_rolling_sum_12  \n",
       "0                                         659.300918    \n",
       "1                                         659.300918    \n",
       "2                                         659.300918    \n",
       "3                                         659.300918    \n",
       "4                                         659.300918    \n",
       "\n",
       "[5 rows x 335 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.merge(train_basic_fea, train_windows_fea, on=[\"adcode\", \"model\", \"bodyType\"], how=\"left\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1320, 14)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaild_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并特征\n",
    "train_data = pd.merge(train_basic_fea, train_windows_fea, on=[\"adcode\", \"model\", \"bodyType\"], how=\"left\")\n",
    "vaild_data = get_data(train_sales, \"test\").groupby([\"adcode\", \"model\"])[\"salesVolume\"].apply(lambda x: pd.DataFrame(np.array(x)).T).reset_index().drop(\"level_2\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train_columns: ['adcode', 'model', 'adcode_model_regMonth_salesVolume_1', 'adcode_model_regMonth_salesVolume_2', 'adcode_model_regMonth_salesVolume_3', 'adcode_model_regMonth_salesVolume_4', 'adcode_model_regMonth_salesVolume_5', 'adcode_model_regMonth_salesVolume_6', 'adcode_model_regMonth_salesVolume_7', 'adcode_model_regMonth_salesVolume_8', 'adcode_model_regMonth_salesVolume_9', 'adcode_model_regMonth_salesVolume_10', 'adcode_model_regMonth_salesVolume_11', 'adcode_model_regMonth_salesVolume_12', 'adcode_model_regMonth_salesVolume_shift_div_2', 'adcode_model_regMonth_salesVolume_shift_div_3', 'adcode_model_regMonth_salesVolume_shift_div_4', 'adcode_model_regMonth_salesVolume_shift_div_5', 'adcode_model_regMonth_salesVolume_shift_div_6', 'adcode_model_regMonth_salesVolume_shift_div_7', 'adcode_model_regMonth_salesVolume_shift_div_8', 'adcode_model_regMonth_salesVolume_shift_div_9', 'adcode_model_regMonth_salesVolume_shift_div_10', 'adcode_model_regMonth_salesVolume_shift_div_11', 'adcode_model_regMonth_salesVolume_shift_div_12', 'adcode_model_regMonth_salesVolume_shift_sub_2', 'adcode_model_regMonth_salesVolume_shift_sub_3', 'adcode_model_regMonth_salesVolume_shift_sub_4', 'adcode_model_regMonth_salesVolume_shift_sub_5', 'adcode_model_regMonth_salesVolume_shift_sub_6', 'adcode_model_regMonth_salesVolume_shift_sub_7', 'adcode_model_regMonth_salesVolume_shift_sub_8', 'adcode_model_regMonth_salesVolume_shift_sub_9', 'adcode_model_regMonth_salesVolume_shift_sub_10', 'adcode_model_regMonth_salesVolume_shift_sub_11', 'adcode_model_regMonth_salesVolume_shift_sub_12', 'adcode_model_regMonth_salesVolume_shift_2_div_2', 'adcode_model_regMonth_salesVolume_shift_2_div_3', 'adcode_model_regMonth_salesVolume_shift_2_div_4', 'adcode_model_regMonth_salesVolume_shift_2_div_5', 'adcode_model_regMonth_salesVolume_shift_2_div_6', 'adcode_model_regMonth_salesVolume_shift_2_div_7', 'adcode_model_regMonth_salesVolume_shift_2_div_8', 'adcode_model_regMonth_salesVolume_shift_2_div_9', 'adcode_model_regMonth_salesVolume_shift_2_div_10', 'adcode_model_regMonth_salesVolume_shift_2_div_11', 'adcode_model_regMonth_salesVolume_shift_2_div_12', 'adcode_model_regMonth_salesVolume_shift_2_sub_2', 'adcode_model_regMonth_salesVolume_shift_2_sub_3', 'adcode_model_regMonth_salesVolume_shift_2_sub_4', 'adcode_model_regMonth_salesVolume_shift_2_sub_5', 'adcode_model_regMonth_salesVolume_shift_2_sub_6', 'adcode_model_regMonth_salesVolume_shift_2_sub_7', 'adcode_model_regMonth_salesVolume_shift_2_sub_8', 'adcode_model_regMonth_salesVolume_shift_2_sub_9', 'adcode_model_regMonth_salesVolume_shift_2_sub_10', 'adcode_model_regMonth_salesVolume_shift_2_sub_11', 'adcode_model_regMonth_salesVolume_shift_2_sub_12', 'adcode_regMonth_salesVolume_1', 'adcode_regMonth_salesVolume_2', 'adcode_regMonth_salesVolume_3', 'adcode_regMonth_salesVolume_4', 'adcode_regMonth_salesVolume_5', 'adcode_regMonth_salesVolume_6', 'adcode_regMonth_salesVolume_7', 'adcode_regMonth_salesVolume_8', 'adcode_regMonth_salesVolume_9', 'adcode_regMonth_salesVolume_10', 'adcode_regMonth_salesVolume_11', 'adcode_regMonth_salesVolume_12', 'adcode_regMonth_salesVolume_shift_div_2', 'adcode_regMonth_salesVolume_shift_div_3', 'adcode_regMonth_salesVolume_shift_div_4', 'adcode_regMonth_salesVolume_shift_div_5', 'adcode_regMonth_salesVolume_shift_div_6', 'adcode_regMonth_salesVolume_shift_div_7', 'adcode_regMonth_salesVolume_shift_div_8', 'adcode_regMonth_salesVolume_shift_div_9', 'adcode_regMonth_salesVolume_shift_div_10', 'adcode_regMonth_salesVolume_shift_div_11', 'adcode_regMonth_salesVolume_shift_div_12', 'adcode_regMonth_salesVolume_shift_sub_2', 'adcode_regMonth_salesVolume_shift_sub_3', 'adcode_regMonth_salesVolume_shift_sub_4', 'adcode_regMonth_salesVolume_shift_sub_5', 'adcode_regMonth_salesVolume_shift_sub_6', 'adcode_regMonth_salesVolume_shift_sub_7', 'adcode_regMonth_salesVolume_shift_sub_8', 'adcode_regMonth_salesVolume_shift_sub_9', 'adcode_regMonth_salesVolume_shift_sub_10', 'adcode_regMonth_salesVolume_shift_sub_11', 'adcode_regMonth_salesVolume_shift_sub_12', 'adcode_regMonth_salesVolume_shift_2_div_2', 'adcode_regMonth_salesVolume_shift_2_div_3', 'adcode_regMonth_salesVolume_shift_2_div_4', 'adcode_regMonth_salesVolume_shift_2_div_5', 'adcode_regMonth_salesVolume_shift_2_div_6', 'adcode_regMonth_salesVolume_shift_2_div_7', 'adcode_regMonth_salesVolume_shift_2_div_8', 'adcode_regMonth_salesVolume_shift_2_div_9', 'adcode_regMonth_salesVolume_shift_2_div_10', 'adcode_regMonth_salesVolume_shift_2_div_11', 'adcode_regMonth_salesVolume_shift_2_div_12', 'adcode_regMonth_salesVolume_shift_2_sub_2', 'adcode_regMonth_salesVolume_shift_2_sub_3', 'adcode_regMonth_salesVolume_shift_2_sub_4', 'adcode_regMonth_salesVolume_shift_2_sub_5', 'adcode_regMonth_salesVolume_shift_2_sub_6', 'adcode_regMonth_salesVolume_shift_2_sub_7', 'adcode_regMonth_salesVolume_shift_2_sub_8', 'adcode_regMonth_salesVolume_shift_2_sub_9', 'adcode_regMonth_salesVolume_shift_2_sub_10', 'adcode_regMonth_salesVolume_shift_2_sub_11', 'adcode_regMonth_salesVolume_shift_2_sub_12', 'model_regMonth_salesVolume_1', 'model_regMonth_salesVolume_2', 'model_regMonth_salesVolume_3', 'model_regMonth_salesVolume_4', 'model_regMonth_salesVolume_5', 'model_regMonth_salesVolume_6', 'model_regMonth_salesVolume_7', 'model_regMonth_salesVolume_8', 'model_regMonth_salesVolume_9', 'model_regMonth_salesVolume_10', 'model_regMonth_salesVolume_11', 'model_regMonth_salesVolume_12', 'model_regMonth_salesVolume_shift_div_2', 'model_regMonth_salesVolume_shift_div_3', 'model_regMonth_salesVolume_shift_div_4', 'model_regMonth_salesVolume_shift_div_5', 'model_regMonth_salesVolume_shift_div_6', 'model_regMonth_salesVolume_shift_div_7', 'model_regMonth_salesVolume_shift_div_8', 'model_regMonth_salesVolume_shift_div_9', 'model_regMonth_salesVolume_shift_div_10', 'model_regMonth_salesVolume_shift_div_11', 'model_regMonth_salesVolume_shift_div_12', 'model_regMonth_salesVolume_shift_sub_2', 'model_regMonth_salesVolume_shift_sub_3', 'model_regMonth_salesVolume_shift_sub_4', 'model_regMonth_salesVolume_shift_sub_5', 'model_regMonth_salesVolume_shift_sub_6', 'model_regMonth_salesVolume_shift_sub_7', 'model_regMonth_salesVolume_shift_sub_8', 'model_regMonth_salesVolume_shift_sub_9', 'model_regMonth_salesVolume_shift_sub_10', 'model_regMonth_salesVolume_shift_sub_11', 'model_regMonth_salesVolume_shift_sub_12', 'model_regMonth_salesVolume_shift_2_div_2', 'model_regMonth_salesVolume_shift_2_div_3', 'model_regMonth_salesVolume_shift_2_div_4', 'model_regMonth_salesVolume_shift_2_div_5', 'model_regMonth_salesVolume_shift_2_div_6', 'model_regMonth_salesVolume_shift_2_div_7', 'model_regMonth_salesVolume_shift_2_div_8', 'model_regMonth_salesVolume_shift_2_div_9', 'model_regMonth_salesVolume_shift_2_div_10', 'model_regMonth_salesVolume_shift_2_div_11', 'model_regMonth_salesVolume_shift_2_div_12', 'model_regMonth_salesVolume_shift_2_sub_2', 'model_regMonth_salesVolume_shift_2_sub_3', 'model_regMonth_salesVolume_shift_2_sub_4', 'model_regMonth_salesVolume_shift_2_sub_5', 'model_regMonth_salesVolume_shift_2_sub_6', 'model_regMonth_salesVolume_shift_2_sub_7', 'model_regMonth_salesVolume_shift_2_sub_8', 'model_regMonth_salesVolume_shift_2_sub_9', 'model_regMonth_salesVolume_shift_2_sub_10', 'model_regMonth_salesVolume_shift_2_sub_11', 'model_regMonth_salesVolume_shift_2_sub_12', 'bodyType', 'adcode_bodyType_regMonth_salesVolume_1', 'adcode_bodyType_regMonth_salesVolume_2', 'adcode_bodyType_regMonth_salesVolume_3', 'adcode_bodyType_regMonth_salesVolume_4', 'adcode_bodyType_regMonth_salesVolume_5', 'adcode_bodyType_regMonth_salesVolume_6', 'adcode_bodyType_regMonth_salesVolume_7', 'adcode_bodyType_regMonth_salesVolume_8', 'adcode_bodyType_regMonth_salesVolume_9', 'adcode_bodyType_regMonth_salesVolume_10', 'adcode_bodyType_regMonth_salesVolume_11', 'adcode_bodyType_regMonth_salesVolume_12', 'adcode_bodyType_regMonth_salesVolume_shift_div_2', 'adcode_bodyType_regMonth_salesVolume_shift_div_3', 'adcode_bodyType_regMonth_salesVolume_shift_div_4', 'adcode_bodyType_regMonth_salesVolume_shift_div_5', 'adcode_bodyType_regMonth_salesVolume_shift_div_6', 'adcode_bodyType_regMonth_salesVolume_shift_div_7', 'adcode_bodyType_regMonth_salesVolume_shift_div_8', 'adcode_bodyType_regMonth_salesVolume_shift_div_9', 'adcode_bodyType_regMonth_salesVolume_shift_div_10', 'adcode_bodyType_regMonth_salesVolume_shift_div_11', 'adcode_bodyType_regMonth_salesVolume_shift_div_12', 'adcode_bodyType_regMonth_salesVolume_shift_sub_2', 'adcode_bodyType_regMonth_salesVolume_shift_sub_3', 'adcode_bodyType_regMonth_salesVolume_shift_sub_4', 'adcode_bodyType_regMonth_salesVolume_shift_sub_5', 'adcode_bodyType_regMonth_salesVolume_shift_sub_6', 'adcode_bodyType_regMonth_salesVolume_shift_sub_7', 'adcode_bodyType_regMonth_salesVolume_shift_sub_8', 'adcode_bodyType_regMonth_salesVolume_shift_sub_9', 'adcode_bodyType_regMonth_salesVolume_shift_sub_10', 'adcode_bodyType_regMonth_salesVolume_shift_sub_11', 'adcode_bodyType_regMonth_salesVolume_shift_sub_12', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_2', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_3', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_4', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_5', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_6', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_7', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_8', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_9', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_10', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_11', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_12', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_2', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_3', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_4', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_5', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_6', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_7', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_8', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_9', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_10', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_11', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_12', 'adcode_model_regMonth_salesVolume_rolling_mean_4', 'adcode_model_regMonth_salesVolume_rolling_mean_5', 'adcode_model_regMonth_salesVolume_rolling_mean_6', 'adcode_model_regMonth_salesVolume_rolling_mean_7', 'adcode_model_regMonth_salesVolume_rolling_mean_8', 'adcode_model_regMonth_salesVolume_rolling_mean_9', 'adcode_model_regMonth_salesVolume_rolling_mean_10', 'adcode_model_regMonth_salesVolume_rolling_mean_11', 'adcode_model_regMonth_salesVolume_rolling_mean_12', 'adcode_model_regMonth_salesVolume_rolling_std_4', 'adcode_model_regMonth_salesVolume_rolling_std_5', 'adcode_model_regMonth_salesVolume_rolling_std_6', 'adcode_model_regMonth_salesVolume_rolling_std_7', 'adcode_model_regMonth_salesVolume_rolling_std_8', 'adcode_model_regMonth_salesVolume_rolling_std_9', 'adcode_model_regMonth_salesVolume_rolling_std_10', 'adcode_model_regMonth_salesVolume_rolling_std_11', 'adcode_model_regMonth_salesVolume_rolling_std_12', 'adcode_model_regMonth_salesVolume_rolling_sum_4', 'adcode_model_regMonth_salesVolume_rolling_sum_5', 'adcode_model_regMonth_salesVolume_rolling_sum_6', 'adcode_model_regMonth_salesVolume_rolling_sum_7', 'adcode_model_regMonth_salesVolume_rolling_sum_8', 'adcode_model_regMonth_salesVolume_rolling_sum_9', 'adcode_model_regMonth_salesVolume_rolling_sum_10', 'adcode_model_regMonth_salesVolume_rolling_sum_11', 'adcode_model_regMonth_salesVolume_rolling_sum_12', 'adcode_regMonth_salesVolume_rolling_mean_4', 'adcode_regMonth_salesVolume_rolling_mean_5', 'adcode_regMonth_salesVolume_rolling_mean_6', 'adcode_regMonth_salesVolume_rolling_mean_7', 'adcode_regMonth_salesVolume_rolling_mean_8', 'adcode_regMonth_salesVolume_rolling_mean_9', 'adcode_regMonth_salesVolume_rolling_mean_10', 'adcode_regMonth_salesVolume_rolling_mean_11', 'adcode_regMonth_salesVolume_rolling_mean_12', 'adcode_regMonth_salesVolume_rolling_std_4', 'adcode_regMonth_salesVolume_rolling_std_5', 'adcode_regMonth_salesVolume_rolling_std_6', 'adcode_regMonth_salesVolume_rolling_std_7', 'adcode_regMonth_salesVolume_rolling_std_8', 'adcode_regMonth_salesVolume_rolling_std_9', 'adcode_regMonth_salesVolume_rolling_std_10', 'adcode_regMonth_salesVolume_rolling_std_11', 'adcode_regMonth_salesVolume_rolling_std_12', 'adcode_regMonth_salesVolume_rolling_sum_4', 'adcode_regMonth_salesVolume_rolling_sum_5', 'adcode_regMonth_salesVolume_rolling_sum_6', 'adcode_regMonth_salesVolume_rolling_sum_7', 'adcode_regMonth_salesVolume_rolling_sum_8', 'adcode_regMonth_salesVolume_rolling_sum_9', 'adcode_regMonth_salesVolume_rolling_sum_10', 'adcode_regMonth_salesVolume_rolling_sum_11', 'adcode_regMonth_salesVolume_rolling_sum_12', 'model_regMonth_salesVolume_rolling_mean_4', 'model_regMonth_salesVolume_rolling_mean_5', 'model_regMonth_salesVolume_rolling_mean_6', 'model_regMonth_salesVolume_rolling_mean_7', 'model_regMonth_salesVolume_rolling_mean_8', 'model_regMonth_salesVolume_rolling_mean_9', 'model_regMonth_salesVolume_rolling_mean_10', 'model_regMonth_salesVolume_rolling_mean_11', 'model_regMonth_salesVolume_rolling_mean_12', 'model_regMonth_salesVolume_rolling_std_4', 'model_regMonth_salesVolume_rolling_std_5', 'model_regMonth_salesVolume_rolling_std_6', 'model_regMonth_salesVolume_rolling_std_7', 'model_regMonth_salesVolume_rolling_std_8', 'model_regMonth_salesVolume_rolling_std_9', 'model_regMonth_salesVolume_rolling_std_10', 'model_regMonth_salesVolume_rolling_std_11', 'model_regMonth_salesVolume_rolling_std_12', 'model_regMonth_salesVolume_rolling_sum_4', 'model_regMonth_salesVolume_rolling_sum_5', 'model_regMonth_salesVolume_rolling_sum_6', 'model_regMonth_salesVolume_rolling_sum_7', 'model_regMonth_salesVolume_rolling_sum_8', 'model_regMonth_salesVolume_rolling_sum_9', 'model_regMonth_salesVolume_rolling_sum_10', 'model_regMonth_salesVolume_rolling_sum_11', 'model_regMonth_salesVolume_rolling_sum_12', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_4', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_5', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_6', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_7', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_8', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_9', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_10', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_11', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_12', 'adcode_bodyType_regMonth_salesVolume_rolling_std_4', 'adcode_bodyType_regMonth_salesVolume_rolling_std_5', 'adcode_bodyType_regMonth_salesVolume_rolling_std_6', 'adcode_bodyType_regMonth_salesVolume_rolling_std_7', 'adcode_bodyType_regMonth_salesVolume_rolling_std_8', 'adcode_bodyType_regMonth_salesVolume_rolling_std_9', 'adcode_bodyType_regMonth_salesVolume_rolling_std_10', 'adcode_bodyType_regMonth_salesVolume_rolling_std_11', 'adcode_bodyType_regMonth_salesVolume_rolling_std_12', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_4', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_5', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_6', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_7', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_8', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_9', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_10', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_11', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_12']"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(1320, 335)\n",
      "335\n",
      "fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\lightgbm\\engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['adcode', 'bodyType', 'model']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\lightgbm\\basic.py:762: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0779921\tvalid_1's l2: 0.120028\n",
      "[400]\ttraining's l2: 0.0238466\tvalid_1's l2: 0.0625996\n",
      "[600]\ttraining's l2: 0.0150581\tvalid_1's l2: 0.0533442\n",
      "[800]\ttraining's l2: 0.0113954\tvalid_1's l2: 0.0510968\n",
      "[1000]\ttraining's l2: 0.00910468\tvalid_1's l2: 0.0499554\n",
      "[1200]\ttraining's l2: 0.00758173\tvalid_1's l2: 0.0493031\n",
      "[1400]\ttraining's l2: 0.00650013\tvalid_1's l2: 0.048957\n",
      "[1600]\ttraining's l2: 0.00562377\tvalid_1's l2: 0.0486795\n",
      "[1800]\ttraining's l2: 0.00495011\tvalid_1's l2: 0.0484565\n",
      "[2000]\ttraining's l2: 0.00446025\tvalid_1's l2: 0.0483876\n",
      "[2200]\ttraining's l2: 0.00413631\tvalid_1's l2: 0.0483154\n",
      "Early stopping, best iteration is:\n",
      "[2166]\ttraining's l2: 0.00413631\tvalid_1's l2: 0.0483154\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0708282\tvalid_1's l2: 0.0991712\n",
      "[400]\ttraining's l2: 0.0232355\tvalid_1's l2: 0.0507108\n",
      "[600]\ttraining's l2: 0.0152975\tvalid_1's l2: 0.0430578\n",
      "[800]\ttraining's l2: 0.0119434\tvalid_1's l2: 0.0406166\n",
      "[1000]\ttraining's l2: 0.00955002\tvalid_1's l2: 0.0398988\n",
      "[1200]\ttraining's l2: 0.00782931\tvalid_1's l2: 0.0395721\n",
      "[1400]\ttraining's l2: 0.00661736\tvalid_1's l2: 0.0394422\n",
      "[1600]\ttraining's l2: 0.00571105\tvalid_1's l2: 0.0392711\n",
      "Early stopping, best iteration is:\n",
      "[1549]\ttraining's l2: 0.00592042\tvalid_1's l2: 0.039231\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.070978\tvalid_1's l2: 0.0769138\n",
      "[400]\ttraining's l2: 0.0238389\tvalid_1's l2: 0.0425782\n",
      "[600]\ttraining's l2: 0.0154368\tvalid_1's l2: 0.0389333\n",
      "[800]\ttraining's l2: 0.0117289\tvalid_1's l2: 0.0380138\n",
      "[1000]\ttraining's l2: 0.00929873\tvalid_1's l2: 0.0378896\n",
      "Early stopping, best iteration is:\n",
      "[930]\ttraining's l2: 0.0100557\tvalid_1's l2: 0.0377327\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0803996\tvalid_1's l2: 0.0917381\n",
      "[400]\ttraining's l2: 0.0277965\tvalid_1's l2: 0.0549752\n",
      "[600]\ttraining's l2: 0.0182819\tvalid_1's l2: 0.0502284\n",
      "[800]\ttraining's l2: 0.0138448\tvalid_1's l2: 0.0484807\n",
      "[1000]\ttraining's l2: 0.0110293\tvalid_1's l2: 0.047711\n",
      "[1200]\ttraining's l2: 0.00895812\tvalid_1's l2: 0.0471247\n",
      "[1400]\ttraining's l2: 0.0074074\tvalid_1's l2: 0.0469767\n",
      "Early stopping, best iteration is:\n",
      "[1346]\ttraining's l2: 0.00776787\tvalid_1's l2: 0.0469475\n",
      "fold 1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0806026\tvalid_1's l2: 0.100074\n",
      "[400]\ttraining's l2: 0.0253007\tvalid_1's l2: 0.0466537\n",
      "[600]\ttraining's l2: 0.0157791\tvalid_1's l2: 0.0395155\n",
      "[800]\ttraining's l2: 0.0120674\tvalid_1's l2: 0.0371391\n",
      "[1000]\ttraining's l2: 0.00967829\tvalid_1's l2: 0.0363533\n",
      "[1200]\ttraining's l2: 0.00803011\tvalid_1's l2: 0.0358874\n",
      "[1400]\ttraining's l2: 0.00671194\tvalid_1's l2: 0.0354699\n",
      "[1600]\ttraining's l2: 0.00570316\tvalid_1's l2: 0.0353169\n",
      "[1800]\ttraining's l2: 0.00497983\tvalid_1's l2: 0.0352399\n",
      "[2000]\ttraining's l2: 0.00461104\tvalid_1's l2: 0.0351608\n",
      "Early stopping, best iteration is:\n",
      "[1952]\ttraining's l2: 0.00461386\tvalid_1's l2: 0.0351599\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0698029\tvalid_1's l2: 0.107093\n",
      "[400]\ttraining's l2: 0.0218118\tvalid_1's l2: 0.0593334\n",
      "[600]\ttraining's l2: 0.014541\tvalid_1's l2: 0.0520743\n",
      "[800]\ttraining's l2: 0.0114704\tvalid_1's l2: 0.0500596\n",
      "[1000]\ttraining's l2: 0.00931527\tvalid_1's l2: 0.0495837\n",
      "[1200]\ttraining's l2: 0.00768096\tvalid_1's l2: 0.0495733\n",
      "Early stopping, best iteration is:\n",
      "[1062]\ttraining's l2: 0.0087745\tvalid_1's l2: 0.0494906\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0716872\tvalid_1's l2: 0.0794389\n",
      "[400]\ttraining's l2: 0.0236161\tvalid_1's l2: 0.0437354\n",
      "[600]\ttraining's l2: 0.0154904\tvalid_1's l2: 0.0402737\n",
      "[800]\ttraining's l2: 0.0118518\tvalid_1's l2: 0.0387807\n",
      "[1000]\ttraining's l2: 0.00945587\tvalid_1's l2: 0.0382096\n",
      "[1200]\ttraining's l2: 0.00780055\tvalid_1's l2: 0.0379981\n",
      "[1400]\ttraining's l2: 0.00665601\tvalid_1's l2: 0.0377828\n",
      "[1600]\ttraining's l2: 0.00577518\tvalid_1's l2: 0.0376093\n",
      "[1800]\ttraining's l2: 0.00509741\tvalid_1's l2: 0.0374288\n",
      "[2000]\ttraining's l2: 0.00457439\tvalid_1's l2: 0.0372899\n",
      "[2200]\ttraining's l2: 0.00432985\tvalid_1's l2: 0.0372257\n",
      "Early stopping, best iteration is:\n",
      "[2120]\ttraining's l2: 0.00433306\tvalid_1's l2: 0.0372245\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0791965\tvalid_1's l2: 0.114107\n",
      "[400]\ttraining's l2: 0.0266424\tvalid_1's l2: 0.0699971\n",
      "[600]\ttraining's l2: 0.0175055\tvalid_1's l2: 0.0641511\n",
      "[800]\ttraining's l2: 0.0134841\tvalid_1's l2: 0.0616697\n",
      "[1000]\ttraining's l2: 0.0108286\tvalid_1's l2: 0.0606343\n",
      "[1200]\ttraining's l2: 0.00885541\tvalid_1's l2: 0.0598716\n",
      "[1400]\ttraining's l2: 0.00743762\tvalid_1's l2: 0.0595337\n",
      "[1600]\ttraining's l2: 0.00639571\tvalid_1's l2: 0.059234\n",
      "[1800]\ttraining's l2: 0.00563281\tvalid_1's l2: 0.05908\n",
      "[2000]\ttraining's l2: 0.0050453\tvalid_1's l2: 0.0589058\n",
      "[2200]\ttraining's l2: 0.00501878\tvalid_1's l2: 0.0589021\n",
      "Early stopping, best iteration is:\n",
      "[2008]\ttraining's l2: 0.00503103\tvalid_1's l2: 0.0588988\n",
      "fold 2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0758025\tvalid_1's l2: 0.163385\n",
      "[400]\ttraining's l2: 0.0229861\tvalid_1's l2: 0.0918498\n",
      "[600]\ttraining's l2: 0.014213\tvalid_1's l2: 0.0758826\n",
      "[800]\ttraining's l2: 0.0106829\tvalid_1's l2: 0.0695955\n",
      "[1000]\ttraining's l2: 0.00865829\tvalid_1's l2: 0.0670496\n",
      "[1200]\ttraining's l2: 0.00722633\tvalid_1's l2: 0.0657685\n",
      "[1400]\ttraining's l2: 0.00611354\tvalid_1's l2: 0.065081\n",
      "[1600]\ttraining's l2: 0.00527771\tvalid_1's l2: 0.0646712\n",
      "[1800]\ttraining's l2: 0.00466239\tvalid_1's l2: 0.0644147\n",
      "[2000]\ttraining's l2: 0.0041541\tvalid_1's l2: 0.0641804\n",
      "[2200]\ttraining's l2: 0.00387499\tvalid_1's l2: 0.0640965\n",
      "Early stopping, best iteration is:\n",
      "[2135]\ttraining's l2: 0.00391402\tvalid_1's l2: 0.064073\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0695956\tvalid_1's l2: 0.130136\n",
      "[400]\ttraining's l2: 0.0230936\tvalid_1's l2: 0.0728311\n",
      "[600]\ttraining's l2: 0.0152993\tvalid_1's l2: 0.0607156\n",
      "[800]\ttraining's l2: 0.0121698\tvalid_1's l2: 0.0568349\n",
      "[1000]\ttraining's l2: 0.00988996\tvalid_1's l2: 0.0556231\n",
      "[1200]\ttraining's l2: 0.00820426\tvalid_1's l2: 0.0551275\n",
      "[1400]\ttraining's l2: 0.00695337\tvalid_1's l2: 0.0549057\n",
      "[1600]\ttraining's l2: 0.00600156\tvalid_1's l2: 0.0546064\n",
      "[1800]\ttraining's l2: 0.00530885\tvalid_1's l2: 0.0546263\n",
      "Early stopping, best iteration is:\n",
      "[1729]\ttraining's l2: 0.00554412\tvalid_1's l2: 0.0545758\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0665925\tvalid_1's l2: 0.139063\n",
      "[400]\ttraining's l2: 0.0219247\tvalid_1's l2: 0.0813722\n",
      "[600]\ttraining's l2: 0.0144177\tvalid_1's l2: 0.0699071\n",
      "[800]\ttraining's l2: 0.0110648\tvalid_1's l2: 0.0658386\n",
      "[1000]\ttraining's l2: 0.00887042\tvalid_1's l2: 0.0641811\n",
      "[1200]\ttraining's l2: 0.00746381\tvalid_1's l2: 0.0636086\n",
      "[1400]\ttraining's l2: 0.00644422\tvalid_1's l2: 0.0631588\n",
      "[1600]\ttraining's l2: 0.00561127\tvalid_1's l2: 0.0629867\n",
      "[1800]\ttraining's l2: 0.00495582\tvalid_1's l2: 0.0628248\n",
      "[2000]\ttraining's l2: 0.00447077\tvalid_1's l2: 0.0626333\n",
      "[2200]\ttraining's l2: 0.00445796\tvalid_1's l2: 0.0626258\n",
      "Early stopping, best iteration is:\n",
      "[2008]\ttraining's l2: 0.00446047\tvalid_1's l2: 0.0626231\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0792757\tvalid_1's l2: 0.128851\n",
      "[400]\ttraining's l2: 0.0281155\tvalid_1's l2: 0.0690623\n",
      "[600]\ttraining's l2: 0.0187913\tvalid_1's l2: 0.0567724\n",
      "[800]\ttraining's l2: 0.0142004\tvalid_1's l2: 0.0530773\n",
      "[1000]\ttraining's l2: 0.01124\tvalid_1's l2: 0.0516529\n",
      "[1200]\ttraining's l2: 0.00914586\tvalid_1's l2: 0.0508405\n",
      "[1400]\ttraining's l2: 0.00761291\tvalid_1's l2: 0.0505924\n",
      "[1600]\ttraining's l2: 0.00650943\tvalid_1's l2: 0.0503932\n",
      "[1800]\ttraining's l2: 0.00571184\tvalid_1's l2: 0.0502995\n",
      "[2000]\ttraining's l2: 0.00506331\tvalid_1's l2: 0.0502661\n",
      "Early stopping, best iteration is:\n",
      "[1876]\ttraining's l2: 0.00543767\tvalid_1's l2: 0.0501892\n",
      "fold 3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.079268\tvalid_1's l2: 0.107401\n",
      "[400]\ttraining's l2: 0.0239989\tvalid_1's l2: 0.0561437\n",
      "[600]\ttraining's l2: 0.0146958\tvalid_1's l2: 0.0483989\n",
      "[800]\ttraining's l2: 0.0109969\tvalid_1's l2: 0.0459404\n",
      "[1000]\ttraining's l2: 0.00868084\tvalid_1's l2: 0.0448549\n",
      "[1200]\ttraining's l2: 0.00717842\tvalid_1's l2: 0.0445854\n",
      "[1400]\ttraining's l2: 0.00612417\tvalid_1's l2: 0.0444931\n",
      "[1600]\ttraining's l2: 0.00528986\tvalid_1's l2: 0.0444393\n",
      "[1800]\ttraining's l2: 0.0046648\tvalid_1's l2: 0.0442308\n",
      "[2000]\ttraining's l2: 0.00420046\tvalid_1's l2: 0.044132\n",
      "Early stopping, best iteration is:\n",
      "[1937]\ttraining's l2: 0.00432497\tvalid_1's l2: 0.044124\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0728617\tvalid_1's l2: 0.0916197\n",
      "[400]\ttraining's l2: 0.0241371\tvalid_1's l2: 0.0456431\n",
      "[600]\ttraining's l2: 0.0162627\tvalid_1's l2: 0.0386647\n",
      "[800]\ttraining's l2: 0.0127839\tvalid_1's l2: 0.0364527\n",
      "[1000]\ttraining's l2: 0.0102593\tvalid_1's l2: 0.0354512\n",
      "[1200]\ttraining's l2: 0.00849176\tvalid_1's l2: 0.0350899\n",
      "[1400]\ttraining's l2: 0.00719022\tvalid_1's l2: 0.0349437\n",
      "[1600]\ttraining's l2: 0.00615734\tvalid_1's l2: 0.0348763\n",
      "[1800]\ttraining's l2: 0.00540187\tvalid_1's l2: 0.0348337\n",
      "[2000]\ttraining's l2: 0.00484435\tvalid_1's l2: 0.0348475\n",
      "Early stopping, best iteration is:\n",
      "[1837]\ttraining's l2: 0.00528451\tvalid_1's l2: 0.0348119\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0701763\tvalid_1's l2: 0.0933993\n",
      "[400]\ttraining's l2: 0.0237722\tvalid_1's l2: 0.0442311\n",
      "[600]\ttraining's l2: 0.0156036\tvalid_1's l2: 0.0373738\n",
      "[800]\ttraining's l2: 0.0118448\tvalid_1's l2: 0.0354213\n",
      "[1000]\ttraining's l2: 0.00943456\tvalid_1's l2: 0.0345872\n",
      "[1200]\ttraining's l2: 0.00780863\tvalid_1's l2: 0.034164\n",
      "[1400]\ttraining's l2: 0.00661686\tvalid_1's l2: 0.0339576\n",
      "[1600]\ttraining's l2: 0.00571576\tvalid_1's l2: 0.0339738\n",
      "Early stopping, best iteration is:\n",
      "[1486]\ttraining's l2: 0.00620107\tvalid_1's l2: 0.03393\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0786512\tvalid_1's l2: 0.125205\n",
      "[400]\ttraining's l2: 0.0272173\tvalid_1's l2: 0.0659663\n",
      "[600]\ttraining's l2: 0.0180273\tvalid_1's l2: 0.0566995\n",
      "[800]\ttraining's l2: 0.0136673\tvalid_1's l2: 0.0537589\n",
      "[1000]\ttraining's l2: 0.0108759\tvalid_1's l2: 0.0524037\n",
      "[1200]\ttraining's l2: 0.00890287\tvalid_1's l2: 0.0517138\n",
      "[1400]\ttraining's l2: 0.00741926\tvalid_1's l2: 0.0512449\n",
      "[1600]\ttraining's l2: 0.00631548\tvalid_1's l2: 0.0510542\n",
      "[1800]\ttraining's l2: 0.00547871\tvalid_1's l2: 0.0509153\n",
      "[2000]\ttraining's l2: 0.00488212\tvalid_1's l2: 0.0508729\n",
      "[2200]\ttraining's l2: 0.00471612\tvalid_1's l2: 0.0508674\n",
      "Early stopping, best iteration is:\n",
      "[2048]\ttraining's l2: 0.00477175\tvalid_1's l2: 0.0508474\n",
      "fold 4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0793327\tvalid_1's l2: 0.119541\n",
      "[400]\ttraining's l2: 0.0243972\tvalid_1's l2: 0.0664403\n",
      "[600]\ttraining's l2: 0.0151707\tvalid_1's l2: 0.0545536\n",
      "[800]\ttraining's l2: 0.0115138\tvalid_1's l2: 0.0505259\n",
      "[1000]\ttraining's l2: 0.00917174\tvalid_1's l2: 0.0484736\n",
      "[1200]\ttraining's l2: 0.00760053\tvalid_1's l2: 0.0475018\n",
      "[1400]\ttraining's l2: 0.00646582\tvalid_1's l2: 0.0467632\n",
      "[1600]\ttraining's l2: 0.00556887\tvalid_1's l2: 0.0462116\n",
      "[1800]\ttraining's l2: 0.00486595\tvalid_1's l2: 0.0457231\n",
      "[2000]\ttraining's l2: 0.00431659\tvalid_1's l2: 0.0454179\n",
      "[2200]\ttraining's l2: 0.00403825\tvalid_1's l2: 0.0453267\n",
      "Early stopping, best iteration is:\n",
      "[2122]\ttraining's l2: 0.00403956\tvalid_1's l2: 0.0453258\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0705015\tvalid_1's l2: 0.0960751\n",
      "[400]\ttraining's l2: 0.0227542\tvalid_1's l2: 0.0557338\n",
      "[600]\ttraining's l2: 0.0153064\tvalid_1's l2: 0.0496202\n",
      "[800]\ttraining's l2: 0.0124545\tvalid_1's l2: 0.047582\n",
      "[1000]\ttraining's l2: 0.0102872\tvalid_1's l2: 0.0466206\n",
      "[1200]\ttraining's l2: 0.00857354\tvalid_1's l2: 0.0461445\n",
      "[1400]\ttraining's l2: 0.00723993\tvalid_1's l2: 0.0458172\n",
      "[1600]\ttraining's l2: 0.00620162\tvalid_1's l2: 0.0456261\n",
      "[1800]\ttraining's l2: 0.00535629\tvalid_1's l2: 0.0455539\n",
      "Early stopping, best iteration is:\n",
      "[1717]\ttraining's l2: 0.00566922\tvalid_1's l2: 0.0455365\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0706348\tvalid_1's l2: 0.103946\n",
      "[400]\ttraining's l2: 0.0240201\tvalid_1's l2: 0.0565016\n",
      "[600]\ttraining's l2: 0.0158115\tvalid_1's l2: 0.0483603\n",
      "[800]\ttraining's l2: 0.0120968\tvalid_1's l2: 0.0453699\n",
      "[1000]\ttraining's l2: 0.00971215\tvalid_1's l2: 0.0440867\n",
      "[1200]\ttraining's l2: 0.0080637\tvalid_1's l2: 0.0433959\n",
      "[1400]\ttraining's l2: 0.00678875\tvalid_1's l2: 0.0427928\n",
      "[1600]\ttraining's l2: 0.00583075\tvalid_1's l2: 0.0424183\n",
      "[1800]\ttraining's l2: 0.00511705\tvalid_1's l2: 0.0421763\n",
      "[2000]\ttraining's l2: 0.00463814\tvalid_1's l2: 0.0421035\n",
      "[2200]\ttraining's l2: 0.00451693\tvalid_1's l2: 0.0420801\n",
      "Early stopping, best iteration is:\n",
      "[2074]\ttraining's l2: 0.00453302\tvalid_1's l2: 0.0420798\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0799402\tvalid_1's l2: 0.109569\n",
      "[400]\ttraining's l2: 0.027325\tvalid_1's l2: 0.0639601\n",
      "[600]\ttraining's l2: 0.0180389\tvalid_1's l2: 0.0561325\n",
      "[800]\ttraining's l2: 0.0139253\tvalid_1's l2: 0.0536194\n",
      "[1000]\ttraining's l2: 0.0110149\tvalid_1's l2: 0.0524343\n",
      "[1200]\ttraining's l2: 0.00910107\tvalid_1's l2: 0.0519042\n",
      "[1400]\ttraining's l2: 0.00768414\tvalid_1's l2: 0.0515807\n",
      "[1600]\ttraining's l2: 0.00656071\tvalid_1's l2: 0.0515369\n",
      "Early stopping, best iteration is:\n",
      "[1458]\ttraining's l2: 0.0073271\tvalid_1's l2: 0.0515063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\ipykernel_launcher.py:157: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\ipykernel_launcher.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\ipykernel_launcher.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\ipykernel_launcher.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# 模型\n",
    "le_model = preprocessing.LabelEncoder()\n",
    "le_bodyType = preprocessing.LabelEncoder()\n",
    "\n",
    "le_model.fit(train_data.model)\n",
    "le_bodyType.fit(train_data.bodyType)\n",
    "\n",
    "lgb_params = {\n",
    "    \"num_leaves\":31,\n",
    "    \"reg_alpha\":1,\n",
    "    \"reg_lambda\":0.1,\n",
    "    \"objective\":'mse',\n",
    "    \"max_depth\": 4,\n",
    "    \"learning_rate\":0.01,\n",
    "    \"min_child_samples\":5,\n",
    "    \"random_state\":2019,\n",
    "    \"n_estimators\":4000,\n",
    "    \"subsample\":0.8,\n",
    "    \"colsample_bytree\":0.8\n",
    "}\n",
    "\n",
    "df_train_columns = [c for c in train_data.columns if c not in []]\n",
    "print(\"df_train_columns:\",df_train_columns)\n",
    "cate_fea = [\"adcode\", \"model\", \"bodyType\"]\n",
    "train_data.model = le_model.transform(train_data.model)\n",
    "train_data.bodyType = le_bodyType.transform(train_data.bodyType)\n",
    "print(train_data.shape)\n",
    "print(len(df_train_columns))\n",
    "\n",
    "\n",
    "y_score = []    # 交叉验证\n",
    "cv_pred = []    # 各折的预测值\n",
    "predictions = 0\n",
    "feature_importance_df = pd.DataFrame()\n",
    "skf = KFold(n_splits=5, random_state=random.randint(100, 10000), shuffle=True)\n",
    "\n",
    "\n",
    "label_0 = vaild_data[0]\n",
    "label_1 = vaild_data[1]\n",
    "label_2 = vaild_data[2]\n",
    "label_3 = vaild_data[3]\n",
    "\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(skf.split(train_data, label_0)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train_data.iloc[trn_idx][df_train_columns], label=label_0.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_data.iloc[val_idx][df_train_columns], label=label_0.iloc[val_idx])\n",
    "\n",
    "    result_df = train_data.iloc[val_idx][[\"adcode\", \"model\"]]\n",
    "\n",
    "    gbm_1 = lgb.train(lgb_params,\n",
    "                    trn_data,\n",
    "                    # init_model=gbm,\n",
    "                    num_boost_round=150000,\n",
    "                    valid_sets=[trn_data, val_data],\n",
    "                    early_stopping_rounds=200,\n",
    "                    verbose_eval=200,\n",
    "                    categorical_feature=cate_fea)     # 训练\n",
    "\n",
    "    trn_data = lgb.Dataset(train_data.iloc[trn_idx][df_train_columns], label=label_1.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_data.iloc[val_idx][df_train_columns], label=label_1.iloc[val_idx])\n",
    "\n",
    "    gbm_2 = lgb.train(lgb_params,\n",
    "                    trn_data,\n",
    "                    # init_model=gbm,\n",
    "                    num_boost_round=150000,\n",
    "                    valid_sets=[trn_data, val_data],\n",
    "                    early_stopping_rounds=200,\n",
    "                    verbose_eval=200,\n",
    "                    categorical_feature=cate_fea)     # 训练\n",
    "\n",
    "    trn_data = lgb.Dataset(train_data.iloc[trn_idx][df_train_columns], label=label_2.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_data.iloc[val_idx][df_train_columns], label=label_2.iloc[val_idx])\n",
    "\n",
    "    gbm_3 = lgb.train(lgb_params,\n",
    "                    trn_data,\n",
    "                    # init_model=gbm,\n",
    "                    num_boost_round=3000,\n",
    "                    valid_sets=[trn_data, val_data],\n",
    "                    early_stopping_rounds=200,\n",
    "                    verbose_eval=200,\n",
    "                    categorical_feature=cate_fea)     # 训练\n",
    "\n",
    "    trn_data = lgb.Dataset(train_data.iloc[trn_idx][df_train_columns], label=label_3.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_data.iloc[val_idx][df_train_columns], label=label_3.iloc[val_idx])\n",
    "\n",
    "    gbm_4 = lgb.train(lgb_params,\n",
    "                    trn_data,\n",
    "                    # init_model=gbm,\n",
    "                    num_boost_round=150000,\n",
    "                    valid_sets=[trn_data, val_data],\n",
    "                    early_stopping_rounds=200,\n",
    "                    verbose_eval=200,\n",
    "                    categorical_feature=cate_fea)     # 训练\n",
    "\n",
    "    result_df[\"y_pred_1\"] = gbm_1.predict(train_data.iloc[val_idx][df_train_columns])\n",
    "    result_df[\"y_pred_2\"] = gbm_2.predict(train_data.iloc[val_idx][df_train_columns])\n",
    "    result_df[\"y_pred_3\"] = gbm_3.predict(train_data.iloc[val_idx][df_train_columns])\n",
    "    result_df[\"y_pred_4\"] = gbm_4.predict(train_data.iloc[val_idx][df_train_columns])\n",
    "    # break\n",
    "\n",
    "result_df[\"y_true_1\"] = label_0\n",
    "result_df[\"y_true_2\"] = label_1\n",
    "result_df[\"y_true_3\"] = label_2\n",
    "result_df[\"y_true_4\"] = label_3\n",
    "\n",
    "# 预测\n",
    "# 基础特征\n",
    "# 城市+车\n",
    "test_basic_fea = cal_basic_fea(train_sales, \"salesVolume\", [\"adcode\", \"model\", \"regMonth\"], \"test\")\n",
    "# 城市\n",
    "tmp_df = cal_basic_fea(train_sales, \"salesVolume\", [\"adcode\", \"regMonth\"], \"test\")\n",
    "test_basic_fea = pd.merge(test_basic_fea, tmp_df, on=\"adcode\", how=\"left\")\n",
    "# 车\n",
    "tmp_df = cal_basic_fea(train_sales, \"salesVolume\", [\"model\", \"regMonth\"], \"test\")\n",
    "test_basic_fea = pd.merge(test_basic_fea, tmp_df, on=\"model\", how=\"left\")\n",
    "# 城市+车型\n",
    "tmp_df = cal_basic_fea(train_sales, \"salesVolume\", [\"adcode\", \"bodyType\", \"regMonth\"], \"test\")\n",
    "test_basic_fea[\"bodyType\"] = test_basic_fea.model.apply(lambda x: model2type[x])\n",
    "test_basic_fea = pd.merge(test_basic_fea, tmp_df, on=[\"adcode\", \"bodyType\"], how=\"left\")\n",
    "\n",
    "# 滑窗特征\n",
    "# 城市+车\n",
    "test_windows_fea = cal_windows_fea(train_sales, cal_col=\"salesVolume\", stat_dim=[\"adcode\", \"model\", \"regMonth\"], data_type=\"test\")\n",
    "# 城市\n",
    "tmp_df = cal_windows_fea(train_sales, \"salesVolume\", [\"adcode\", \"regMonth\"], \"test\")\n",
    "test_windows_fea = pd.merge(test_windows_fea, tmp_df, on=\"adcode\", how=\"left\")\n",
    "# 车\n",
    "tmp_df = cal_windows_fea(train_sales, \"salesVolume\", [\"model\", \"regMonth\"], \"test\")\n",
    "test_windows_fea = pd.merge(test_windows_fea, tmp_df, on=\"model\", how=\"left\")\n",
    "# 城市+车型\n",
    "tmp_df = cal_windows_fea(train_sales, \"salesVolume\", [\"adcode\", \"bodyType\", \"regMonth\"], \"test\")\n",
    "test_windows_fea[\"bodyType\"] = test_windows_fea.model.apply(lambda x: model2type[x])\n",
    "test_windows_fea = pd.merge(test_windows_fea, tmp_df, on=[\"adcode\", \"bodyType\"], how=\"left\")\n",
    "\n",
    "# 合并\n",
    "test_data = pd.merge(test_basic_fea, test_windows_fea, on=[\"adcode\", \"model\", \"bodyType\"], how=\"left\")\n",
    "\n",
    "test_data.model = le_model.transform(test_data.model)\n",
    "test_data.bodyType = le_bodyType.transform(test_data.bodyType)\n",
    "\n",
    "y_pred_1 = gbm_1.predict(test_data[df_train_columns])\n",
    "y_pred_2 = gbm_2.predict(test_data[df_train_columns])\n",
    "y_pred_3 = gbm_3.predict(test_data[df_train_columns])\n",
    "y_pred_4 = gbm_4.predict(test_data[df_train_columns])\n",
    "\n",
    "y_pred_1 = (np.e ** y_pred_1 - 1).astype(int)\n",
    "y_pred_2 = (np.e ** y_pred_2 - 1).astype(int)\n",
    "y_pred_3 = (np.e ** y_pred_3 - 1).astype(int)\n",
    "y_pred_4 = (np.e ** y_pred_4 - 1).astype(int)\n",
    "\n",
    "result_df = test_basic_fea[[\"adcode\", \"model\"]]\n",
    "result_df[\"y_pred_1\"] = y_pred_1\n",
    "result_df[\"y_pred_2\"] = y_pred_2\n",
    "result_df[\"y_pred_3\"] = y_pred_3\n",
    "result_df[\"y_pred_4\"] = y_pred_4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train_columns: ['adcode', 'model', 'adcode_model_regMonth_salesVolume_1', 'adcode_model_regMonth_salesVolume_2', 'adcode_model_regMonth_salesVolume_3', 'adcode_model_regMonth_salesVolume_4', 'adcode_model_regMonth_salesVolume_5', 'adcode_model_regMonth_salesVolume_6', 'adcode_model_regMonth_salesVolume_7', 'adcode_model_regMonth_salesVolume_8', 'adcode_model_regMonth_salesVolume_9', 'adcode_model_regMonth_salesVolume_10', 'adcode_model_regMonth_salesVolume_11', 'adcode_model_regMonth_salesVolume_12', 'adcode_model_regMonth_salesVolume_shift_div_2', 'adcode_model_regMonth_salesVolume_shift_div_3', 'adcode_model_regMonth_salesVolume_shift_div_4', 'adcode_model_regMonth_salesVolume_shift_div_5', 'adcode_model_regMonth_salesVolume_shift_div_6', 'adcode_model_regMonth_salesVolume_shift_div_7', 'adcode_model_regMonth_salesVolume_shift_div_8', 'adcode_model_regMonth_salesVolume_shift_div_9', 'adcode_model_regMonth_salesVolume_shift_div_10', 'adcode_model_regMonth_salesVolume_shift_div_11', 'adcode_model_regMonth_salesVolume_shift_div_12', 'adcode_model_regMonth_salesVolume_shift_sub_2', 'adcode_model_regMonth_salesVolume_shift_sub_3', 'adcode_model_regMonth_salesVolume_shift_sub_4', 'adcode_model_regMonth_salesVolume_shift_sub_5', 'adcode_model_regMonth_salesVolume_shift_sub_6', 'adcode_model_regMonth_salesVolume_shift_sub_7', 'adcode_model_regMonth_salesVolume_shift_sub_8', 'adcode_model_regMonth_salesVolume_shift_sub_9', 'adcode_model_regMonth_salesVolume_shift_sub_10', 'adcode_model_regMonth_salesVolume_shift_sub_11', 'adcode_model_regMonth_salesVolume_shift_sub_12', 'adcode_model_regMonth_salesVolume_shift_2_div_2', 'adcode_model_regMonth_salesVolume_shift_2_div_3', 'adcode_model_regMonth_salesVolume_shift_2_div_4', 'adcode_model_regMonth_salesVolume_shift_2_div_5', 'adcode_model_regMonth_salesVolume_shift_2_div_6', 'adcode_model_regMonth_salesVolume_shift_2_div_7', 'adcode_model_regMonth_salesVolume_shift_2_div_8', 'adcode_model_regMonth_salesVolume_shift_2_div_9', 'adcode_model_regMonth_salesVolume_shift_2_div_10', 'adcode_model_regMonth_salesVolume_shift_2_div_11', 'adcode_model_regMonth_salesVolume_shift_2_div_12', 'adcode_model_regMonth_salesVolume_shift_2_sub_2', 'adcode_model_regMonth_salesVolume_shift_2_sub_3', 'adcode_model_regMonth_salesVolume_shift_2_sub_4', 'adcode_model_regMonth_salesVolume_shift_2_sub_5', 'adcode_model_regMonth_salesVolume_shift_2_sub_6', 'adcode_model_regMonth_salesVolume_shift_2_sub_7', 'adcode_model_regMonth_salesVolume_shift_2_sub_8', 'adcode_model_regMonth_salesVolume_shift_2_sub_9', 'adcode_model_regMonth_salesVolume_shift_2_sub_10', 'adcode_model_regMonth_salesVolume_shift_2_sub_11', 'adcode_model_regMonth_salesVolume_shift_2_sub_12', 'adcode_regMonth_salesVolume_1', 'adcode_regMonth_salesVolume_2', 'adcode_regMonth_salesVolume_3', 'adcode_regMonth_salesVolume_4', 'adcode_regMonth_salesVolume_5', 'adcode_regMonth_salesVolume_6', 'adcode_regMonth_salesVolume_7', 'adcode_regMonth_salesVolume_8', 'adcode_regMonth_salesVolume_9', 'adcode_regMonth_salesVolume_10', 'adcode_regMonth_salesVolume_11', 'adcode_regMonth_salesVolume_12', 'adcode_regMonth_salesVolume_shift_div_2', 'adcode_regMonth_salesVolume_shift_div_3', 'adcode_regMonth_salesVolume_shift_div_4', 'adcode_regMonth_salesVolume_shift_div_5', 'adcode_regMonth_salesVolume_shift_div_6', 'adcode_regMonth_salesVolume_shift_div_7', 'adcode_regMonth_salesVolume_shift_div_8', 'adcode_regMonth_salesVolume_shift_div_9', 'adcode_regMonth_salesVolume_shift_div_10', 'adcode_regMonth_salesVolume_shift_div_11', 'adcode_regMonth_salesVolume_shift_div_12', 'adcode_regMonth_salesVolume_shift_sub_2', 'adcode_regMonth_salesVolume_shift_sub_3', 'adcode_regMonth_salesVolume_shift_sub_4', 'adcode_regMonth_salesVolume_shift_sub_5', 'adcode_regMonth_salesVolume_shift_sub_6', 'adcode_regMonth_salesVolume_shift_sub_7', 'adcode_regMonth_salesVolume_shift_sub_8', 'adcode_regMonth_salesVolume_shift_sub_9', 'adcode_regMonth_salesVolume_shift_sub_10', 'adcode_regMonth_salesVolume_shift_sub_11', 'adcode_regMonth_salesVolume_shift_sub_12', 'adcode_regMonth_salesVolume_shift_2_div_2', 'adcode_regMonth_salesVolume_shift_2_div_3', 'adcode_regMonth_salesVolume_shift_2_div_4', 'adcode_regMonth_salesVolume_shift_2_div_5', 'adcode_regMonth_salesVolume_shift_2_div_6', 'adcode_regMonth_salesVolume_shift_2_div_7', 'adcode_regMonth_salesVolume_shift_2_div_8', 'adcode_regMonth_salesVolume_shift_2_div_9', 'adcode_regMonth_salesVolume_shift_2_div_10', 'adcode_regMonth_salesVolume_shift_2_div_11', 'adcode_regMonth_salesVolume_shift_2_div_12', 'adcode_regMonth_salesVolume_shift_2_sub_2', 'adcode_regMonth_salesVolume_shift_2_sub_3', 'adcode_regMonth_salesVolume_shift_2_sub_4', 'adcode_regMonth_salesVolume_shift_2_sub_5', 'adcode_regMonth_salesVolume_shift_2_sub_6', 'adcode_regMonth_salesVolume_shift_2_sub_7', 'adcode_regMonth_salesVolume_shift_2_sub_8', 'adcode_regMonth_salesVolume_shift_2_sub_9', 'adcode_regMonth_salesVolume_shift_2_sub_10', 'adcode_regMonth_salesVolume_shift_2_sub_11', 'adcode_regMonth_salesVolume_shift_2_sub_12', 'model_regMonth_salesVolume_1', 'model_regMonth_salesVolume_2', 'model_regMonth_salesVolume_3', 'model_regMonth_salesVolume_4', 'model_regMonth_salesVolume_5', 'model_regMonth_salesVolume_6', 'model_regMonth_salesVolume_7', 'model_regMonth_salesVolume_8', 'model_regMonth_salesVolume_9', 'model_regMonth_salesVolume_10', 'model_regMonth_salesVolume_11', 'model_regMonth_salesVolume_12', 'model_regMonth_salesVolume_shift_div_2', 'model_regMonth_salesVolume_shift_div_3', 'model_regMonth_salesVolume_shift_div_4', 'model_regMonth_salesVolume_shift_div_5', 'model_regMonth_salesVolume_shift_div_6', 'model_regMonth_salesVolume_shift_div_7', 'model_regMonth_salesVolume_shift_div_8', 'model_regMonth_salesVolume_shift_div_9', 'model_regMonth_salesVolume_shift_div_10', 'model_regMonth_salesVolume_shift_div_11', 'model_regMonth_salesVolume_shift_div_12', 'model_regMonth_salesVolume_shift_sub_2', 'model_regMonth_salesVolume_shift_sub_3', 'model_regMonth_salesVolume_shift_sub_4', 'model_regMonth_salesVolume_shift_sub_5', 'model_regMonth_salesVolume_shift_sub_6', 'model_regMonth_salesVolume_shift_sub_7', 'model_regMonth_salesVolume_shift_sub_8', 'model_regMonth_salesVolume_shift_sub_9', 'model_regMonth_salesVolume_shift_sub_10', 'model_regMonth_salesVolume_shift_sub_11', 'model_regMonth_salesVolume_shift_sub_12', 'model_regMonth_salesVolume_shift_2_div_2', 'model_regMonth_salesVolume_shift_2_div_3', 'model_regMonth_salesVolume_shift_2_div_4', 'model_regMonth_salesVolume_shift_2_div_5', 'model_regMonth_salesVolume_shift_2_div_6', 'model_regMonth_salesVolume_shift_2_div_7', 'model_regMonth_salesVolume_shift_2_div_8', 'model_regMonth_salesVolume_shift_2_div_9', 'model_regMonth_salesVolume_shift_2_div_10', 'model_regMonth_salesVolume_shift_2_div_11', 'model_regMonth_salesVolume_shift_2_div_12', 'model_regMonth_salesVolume_shift_2_sub_2', 'model_regMonth_salesVolume_shift_2_sub_3', 'model_regMonth_salesVolume_shift_2_sub_4', 'model_regMonth_salesVolume_shift_2_sub_5', 'model_regMonth_salesVolume_shift_2_sub_6', 'model_regMonth_salesVolume_shift_2_sub_7', 'model_regMonth_salesVolume_shift_2_sub_8', 'model_regMonth_salesVolume_shift_2_sub_9', 'model_regMonth_salesVolume_shift_2_sub_10', 'model_regMonth_salesVolume_shift_2_sub_11', 'model_regMonth_salesVolume_shift_2_sub_12', 'bodyType', 'adcode_bodyType_regMonth_salesVolume_1', 'adcode_bodyType_regMonth_salesVolume_2', 'adcode_bodyType_regMonth_salesVolume_3', 'adcode_bodyType_regMonth_salesVolume_4', 'adcode_bodyType_regMonth_salesVolume_5', 'adcode_bodyType_regMonth_salesVolume_6', 'adcode_bodyType_regMonth_salesVolume_7', 'adcode_bodyType_regMonth_salesVolume_8', 'adcode_bodyType_regMonth_salesVolume_9', 'adcode_bodyType_regMonth_salesVolume_10', 'adcode_bodyType_regMonth_salesVolume_11', 'adcode_bodyType_regMonth_salesVolume_12', 'adcode_bodyType_regMonth_salesVolume_shift_div_2', 'adcode_bodyType_regMonth_salesVolume_shift_div_3', 'adcode_bodyType_regMonth_salesVolume_shift_div_4', 'adcode_bodyType_regMonth_salesVolume_shift_div_5', 'adcode_bodyType_regMonth_salesVolume_shift_div_6', 'adcode_bodyType_regMonth_salesVolume_shift_div_7', 'adcode_bodyType_regMonth_salesVolume_shift_div_8', 'adcode_bodyType_regMonth_salesVolume_shift_div_9', 'adcode_bodyType_regMonth_salesVolume_shift_div_10', 'adcode_bodyType_regMonth_salesVolume_shift_div_11', 'adcode_bodyType_regMonth_salesVolume_shift_div_12', 'adcode_bodyType_regMonth_salesVolume_shift_sub_2', 'adcode_bodyType_regMonth_salesVolume_shift_sub_3', 'adcode_bodyType_regMonth_salesVolume_shift_sub_4', 'adcode_bodyType_regMonth_salesVolume_shift_sub_5', 'adcode_bodyType_regMonth_salesVolume_shift_sub_6', 'adcode_bodyType_regMonth_salesVolume_shift_sub_7', 'adcode_bodyType_regMonth_salesVolume_shift_sub_8', 'adcode_bodyType_regMonth_salesVolume_shift_sub_9', 'adcode_bodyType_regMonth_salesVolume_shift_sub_10', 'adcode_bodyType_regMonth_salesVolume_shift_sub_11', 'adcode_bodyType_regMonth_salesVolume_shift_sub_12', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_2', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_3', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_4', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_5', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_6', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_7', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_8', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_9', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_10', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_11', 'adcode_bodyType_regMonth_salesVolume_shift_2_div_12', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_2', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_3', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_4', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_5', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_6', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_7', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_8', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_9', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_10', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_11', 'adcode_bodyType_regMonth_salesVolume_shift_2_sub_12', 'adcode_model_regMonth_salesVolume_rolling_mean_3', 'adcode_model_regMonth_salesVolume_rolling_mean_4', 'adcode_model_regMonth_salesVolume_rolling_mean_5', 'adcode_model_regMonth_salesVolume_rolling_mean_6', 'adcode_model_regMonth_salesVolume_rolling_mean_7', 'adcode_model_regMonth_salesVolume_rolling_mean_8', 'adcode_model_regMonth_salesVolume_rolling_mean_9', 'adcode_model_regMonth_salesVolume_rolling_mean_10', 'adcode_model_regMonth_salesVolume_rolling_mean_11', 'adcode_model_regMonth_salesVolume_rolling_mean_12', 'adcode_model_regMonth_salesVolume_rolling_std_3', 'adcode_model_regMonth_salesVolume_rolling_std_4', 'adcode_model_regMonth_salesVolume_rolling_std_5', 'adcode_model_regMonth_salesVolume_rolling_std_6', 'adcode_model_regMonth_salesVolume_rolling_std_7', 'adcode_model_regMonth_salesVolume_rolling_std_8', 'adcode_model_regMonth_salesVolume_rolling_std_9', 'adcode_model_regMonth_salesVolume_rolling_std_10', 'adcode_model_regMonth_salesVolume_rolling_std_11', 'adcode_model_regMonth_salesVolume_rolling_std_12', 'adcode_model_regMonth_salesVolume_rolling_sum_3', 'adcode_model_regMonth_salesVolume_rolling_sum_4', 'adcode_model_regMonth_salesVolume_rolling_sum_5', 'adcode_model_regMonth_salesVolume_rolling_sum_6', 'adcode_model_regMonth_salesVolume_rolling_sum_7', 'adcode_model_regMonth_salesVolume_rolling_sum_8', 'adcode_model_regMonth_salesVolume_rolling_sum_9', 'adcode_model_regMonth_salesVolume_rolling_sum_10', 'adcode_model_regMonth_salesVolume_rolling_sum_11', 'adcode_model_regMonth_salesVolume_rolling_sum_12', 'adcode_regMonth_salesVolume_rolling_mean_3', 'adcode_regMonth_salesVolume_rolling_mean_4', 'adcode_regMonth_salesVolume_rolling_mean_5', 'adcode_regMonth_salesVolume_rolling_mean_6', 'adcode_regMonth_salesVolume_rolling_mean_7', 'adcode_regMonth_salesVolume_rolling_mean_8', 'adcode_regMonth_salesVolume_rolling_mean_9', 'adcode_regMonth_salesVolume_rolling_mean_10', 'adcode_regMonth_salesVolume_rolling_mean_11', 'adcode_regMonth_salesVolume_rolling_mean_12', 'adcode_regMonth_salesVolume_rolling_std_3', 'adcode_regMonth_salesVolume_rolling_std_4', 'adcode_regMonth_salesVolume_rolling_std_5', 'adcode_regMonth_salesVolume_rolling_std_6', 'adcode_regMonth_salesVolume_rolling_std_7', 'adcode_regMonth_salesVolume_rolling_std_8', 'adcode_regMonth_salesVolume_rolling_std_9', 'adcode_regMonth_salesVolume_rolling_std_10', 'adcode_regMonth_salesVolume_rolling_std_11', 'adcode_regMonth_salesVolume_rolling_std_12', 'adcode_regMonth_salesVolume_rolling_sum_3', 'adcode_regMonth_salesVolume_rolling_sum_4', 'adcode_regMonth_salesVolume_rolling_sum_5', 'adcode_regMonth_salesVolume_rolling_sum_6', 'adcode_regMonth_salesVolume_rolling_sum_7', 'adcode_regMonth_salesVolume_rolling_sum_8', 'adcode_regMonth_salesVolume_rolling_sum_9', 'adcode_regMonth_salesVolume_rolling_sum_10', 'adcode_regMonth_salesVolume_rolling_sum_11', 'adcode_regMonth_salesVolume_rolling_sum_12', 'model_regMonth_salesVolume_rolling_mean_3', 'model_regMonth_salesVolume_rolling_mean_4', 'model_regMonth_salesVolume_rolling_mean_5', 'model_regMonth_salesVolume_rolling_mean_6', 'model_regMonth_salesVolume_rolling_mean_7', 'model_regMonth_salesVolume_rolling_mean_8', 'model_regMonth_salesVolume_rolling_mean_9', 'model_regMonth_salesVolume_rolling_mean_10', 'model_regMonth_salesVolume_rolling_mean_11', 'model_regMonth_salesVolume_rolling_mean_12', 'model_regMonth_salesVolume_rolling_std_3', 'model_regMonth_salesVolume_rolling_std_4', 'model_regMonth_salesVolume_rolling_std_5', 'model_regMonth_salesVolume_rolling_std_6', 'model_regMonth_salesVolume_rolling_std_7', 'model_regMonth_salesVolume_rolling_std_8', 'model_regMonth_salesVolume_rolling_std_9', 'model_regMonth_salesVolume_rolling_std_10', 'model_regMonth_salesVolume_rolling_std_11', 'model_regMonth_salesVolume_rolling_std_12', 'model_regMonth_salesVolume_rolling_sum_3', 'model_regMonth_salesVolume_rolling_sum_4', 'model_regMonth_salesVolume_rolling_sum_5', 'model_regMonth_salesVolume_rolling_sum_6', 'model_regMonth_salesVolume_rolling_sum_7', 'model_regMonth_salesVolume_rolling_sum_8', 'model_regMonth_salesVolume_rolling_sum_9', 'model_regMonth_salesVolume_rolling_sum_10', 'model_regMonth_salesVolume_rolling_sum_11', 'model_regMonth_salesVolume_rolling_sum_12', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_3', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_4', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_5', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_6', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_7', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_8', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_9', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_10', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_11', 'adcode_bodyType_regMonth_salesVolume_rolling_mean_12', 'adcode_bodyType_regMonth_salesVolume_rolling_std_3', 'adcode_bodyType_regMonth_salesVolume_rolling_std_4', 'adcode_bodyType_regMonth_salesVolume_rolling_std_5', 'adcode_bodyType_regMonth_salesVolume_rolling_std_6', 'adcode_bodyType_regMonth_salesVolume_rolling_std_7', 'adcode_bodyType_regMonth_salesVolume_rolling_std_8', 'adcode_bodyType_regMonth_salesVolume_rolling_std_9', 'adcode_bodyType_regMonth_salesVolume_rolling_std_10', 'adcode_bodyType_regMonth_salesVolume_rolling_std_11', 'adcode_bodyType_regMonth_salesVolume_rolling_std_12', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_3', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_4', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_5', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_6', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_7', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_8', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_9', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_10', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_11', 'adcode_bodyType_regMonth_salesVolume_rolling_sum_12']"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(1320, 347)\n",
      "347\n",
      "fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\lightgbm\\engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['adcode', 'bodyType', 'model']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\lightgbm\\basic.py:762: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0784653\tvalid_1's l2: 0.117199\n",
      "[400]\ttraining's l2: 0.0234233\tvalid_1's l2: 0.0624278\n",
      "[600]\ttraining's l2: 0.0146224\tvalid_1's l2: 0.05196\n",
      "[800]\ttraining's l2: 0.0110052\tvalid_1's l2: 0.0484078\n",
      "[1000]\ttraining's l2: 0.00881217\tvalid_1's l2: 0.0465347\n",
      "[1200]\ttraining's l2: 0.00730667\tvalid_1's l2: 0.0455504\n",
      "[1400]\ttraining's l2: 0.00614076\tvalid_1's l2: 0.0451977\n",
      "[1600]\ttraining's l2: 0.00525662\tvalid_1's l2: 0.0448401\n",
      "[1800]\ttraining's l2: 0.00459806\tvalid_1's l2: 0.0445541\n",
      "[2000]\ttraining's l2: 0.00413173\tvalid_1's l2: 0.0445176\n",
      "[2200]\ttraining's l2: 0.00400036\tvalid_1's l2: 0.0445261\n",
      "Early stopping, best iteration is:\n",
      "[2030]\ttraining's l2: 0.00407556\tvalid_1's l2: 0.0445\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.070053\tvalid_1's l2: 0.107385\n",
      "[400]\ttraining's l2: 0.0226529\tvalid_1's l2: 0.0600138\n",
      "[600]\ttraining's l2: 0.0150841\tvalid_1's l2: 0.0512898\n",
      "[800]\ttraining's l2: 0.0116219\tvalid_1's l2: 0.0487931\n",
      "[1000]\ttraining's l2: 0.00896842\tvalid_1's l2: 0.0477422\n",
      "[1200]\ttraining's l2: 0.00732658\tvalid_1's l2: 0.0472662\n",
      "[1400]\ttraining's l2: 0.0061547\tvalid_1's l2: 0.0471669\n",
      "[1600]\ttraining's l2: 0.00531947\tvalid_1's l2: 0.0470493\n",
      "[1800]\ttraining's l2: 0.00471556\tvalid_1's l2: 0.0470152\n",
      "[2000]\ttraining's l2: 0.00430463\tvalid_1's l2: 0.0469892\n",
      "Early stopping, best iteration is:\n",
      "[1881]\ttraining's l2: 0.00452788\tvalid_1's l2: 0.0469678\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0698108\tvalid_1's l2: 0.0831942\n",
      "[400]\ttraining's l2: 0.0233006\tvalid_1's l2: 0.0548883\n",
      "[600]\ttraining's l2: 0.01545\tvalid_1's l2: 0.0504882\n",
      "[800]\ttraining's l2: 0.0117201\tvalid_1's l2: 0.0498258\n",
      "[1000]\ttraining's l2: 0.00909231\tvalid_1's l2: 0.049088\n",
      "[1200]\ttraining's l2: 0.00735726\tvalid_1's l2: 0.0490589\n",
      "Early stopping, best iteration is:\n",
      "[1090]\ttraining's l2: 0.00821995\tvalid_1's l2: 0.0489958\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0765871\tvalid_1's l2: 0.10254\n",
      "[400]\ttraining's l2: 0.0247729\tvalid_1's l2: 0.0740763\n",
      "[600]\ttraining's l2: 0.0159581\tvalid_1's l2: 0.0707481\n",
      "[800]\ttraining's l2: 0.0120835\tvalid_1's l2: 0.0693613\n",
      "[1000]\ttraining's l2: 0.00956921\tvalid_1's l2: 0.0687244\n",
      "[1200]\ttraining's l2: 0.00792891\tvalid_1's l2: 0.0683213\n",
      "[1400]\ttraining's l2: 0.0066698\tvalid_1's l2: 0.0680971\n",
      "[1600]\ttraining's l2: 0.00571976\tvalid_1's l2: 0.0676763\n",
      "[1800]\ttraining's l2: 0.00503078\tvalid_1's l2: 0.0674418\n",
      "[2000]\ttraining's l2: 0.00449501\tvalid_1's l2: 0.06733\n",
      "[2200]\ttraining's l2: 0.00430374\tvalid_1's l2: 0.0673226\n",
      "Early stopping, best iteration is:\n",
      "[2021]\ttraining's l2: 0.00444356\tvalid_1's l2: 0.0673094\n",
      "fold 1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0797794\tvalid_1's l2: 0.0884348\n",
      "[400]\ttraining's l2: 0.0246286\tvalid_1's l2: 0.046042\n",
      "[600]\ttraining's l2: 0.0152044\tvalid_1's l2: 0.0398629\n",
      "[800]\ttraining's l2: 0.0113243\tvalid_1's l2: 0.0378887\n",
      "[1000]\ttraining's l2: 0.00897169\tvalid_1's l2: 0.0372084\n",
      "[1200]\ttraining's l2: 0.00734315\tvalid_1's l2: 0.0368514\n",
      "[1400]\ttraining's l2: 0.00613529\tvalid_1's l2: 0.0367004\n",
      "[1600]\ttraining's l2: 0.00522529\tvalid_1's l2: 0.0365532\n",
      "[1800]\ttraining's l2: 0.00456679\tvalid_1's l2: 0.0365744\n",
      "Early stopping, best iteration is:\n",
      "[1660]\ttraining's l2: 0.00501152\tvalid_1's l2: 0.0365249\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0696814\tvalid_1's l2: 0.111477\n",
      "[400]\ttraining's l2: 0.022344\tvalid_1's l2: 0.0632744\n",
      "[600]\ttraining's l2: 0.0147375\tvalid_1's l2: 0.0558031\n",
      "[800]\ttraining's l2: 0.011643\tvalid_1's l2: 0.0534118\n",
      "[1000]\ttraining's l2: 0.00958455\tvalid_1's l2: 0.0523475\n",
      "[1200]\ttraining's l2: 0.00793775\tvalid_1's l2: 0.0520149\n",
      "[1400]\ttraining's l2: 0.00666886\tvalid_1's l2: 0.0517308\n",
      "[1600]\ttraining's l2: 0.00573431\tvalid_1's l2: 0.0515705\n",
      "[1800]\ttraining's l2: 0.00502217\tvalid_1's l2: 0.0513669\n",
      "[2000]\ttraining's l2: 0.00448749\tvalid_1's l2: 0.0512747\n",
      "[2200]\ttraining's l2: 0.00418453\tvalid_1's l2: 0.0512484\n",
      "Early stopping, best iteration is:\n",
      "[2062]\ttraining's l2: 0.00434648\tvalid_1's l2: 0.0512408\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.070445\tvalid_1's l2: 0.0888603\n",
      "[400]\ttraining's l2: 0.0239325\tvalid_1's l2: 0.0479415\n",
      "[600]\ttraining's l2: 0.0156669\tvalid_1's l2: 0.0432334\n",
      "[800]\ttraining's l2: 0.0119669\tvalid_1's l2: 0.0417139\n",
      "[1000]\ttraining's l2: 0.00947666\tvalid_1's l2: 0.0413165\n",
      "[1200]\ttraining's l2: 0.00766376\tvalid_1's l2: 0.0413544\n",
      "[1400]\ttraining's l2: 0.00640478\tvalid_1's l2: 0.0411191\n",
      "[1600]\ttraining's l2: 0.00547674\tvalid_1's l2: 0.0409824\n",
      "[1800]\ttraining's l2: 0.00480055\tvalid_1's l2: 0.0410155\n",
      "Early stopping, best iteration is:\n",
      "[1681]\ttraining's l2: 0.00519033\tvalid_1's l2: 0.0409479\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0785003\tvalid_1's l2: 0.105077\n",
      "[400]\ttraining's l2: 0.0268495\tvalid_1's l2: 0.0583863\n",
      "[600]\ttraining's l2: 0.0176382\tvalid_1's l2: 0.0510375\n",
      "[800]\ttraining's l2: 0.013471\tvalid_1's l2: 0.0482212\n",
      "[1000]\ttraining's l2: 0.0106358\tvalid_1's l2: 0.0469634\n",
      "[1200]\ttraining's l2: 0.0085502\tvalid_1's l2: 0.0461867\n",
      "[1400]\ttraining's l2: 0.00711767\tvalid_1's l2: 0.0455941\n",
      "[1600]\ttraining's l2: 0.00604201\tvalid_1's l2: 0.045159\n",
      "[1800]\ttraining's l2: 0.0053098\tvalid_1's l2: 0.0449922\n",
      "Early stopping, best iteration is:\n",
      "[1771]\ttraining's l2: 0.00540613\tvalid_1's l2: 0.0449708\n",
      "fold 2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0770478\tvalid_1's l2: 0.12366\n",
      "[400]\ttraining's l2: 0.0234796\tvalid_1's l2: 0.0713103\n",
      "[600]\ttraining's l2: 0.0144099\tvalid_1's l2: 0.0613735\n",
      "[800]\ttraining's l2: 0.0107741\tvalid_1's l2: 0.0582979\n",
      "[1000]\ttraining's l2: 0.00857118\tvalid_1's l2: 0.0562674\n",
      "[1200]\ttraining's l2: 0.00717353\tvalid_1's l2: 0.0551418\n",
      "[1400]\ttraining's l2: 0.00610573\tvalid_1's l2: 0.0544623\n",
      "[1600]\ttraining's l2: 0.00531354\tvalid_1's l2: 0.0541643\n",
      "[1800]\ttraining's l2: 0.0046848\tvalid_1's l2: 0.0538519\n",
      "[2000]\ttraining's l2: 0.00425486\tvalid_1's l2: 0.0535768\n",
      "[2200]\ttraining's l2: 0.00424293\tvalid_1's l2: 0.053577\n",
      "Early stopping, best iteration is:\n",
      "[2002]\ttraining's l2: 0.00425194\tvalid_1's l2: 0.053573\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.070637\tvalid_1's l2: 0.100834\n",
      "[400]\ttraining's l2: 0.022691\tvalid_1's l2: 0.0590935\n",
      "[600]\ttraining's l2: 0.0148207\tvalid_1's l2: 0.0527012\n",
      "[800]\ttraining's l2: 0.0114621\tvalid_1's l2: 0.0507223\n",
      "[1000]\ttraining's l2: 0.00918446\tvalid_1's l2: 0.0500037\n",
      "[1200]\ttraining's l2: 0.00764805\tvalid_1's l2: 0.0495743\n",
      "[1400]\ttraining's l2: 0.00642174\tvalid_1's l2: 0.0492538\n",
      "[1600]\ttraining's l2: 0.00549785\tvalid_1's l2: 0.0490259\n",
      "[1800]\ttraining's l2: 0.00480487\tvalid_1's l2: 0.0490799\n",
      "Early stopping, best iteration is:\n",
      "[1679]\ttraining's l2: 0.0052037\tvalid_1's l2: 0.0489776\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0690353\tvalid_1's l2: 0.0868664\n",
      "[400]\ttraining's l2: 0.0226042\tvalid_1's l2: 0.0475694\n",
      "[600]\ttraining's l2: 0.0146346\tvalid_1's l2: 0.0434313\n",
      "[800]\ttraining's l2: 0.0111798\tvalid_1's l2: 0.0421331\n",
      "[1000]\ttraining's l2: 0.00883146\tvalid_1's l2: 0.0417516\n",
      "[1200]\ttraining's l2: 0.00720212\tvalid_1's l2: 0.0413982\n",
      "[1400]\ttraining's l2: 0.00608557\tvalid_1's l2: 0.0411268\n",
      "Early stopping, best iteration is:\n",
      "[1368]\ttraining's l2: 0.00624098\tvalid_1's l2: 0.0411105\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0795256\tvalid_1's l2: 0.106137\n",
      "[400]\ttraining's l2: 0.0278074\tvalid_1's l2: 0.0573847\n",
      "[600]\ttraining's l2: 0.0182068\tvalid_1's l2: 0.0515064\n",
      "[800]\ttraining's l2: 0.0137818\tvalid_1's l2: 0.0503346\n",
      "[1000]\ttraining's l2: 0.0109143\tvalid_1's l2: 0.05009\n",
      "[1200]\ttraining's l2: 0.00889348\tvalid_1's l2: 0.0499913\n",
      "[1400]\ttraining's l2: 0.00742103\tvalid_1's l2: 0.0498892\n",
      "[1600]\ttraining's l2: 0.00631038\tvalid_1's l2: 0.0496972\n",
      "[1800]\ttraining's l2: 0.00546642\tvalid_1's l2: 0.0495654\n",
      "[2000]\ttraining's l2: 0.00486527\tvalid_1's l2: 0.0494361\n",
      "[2200]\ttraining's l2: 0.00469942\tvalid_1's l2: 0.0493999\n",
      "Early stopping, best iteration is:\n",
      "[2054]\ttraining's l2: 0.00473866\tvalid_1's l2: 0.0493907\n",
      "fold 3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0800761\tvalid_1's l2: 0.105828\n",
      "[400]\ttraining's l2: 0.0246418\tvalid_1's l2: 0.0603088\n",
      "[600]\ttraining's l2: 0.0153651\tvalid_1's l2: 0.0522328\n",
      "[800]\ttraining's l2: 0.0116687\tvalid_1's l2: 0.0494819\n",
      "[1000]\ttraining's l2: 0.0093873\tvalid_1's l2: 0.0481424\n",
      "[1200]\ttraining's l2: 0.00769763\tvalid_1's l2: 0.0474181\n",
      "[1400]\ttraining's l2: 0.00646596\tvalid_1's l2: 0.0470517\n",
      "[1600]\ttraining's l2: 0.0055448\tvalid_1's l2: 0.0466307\n",
      "[1800]\ttraining's l2: 0.00483467\tvalid_1's l2: 0.0463829\n",
      "[2000]\ttraining's l2: 0.00435148\tvalid_1's l2: 0.0462268\n",
      "Early stopping, best iteration is:\n",
      "[1935]\ttraining's l2: 0.00448413\tvalid_1's l2: 0.0462159\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0719638\tvalid_1's l2: 0.0863845\n",
      "[400]\ttraining's l2: 0.0237687\tvalid_1's l2: 0.0470884\n",
      "[600]\ttraining's l2: 0.0160651\tvalid_1's l2: 0.0400354\n",
      "[800]\ttraining's l2: 0.0126898\tvalid_1's l2: 0.0379274\n",
      "[1000]\ttraining's l2: 0.0101744\tvalid_1's l2: 0.0371917\n",
      "[1200]\ttraining's l2: 0.00830725\tvalid_1's l2: 0.036832\n",
      "[1400]\ttraining's l2: 0.0069886\tvalid_1's l2: 0.0366827\n",
      "Early stopping, best iteration is:\n",
      "[1346]\ttraining's l2: 0.00731912\tvalid_1's l2: 0.0366539\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0706683\tvalid_1's l2: 0.0958999\n",
      "[400]\ttraining's l2: 0.0237326\tvalid_1's l2: 0.0504636\n",
      "[600]\ttraining's l2: 0.0157073\tvalid_1's l2: 0.042205\n",
      "[800]\ttraining's l2: 0.0121191\tvalid_1's l2: 0.0397557\n",
      "[1000]\ttraining's l2: 0.00950237\tvalid_1's l2: 0.0385214\n",
      "[1200]\ttraining's l2: 0.00774844\tvalid_1's l2: 0.0380873\n",
      "[1400]\ttraining's l2: 0.00651783\tvalid_1's l2: 0.0380426\n",
      "[1600]\ttraining's l2: 0.00558933\tvalid_1's l2: 0.038006\n",
      "[1800]\ttraining's l2: 0.00493514\tvalid_1's l2: 0.0378983\n",
      "[2000]\ttraining's l2: 0.00448933\tvalid_1's l2: 0.0379102\n",
      "Early stopping, best iteration is:\n",
      "[1859]\ttraining's l2: 0.00477009\tvalid_1's l2: 0.0378858\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0796086\tvalid_1's l2: 0.111992\n",
      "[400]\ttraining's l2: 0.0275633\tvalid_1's l2: 0.0650351\n",
      "[600]\ttraining's l2: 0.0183302\tvalid_1's l2: 0.0577452\n",
      "[800]\ttraining's l2: 0.0142673\tvalid_1's l2: 0.0551027\n",
      "[1000]\ttraining's l2: 0.0114731\tvalid_1's l2: 0.0541465\n",
      "[1200]\ttraining's l2: 0.00944278\tvalid_1's l2: 0.0536767\n",
      "[1400]\ttraining's l2: 0.00796949\tvalid_1's l2: 0.0531875\n",
      "[1600]\ttraining's l2: 0.00681412\tvalid_1's l2: 0.0529823\n",
      "[1800]\ttraining's l2: 0.00590666\tvalid_1's l2: 0.0527047\n",
      "[2000]\ttraining's l2: 0.00523435\tvalid_1's l2: 0.0525092\n",
      "[2200]\ttraining's l2: 0.00492946\tvalid_1's l2: 0.0524158\n",
      "Early stopping, best iteration is:\n",
      "[2087]\ttraining's l2: 0.00500334\tvalid_1's l2: 0.0524081\n",
      "fold 4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0758642\tvalid_1's l2: 0.175222\n",
      "[400]\ttraining's l2: 0.0238755\tvalid_1's l2: 0.0882258\n",
      "[600]\ttraining's l2: 0.0148054\tvalid_1's l2: 0.0703938\n",
      "[800]\ttraining's l2: 0.011127\tvalid_1's l2: 0.0652503\n",
      "[1000]\ttraining's l2: 0.00885651\tvalid_1's l2: 0.0633881\n",
      "[1200]\ttraining's l2: 0.00726363\tvalid_1's l2: 0.0620307\n",
      "[1400]\ttraining's l2: 0.00612347\tvalid_1's l2: 0.0613319\n",
      "[1600]\ttraining's l2: 0.00523956\tvalid_1's l2: 0.0610065\n",
      "[1800]\ttraining's l2: 0.00463275\tvalid_1's l2: 0.0607528\n",
      "[2000]\ttraining's l2: 0.00414116\tvalid_1's l2: 0.0606016\n",
      "[2200]\ttraining's l2: 0.00389029\tvalid_1's l2: 0.0605331\n",
      "Early stopping, best iteration is:\n",
      "[2129]\ttraining's l2: 0.00391029\tvalid_1's l2: 0.0605267\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.0700134\tvalid_1's l2: 0.132909\n",
      "[400]\ttraining's l2: 0.0233448\tvalid_1's l2: 0.066823\n",
      "[600]\ttraining's l2: 0.0158373\tvalid_1's l2: 0.0551385\n",
      "[800]\ttraining's l2: 0.0125566\tvalid_1's l2: 0.051547\n",
      "[1000]\ttraining's l2: 0.0101416\tvalid_1's l2: 0.0501498\n",
      "[1200]\ttraining's l2: 0.00836686\tvalid_1's l2: 0.0492616\n",
      "[1400]\ttraining's l2: 0.00695596\tvalid_1's l2: 0.0486736\n",
      "[1600]\ttraining's l2: 0.00593705\tvalid_1's l2: 0.0484774\n",
      "[1800]\ttraining's l2: 0.0052251\tvalid_1's l2: 0.0483791\n",
      "Early stopping, best iteration is:\n",
      "[1759]\ttraining's l2: 0.00535019\tvalid_1's l2: 0.0483488\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.067868\tvalid_1's l2: 0.127791\n",
      "[400]\ttraining's l2: 0.0225025\tvalid_1's l2: 0.0692954\n",
      "[600]\ttraining's l2: 0.0148395\tvalid_1's l2: 0.0596769\n",
      "[800]\ttraining's l2: 0.0113634\tvalid_1's l2: 0.0565092\n",
      "[1000]\ttraining's l2: 0.00916327\tvalid_1's l2: 0.0549093\n",
      "[1200]\ttraining's l2: 0.00749387\tvalid_1's l2: 0.0540646\n",
      "[1400]\ttraining's l2: 0.0063612\tvalid_1's l2: 0.0537593\n",
      "[1600]\ttraining's l2: 0.00550022\tvalid_1's l2: 0.0534501\n",
      "[1800]\ttraining's l2: 0.00488577\tvalid_1's l2: 0.0532136\n",
      "[2000]\ttraining's l2: 0.00436693\tvalid_1's l2: 0.053182\n",
      "Early stopping, best iteration is:\n",
      "[1928]\ttraining's l2: 0.00452625\tvalid_1's l2: 0.0531478\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.077706\tvalid_1's l2: 0.139305\n",
      "[400]\ttraining's l2: 0.0275568\tvalid_1's l2: 0.0722875\n",
      "[600]\ttraining's l2: 0.0179607\tvalid_1's l2: 0.0623847\n",
      "[800]\ttraining's l2: 0.0137136\tvalid_1's l2: 0.0587396\n",
      "[1000]\ttraining's l2: 0.0108082\tvalid_1's l2: 0.0568336\n",
      "[1200]\ttraining's l2: 0.00877511\tvalid_1's l2: 0.0562371\n",
      "[1400]\ttraining's l2: 0.00735349\tvalid_1's l2: 0.0558\n",
      "[1600]\ttraining's l2: 0.00628409\tvalid_1's l2: 0.0558113\n",
      "Early stopping, best iteration is:\n",
      "[1510]\ttraining's l2: 0.00671718\tvalid_1's l2: 0.0557362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\ipykernel_launcher.py:157: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\ipykernel_launcher.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\ipykernel_launcher.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Users\\X1Carbon\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\ipykernel_launcher.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# 模型\n",
    "le_model = preprocessing.LabelEncoder()\n",
    "le_bodyType = preprocessing.LabelEncoder()\n",
    "\n",
    "le_model.fit(train_data.model)\n",
    "le_bodyType.fit(train_data.bodyType)\n",
    "\n",
    "lgb_params = {\n",
    "    \"num_leaves\":32,\n",
    "    \"reg_alpha\":1,\n",
    "    \"reg_lambda\":0.1,\n",
    "    \"objective\":'mse',\n",
    "    \"max_depth\": 4,\n",
    "    \"learning_rate\":0.01,\n",
    "    \"min_child_samples\":5,\n",
    "    \"random_state\":random.randint(100, 10000),\n",
    "    \"n_estimators\":5000,\n",
    "    \"subsample\":0.8,\n",
    "    \"colsample_bytree\":0.8\n",
    "}\n",
    "\n",
    "df_train_columns = [c for c in train_data.columns if c not in []]\n",
    "print(\"df_train_columns:\",df_train_columns)\n",
    "cate_fea = [\"adcode\", \"model\", \"bodyType\"]\n",
    "train_data.model = le_model.transform(train_data.model)\n",
    "train_data.bodyType = le_bodyType.transform(train_data.bodyType)\n",
    "print(train_data.shape)\n",
    "print(len(df_train_columns))\n",
    "\n",
    "\n",
    "y_score = []    # 交叉验证\n",
    "cv_pred = []    # 各折的预测值\n",
    "predictions = 0\n",
    "feature_importance_df = pd.DataFrame()\n",
    "skf = KFold(n_splits=5, random_state=random.randint(100, 10000), shuffle=True)\n",
    "\n",
    "\n",
    "label_0 = vaild_data[0]\n",
    "label_1 = vaild_data[1]\n",
    "label_2 = vaild_data[2]\n",
    "label_3 = vaild_data[3]\n",
    "\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(skf.split(train_data, label_0)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train_data.iloc[trn_idx][df_train_columns], label=label_0.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_data.iloc[val_idx][df_train_columns], label=label_0.iloc[val_idx])\n",
    "\n",
    "    result_df = train_data.iloc[val_idx][[\"adcode\", \"model\"]]\n",
    "\n",
    "    gbm_1 = lgb.train(lgb_params,\n",
    "                    trn_data,\n",
    "                    # init_model=gbm,\n",
    "                    num_boost_round=150000,\n",
    "                    valid_sets=[trn_data, val_data],\n",
    "                    early_stopping_rounds=200,\n",
    "                    verbose_eval=200,\n",
    "                    categorical_feature=cate_fea)     # 训练\n",
    "\n",
    "    trn_data = lgb.Dataset(train_data.iloc[trn_idx][df_train_columns], label=label_1.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_data.iloc[val_idx][df_train_columns], label=label_1.iloc[val_idx])\n",
    "\n",
    "    gbm_2 = lgb.train(lgb_params,\n",
    "                    trn_data,\n",
    "                    # init_model=gbm,\n",
    "                    num_boost_round=150000,\n",
    "                    valid_sets=[trn_data, val_data],\n",
    "                    early_stopping_rounds=200,\n",
    "                    verbose_eval=200,\n",
    "                    categorical_feature=cate_fea)     # 训练\n",
    "\n",
    "    trn_data = lgb.Dataset(train_data.iloc[trn_idx][df_train_columns], label=label_2.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_data.iloc[val_idx][df_train_columns], label=label_2.iloc[val_idx])\n",
    "\n",
    "    gbm_3 = lgb.train(lgb_params,\n",
    "                    trn_data,\n",
    "                    # init_model=gbm,\n",
    "                    num_boost_round=3000,\n",
    "                    valid_sets=[trn_data, val_data],\n",
    "                    early_stopping_rounds=200,\n",
    "                    verbose_eval=200,\n",
    "                    categorical_feature=cate_fea)     # 训练\n",
    "\n",
    "    trn_data = lgb.Dataset(train_data.iloc[trn_idx][df_train_columns], label=label_3.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_data.iloc[val_idx][df_train_columns], label=label_3.iloc[val_idx])\n",
    "\n",
    "    gbm_4 = lgb.train(lgb_params,\n",
    "                    trn_data,\n",
    "                    # init_model=gbm,\n",
    "                    num_boost_round=150000,\n",
    "                    valid_sets=[trn_data, val_data],\n",
    "                    early_stopping_rounds=200,\n",
    "                    verbose_eval=200,\n",
    "                    categorical_feature=cate_fea)     # 训练\n",
    "\n",
    "    result_df[\"y_pred_1\"] = gbm_1.predict(train_data.iloc[val_idx][df_train_columns])\n",
    "    result_df[\"y_pred_2\"] = gbm_2.predict(train_data.iloc[val_idx][df_train_columns])\n",
    "    result_df[\"y_pred_3\"] = gbm_3.predict(train_data.iloc[val_idx][df_train_columns])\n",
    "    result_df[\"y_pred_4\"] = gbm_4.predict(train_data.iloc[val_idx][df_train_columns])\n",
    "    # break\n",
    "\n",
    "result_df[\"y_true_1\"] = label_0\n",
    "result_df[\"y_true_2\"] = label_1\n",
    "result_df[\"y_true_3\"] = label_2\n",
    "result_df[\"y_true_4\"] = label_3\n",
    "\n",
    "# 预测\n",
    "# 基础特征\n",
    "# 城市+车\n",
    "test_basic_fea = cal_basic_fea(train_sales, \"salesVolume\", [\"adcode\", \"model\", \"regMonth\"], \"test\")\n",
    "# 城市\n",
    "tmp_df = cal_basic_fea(train_sales, \"salesVolume\", [\"adcode\", \"regMonth\"], \"test\")\n",
    "test_basic_fea = pd.merge(test_basic_fea, tmp_df, on=\"adcode\", how=\"left\")\n",
    "# 车\n",
    "tmp_df = cal_basic_fea(train_sales, \"salesVolume\", [\"model\", \"regMonth\"], \"test\")\n",
    "test_basic_fea = pd.merge(test_basic_fea, tmp_df, on=\"model\", how=\"left\")\n",
    "# 城市+车型\n",
    "tmp_df = cal_basic_fea(train_sales, \"salesVolume\", [\"adcode\", \"bodyType\", \"regMonth\"], \"test\")\n",
    "test_basic_fea[\"bodyType\"] = test_basic_fea.model.apply(lambda x: model2type[x])\n",
    "test_basic_fea = pd.merge(test_basic_fea, tmp_df, on=[\"adcode\", \"bodyType\"], how=\"left\")\n",
    "\n",
    "# 滑窗特征\n",
    "# 城市+车\n",
    "test_windows_fea = cal_windows_fea(train_sales, cal_col=\"salesVolume\", stat_dim=[\"adcode\", \"model\", \"regMonth\"], data_type=\"test\")\n",
    "# 城市\n",
    "tmp_df = cal_windows_fea(train_sales, \"salesVolume\", [\"adcode\", \"regMonth\"], \"test\")\n",
    "test_windows_fea = pd.merge(test_windows_fea, tmp_df, on=\"adcode\", how=\"left\")\n",
    "# 车\n",
    "tmp_df = cal_windows_fea(train_sales, \"salesVolume\", [\"model\", \"regMonth\"], \"test\")\n",
    "test_windows_fea = pd.merge(test_windows_fea, tmp_df, on=\"model\", how=\"left\")\n",
    "# 城市+车型\n",
    "tmp_df = cal_windows_fea(train_sales, \"salesVolume\", [\"adcode\", \"bodyType\", \"regMonth\"], \"test\")\n",
    "test_windows_fea[\"bodyType\"] = test_windows_fea.model.apply(lambda x: model2type[x])\n",
    "test_windows_fea = pd.merge(test_windows_fea, tmp_df, on=[\"adcode\", \"bodyType\"], how=\"left\")\n",
    "\n",
    "# 合并\n",
    "test_data = pd.merge(test_basic_fea, test_windows_fea, on=[\"adcode\", \"model\", \"bodyType\"], how=\"left\")\n",
    "\n",
    "test_data.model = le_model.transform(test_data.model)\n",
    "test_data.bodyType = le_bodyType.transform(test_data.bodyType)\n",
    "\n",
    "y_pred_1 = gbm_1.predict(test_data[df_train_columns])\n",
    "y_pred_2 = gbm_2.predict(test_data[df_train_columns])\n",
    "y_pred_3 = gbm_3.predict(test_data[df_train_columns])\n",
    "y_pred_4 = gbm_4.predict(test_data[df_train_columns])\n",
    "\n",
    "y_pred_1 = (np.e ** y_pred_1 - 1).astype(int)\n",
    "y_pred_2 = (np.e ** y_pred_2 - 1).astype(int)\n",
    "y_pred_3 = (np.e ** y_pred_3 - 1).astype(int)\n",
    "y_pred_4 = (np.e ** y_pred_4 - 1).astype(int)\n",
    "\n",
    "result_df = test_basic_fea[[\"adcode\", \"model\"]]\n",
    "result_df[\"y_pred_1\"] = y_pred_1\n",
    "result_df[\"y_pred_2\"] = y_pred_2\n",
    "result_df[\"y_pred_3\"] = y_pred_3\n",
    "result_df[\"y_pred_4\"] = y_pred_4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(TEST_PATH)\n",
    "test_data = test_data.drop(\"forecastVolum\", axis=1)\n",
    "test_data_1 = pd.merge(test_data.loc[test_data.regMonth == 1], result_df[[\"adcode\", \"model\", \"y_pred_1\"]].rename(columns={\"y_pred_1\":\"forecastVolum\"}),\\\n",
    "                       how=\"left\", on=[\"adcode\", \"model\"])\n",
    "test_data_2 = pd.merge(test_data.loc[test_data.regMonth == 2], result_df[[\"adcode\", \"model\", \"y_pred_2\"]].rename(columns={\"y_pred_2\":\"forecastVolum\"}),\\\n",
    "                       how=\"left\", on=[\"adcode\", \"model\"])\n",
    "test_data_3 = pd.merge(test_data.loc[test_data.regMonth == 3], result_df[[\"adcode\", \"model\", \"y_pred_3\"]].rename(columns={\"y_pred_3\":\"forecastVolum\"}),\\\n",
    "                       how=\"left\", on=[\"adcode\", \"model\"])\n",
    "test_data_4 = pd.merge(test_data.loc[test_data.regMonth == 4], result_df[[\"adcode\", \"model\", \"y_pred_4\"]].rename(columns={\"y_pred_4\":\"forecastVolum\"}),\\\n",
    "                       how=\"left\", on=[\"adcode\", \"model\"])\n",
    "result = pd.concat([test_data_1, test_data_2, test_data_3, test_data_4]).reset_index(drop=True)\n",
    "result.forecastVolum = result.forecastVolum.astype(int)\n",
    "result.loc[(result.forecastVolum < 0), \"forecastVolum\"] = 1\n",
    "print((result.forecastVolum < 0 ).sum())\n",
    "result[[\"id\", \"forecastVolum\"]].to_csv(\"submit/evaluation_public_20190917_lgb.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
