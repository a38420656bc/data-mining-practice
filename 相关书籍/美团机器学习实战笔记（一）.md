# 美团机器学习实战笔记（一）

## 第一章：问题建模

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190819211832745.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RlbmdjaGVuZ3R1NDEzOQ==,size_16,color_FFFFFF,t_70)

### 1.1 评估指标

评估指标根据任务类型分类，可分为分类指标、回归指标、聚类指标和排序指标等

#### 1.1.1 分类指标

##### 1.精确率和召回率：多用于二分类问题可结合棍淆矩阵介绍




![在这里插入图片描述](https://img-blog.csdnimg.cn/20190819211904424.png)
其中：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190819211926951.png)

理想情况下，精确率和召回率两者都越高越好，然而事实上这两者在某些情况下是矛盾的:
精确率高时\召回率低;而精确率低时，召回率高。

此外，**准确率**和**错误率**也是常用的评估指标：

精确率和准确率是比较容易混淆的两个评估指标，两者是有区别的。精确率是一个二分类指
标，而准确率能应用于多分类，其计算公式为:

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190819211945890.png)

##### 2.ROC和AUC

> `在众多的机器学习模型中，很多模型输出是预测概率。而使用精确率、召回率这类指标进行
> 模型评估时，还需要对预测概率设分类阔值，比如预测概率大于|萄值为正例，反之为负例。这使
> 得模型多了一个超参数，并且这个超参数会影响模型的泛化能力。

接收者操作特征(Receiver Operating Characteristic, ROC ) 曲线不需要设定这样的闽值。ROC
曲线纵坐标是真正率，横坐标是假正率:

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190819212002987.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RlbmdjaGVuZ3R1NDEzOQ==,size_16,color_FFFFFF,t_70)

**ROC 曲线越靠近左上角性能越好。**左上角坐标为(0 ，1) ，即FPR=O, TPR斗，根据FPR和TPR公式可以得知，此时FN=O ，FP=O ，模型对所有样本分类正确。
绘制ROC 曲线很简单，首先对所有样本按预测概率排序，以每条样本的预测概率为阔值，计算对
应的FPR和TPR ，然后用线段连接。当数据量少时\绘制的ROCI曲线不平滑; 当数据量大时，绘
制的ROC 曲线会趋于平滑。

AUC (Area Under Roc Curve ) 即**ROC 曲线下的面积**，取值越大说明模型越可能将正样本排在负样本前面

AUC 的计算方法有多种，从物理意义角度理解，AUC计算的是ROC 曲线下的面积:

[外链图片转存失败(img-n6MA4S5t-1566219726455)(C:\Users\X1 Carbon\AppData\Roaming\Typora\typora-user-images\1566218043542.png)]

从概率意义角度理解，AUC考虑的是样本的排序质量，它与排序误差有密切关系，可得到计
算公式

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190819212021356.png)

rank为样本排序位置从l 开始，IPI为正样本数，INI为负样本数。AUC计算主要与排序有关，所以它对排序敏感，而对预测分数没那么敏感

##### 3.对数损失

对数损失对应的二分类的计算公式为：

![](https://img-blog.csdnimg.cn/20190819212039117.png)

多分类：


![在这里插入图片描述](https://img-blog.csdnimg.cn/20190819212136370.png)
N为样本数，c为类别数，Yij = 1表示第t条样本的类别为j ，Pij为第i条样本类别j 的概率。

logloss衡量的是预测概率分布和真实概率分布的差异性，取值越小越好。与AUC不同，
loglo ss对预测概率敏感。

#### 1.1.2 回归指标

##### 1.平均绝对误差（Mean Absolute Error, MAE) ，也叫范数损失( L -normLoss )

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190819212207224.png)

其中，N为样本数，Yi 为第l 条样本的真实值，Pi 为第i 条样本的预测值。MAE是绝对误差的平均
值，因为预测误差有正有负，绝对值可以避免正负抵消。MAE能很好地刻画预测值与真实值的
偏差。模型使用MAE作为损失函数则是对数据分布的中值进行拟合。某些模型(如**XGBoost** ）必
须要求损失函数有二阶导数，所以不能直接优化MAE。

加权平均绝对误差( Weighted Mean Absolute Error, WMAE) 是基于MAE的变种评估指标，
对每条样本考虑不同的权重，比如考虑时间因素，离当前时间越久的样本权重越低

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190819212225268.png)

##### 2.平均绝对百分误差Mean Absolute Percentage Error, MAPE)

![在这里插入图片描述](https://img-blog.csdnimg.cn/2019081921223960.png)

##### 3.均方根误差Root Mean Squared Error , RMSE

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190819212252410.png)

RMSE代表的是预测值和真实值差值的样本标准差。和MAE 比，RMSE对大误差样本有更大
的惩罚;但它也对离群点敏感，其健壮性不如MAE 。模型使用灿1SE作为损失函数则是对数据分
布的平均值进行拟合

基于均方根误差也有一个常用的变种评估指标叫均方根对数误差( Root Mean Squared
Logarithmic Error , RMSLE) 

![在这里插入图片描述](https://img-blog.csdnimg.cn/2019081921231046.png)

RMSLE对预测值偏小的样本惩罚比对预测值偏大的样本惩罚更大，比如一个酒店消费均价
是200元，预测成150元的惩罚会比预测成250元的大。如果评估指标选用RMSLE ，没办法直接优
化RMSLE但是能直接优化RMSE的模型。

#### 1.1.3 排序指标

##### 1.平均准确率均值Mean Average Precision, MAP 

分两部分计算，先计算一次排序的
平均准确率，再计算总体的平均准确率。常用的MAP指标会限定评估排在前面的文档质量

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190819212334340.png)

其中，AP@K表示计算前K个结果的平均准确率;M表示每次排序的文档总数，可能一次返回文
档数不足K个; P(k)表示前k个结果的准确率; rel(k)表示第k个结果是否是相关文档，相关取值
为1 ，不相关取值为0 

##### 2.NDCG

### 1.2样本选择

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190819212355739.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RlbmdjaGVuZ3R1NDEzOQ==,size_16,color_FFFFFF,t_70)

##### 1.2.1数据去噪

> 数据中含有噪声数据几乎是不可避免的问题。噪声的存在会导致数据质量变低，影响模型的
> 效果，但通过在训练集中引人噪声数据也能起到提升模型健壮性的作用。因此，包含噪声数据的
> 问题是非常复杂

针对误标注实例有很多成功的处理方案最常见的有集成过滤法( Ensemble Filter , EF)、交
叉验证委员会过滤法( Cross-Validated Committees Filter , CVCF) 和迭代分割过波、法( Iterative-
Partitioning Filter , IPF) 这三种方法，这些方法都是基于融合或者投票的思想进行数据过滤的

除了这些过滤方法外，其实还会考虑就业务的本身性质做一些数据过滤工作，比如清洗爬虫
数据和不具代表性样本等。再如过滤掉无效l曝光数据，根据用户最后一次点击行为的位置，过滤
掉最后一次点击之后的展示，可以认为用户没有看到，也可以保留最后一次点击之后的少数几个
曝光

##### 1.2.2采样

进行采样时最关心采样方法和采样比例

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190819212412245.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RlbmdjaGVuZ3R1NDEzOQ==,size_16,color_FFFFFF,t_70)

##### 1.2.3原型选择和训练集选择

> 原型选择是基于实例的方法，在样本选择过程中不需要训练模型，而是选取相似度或距离度
> 量指标来找到分类精度和数据量最佳的训练集，多数采用KNN算法。训练、集选择则是构建预测模
> 型来进行样本选择的方法的统称，比如决策树、ANN和SVM等算法。原型选择和训练集选择两
> 大类别的样本选择方法有很多，然而没有一种方法能够通用。

### 1.3交叉验证

在离线环节，需要对模型进行评估，根据评估指标选择最佳模型。

我们将划分训练集和测试集的方法统称为交叉验证。交叉验证有很多方法，不同方法适用不同场景

##### 1.3.1留出法

留出法(Hold-Out) 是将数据集D 随机划分成两份互斥的数据集，一份作为训练集一份作为测试集，在训练集上训练模型，然后用测试集评估模型效果。本质上，**留出法并非一种交叉验证方法，因为数据并没有交叉**。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190819212427141.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RlbmdjaGVuZ3R1NDEzOQ==,size_16,color_FFFFFF,t_70)

留出法只需将数据划分成两部分，简单好实现，如图1-6所示。但这种方法的缺点也比较明显：

它**不能充分利用数据训练模型**，并且训练集和测试集的划分严重影响最终结果。通常的做法是，2/3数据作为训练集，1 /3 数据作为测试集

除了划分测试集数据量对结论有影响外，**划分哪些样本作为测试集也会影响实验结论**，因为
这将导致数据分布发生变化。比如二分类问题有1500条正样本和1500条负样本，将1/3 数据作为
测试集，应该使得测试集正负样本均在50条左右;如果测试集由50条正样本和950条负样本组成，
实验结论将因为样本分布差异悬殊而有很大偏差。因此，**考虑到单次留出法得到的结论往往不靠**
**谱，我们会进行多次留出法实验，每次随机划分，最终将多次得到的实验结论进行平均**。

实际工作中有一种普遍的应用场景**广泛使用留出法**: ***数据有明显的时间序列因素***，即线上数
据的时间都在离线数据集之后，这种情况下应该根据时间对离线数据集划分训练集和测试集，使
测试集时间分布在训练集时间之后。
比如，在2017年6月初需要训练模型，可以采用2017年1 月到2017年4月的数据作为训练集，
2017 年5 月的数据作为测试集

##### 1.3.2K折交叉验证

K折交叉，验证(K-fold Cross Validation ) 将数据集D 划分成K份互斥数据集

一般是平均分配使每份数据量接近并且数据分布尽可能一致。每次用一份数据测试，其余
K-l 份数据训练，需要迭代K 轮得到K个模型; 最后再将K份测试结果汇总到一起评估一个离线
指标。

![在这里插入图片描述](https://img-blog.csdnimg.cn/2019081921244119.png)

K折交叉验证的稳定性与K取值有很大关系。K值太小实验稳定性依然偏低，K值太大又可能
导致实验成本高，K最常用的取值是5和10 ，如图1-7所示。K折交叉验证能够更好地避免过拟合
和欠拟合，得到的结论也更有说服力。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190819212452961.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RlbmdjaGVuZ3R1NDEzOQ==,size_16,color_FFFFFF,t_70)

基于K折交叉验证还变种出一个在类不均衡情况下常用的方法，叫作**分层K折交叉验证**
**( Stratified K-Fold )**。该方法对每个类别进行K折划分，使每份数据中各类别的数据分布与完整数
据集分布更一致。比如二分类数据进行5折交叉验证，类别l 有30条数据，类别2有300条数据，在
划分成5折时，如果随机划分成5份，这可能导致5份数据中的类别l 数据量差别很大，导致每份数
据训练出来的模型对类别l 的分类效果差异很大，影响整体效果**。如果通过分层5 折交叉验证，即**
**分别对2个类别划分，使每份数据有6条类别l 样本，60条类别2样本，每份数据分布都和整体数据**
**分布一致，得到的模型也就更可信**

如二分类数据进行5折交叉验证，类别l 有30条数据，类别2有300条数据，在
划分成5折时，如果随机划分成5份，这可能导致5份数据中的类别l 数据量差别很大，导致每份数
据训练出来的模型对类别l 的分类效果差异很大，影响整体效果**。如果通过分层5 折交叉验证，即**
**分别对2个类别划分，使每份数据有6条类别l 样本，60条类别2样本，每份数据分布都和整体数据**
**分布一致，得到的模型也就更可信**

##### 1.3.3 自助法
