{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主要写一下sklearn.preprocessing的用法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这里主要讨论两种归一化方法：\n",
    "\n",
    "1、线性函数归一化(Min-Max scaling)\n",
    "线性函数将原始数据线性化的方法转换到[0 1]的范围，归一化公式如下：\n",
    "\n",
    "\n",
    "该方法实现对原始数据的等比例缩放，其中Xnorm为归一化后的数据，X为原始数据，Xmax、Xmin分别为原始数据集的最大值和最小值。\n",
    "\n",
    "2、0均值标准化(Z-score standardization)\n",
    "0均值归一化方法将原始数据集归一化为均值为0、方差1的数据集，归一化公式如下：\n",
    "\n",
    "其中，μ、σ分别为原始数据集的均值和方法。该种归一化方式要求原始数据的分布可以近似为高斯分布，否则归一化的效果会变得很糟糕。\n",
    "\n",
    "以上为两种比较普通但是常用的归一化技术，那这两种归一化的应用场景是怎么样的呢？什么时候第一种方法比较好、什么时候第二种方法比较好呢？下面做一个简要的分析概括：\n",
    "\n",
    "1、在分类、聚类算法中，需要使用距离来度量相似性的时候、或者使用PCA技术进行降维的时候，第二种方法(Z-score standardization)表现更好。\n",
    "\n",
    "2、在不涉及距离度量、协方差计算、数据不符合正太分布的时候，可以使用第一种方法或其他归一化方法。比如图像处理中，将RGB图像转换为灰度图像后将其值限定在[0 255]的范围。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import scale,StandardScaler\n",
    "\n",
    "\n",
    "X = np.array([[ 1., -1.,  2.], \n",
    "              [ 2.,  0.,  0.],\n",
    "              [ 0.,  1., -1.]])\n",
    "scaler = StandardScaler().fit(X)\n",
    "print(scaler)\n",
    "\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "\n",
    "print(scaler.transform(X))\n",
    "[[ 0.         -1.22474487  1.33630621]\n",
    " [ 1.22474487  0.         -0.26726124]\n",
    " [-1.22474487  1.22474487 -1.06904497]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_train = np.array([[ 1., -1.,  2.], \n",
    "                    [ 2.,  0.,  0.],\n",
    "                    [ 0.,  1., -1.]])\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "print(min_max_scaler)\n",
    "\n",
    "X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
    "\n",
    "print(X_train_minmax)\n",
    "\n",
    "origin_data = min_max_scaler.inverse_transform(X_train_minmax)\n",
    "\n",
    "print(origin_data)\n",
    "\n",
    "\n",
    "#将相同的缩放应用到测试集数据中\n",
    "X_test = np.array([-3., -1., 4.])\n",
    "X_test_minmax = min_max_scaler.transform(X_test.reshape(1,-1))\n",
    "\n",
    "print(X_test_minmax)\n",
    "\n",
    "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
    "[[0.5        0.         1.        ]\n",
    " [1.         0.5        0.33333333]\n",
    " [0.         1.         0.        ]]\n",
    "[[ 1. -1.  2.]\n",
    " [ 2.  0.  0.]\n",
    " [ 0.  1. -1.]]\n",
    "[[-1.5         0.          1.66666667]]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
