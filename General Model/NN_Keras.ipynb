{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# coding=utf-8\n",
    "from model.util import load_data as load_data_1\n",
    "from model.util_combine_train_test import load_data as load_data_2\n",
    "from sklearn.preprocessing import StandardScaler # 用于特征的标准化\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "print(\"Loading Data ... \")\n",
    "# 导入数据\n",
    "train_x, train_y, test_x = load_data()\n",
    "\n",
    "# 构建特征\n",
    "X_train = train_x.values\n",
    "X_test  = test_x.values\n",
    "y = train_y\n",
    "\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "X_train = imp.fit_transform(X_train)\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train = sc.transform(X_train)\n",
    "X_test  = sc.transform(X_test)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(X_train.shape[1],)))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('linear'))\n",
    "model.add(Dense(1)) # 这里需要和输出的维度一致\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# For a multi-class classification problem\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 100\n",
    "model.fit(X_train, y, epochs=epochs, batch_size=2000, validation_split=0.1, shuffle=True)\n",
    "\n",
    "# 导出结果\n",
    "threshold = 0.5\n",
    "for index, case in enumerate(X_test):\n",
    "    case =np.array([case])\n",
    "    prediction_prob = model.predict(case)\n",
    "    prediction = 1 if prediction_prob[0][0] > threshold else 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# coding=utf-8\n",
    "from model.util import load_data as load_data_1\n",
    "from model.util_combine_train_test import load_data as load_data_2\n",
    "from sklearn.preprocessing import StandardScaler # 用于特征的标准化\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "print(\"Loading Data ... \")\n",
    "# 导入数据\n",
    "train_x, train_y, test_x = load_data()\n",
    "\n",
    "# 构建特征\n",
    "X_train = train_x.values\n",
    "X_test  = test_x.values\n",
    "y = train_y\n",
    "\n",
    "# 特征处理\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train = sc.transform(X_train)\n",
    "X_test  = sc.transform(X_test)\n",
    "y = to_categorical(y) ## 这一步很重要，一定要将多类别的标签进行one-hot编码\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(X_train.shape[1],)))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('linear'))\n",
    "model.add(Dense(9)) # 这里需要和输出的维度一致\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# For a multi-class classification problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 200\n",
    "model.fit(X_train, y, epochs=epochs, batch_size=200, validation_split=0.1, shuffle=True)\n",
    "\n",
    "# 导出结果\n",
    "for index, case in enumerate(X_test):\n",
    "    case = np.array([case])\n",
    "    prediction_prob = model.predict(case)\n",
    "    prediction = np.argmax(prediction_prob)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
